{
    "topic": "media_bias",
    "source": "Vanity Fair",
    "bias": 0,
    "url": "http://www.vanityfair.com/news/2016/12/there-is-no-good-answer-to-facebooks-fake-news-problem",
    "title": "There is No Good Answer to Facebook's Fake News Problem",
    "date": "",
    "authors": "Cond\u00e9 Nast, Maya Kosof, Abigail Tracy, Bess Levin, T.A. Frank, Laura Bradley",
    "content": "The utopian dream of the Internet as a place to connect the world and share ideas appears to have found its nemesis not in censorship , as some early Web pioneers feared , but in the proliferation of fake news , an even more pernicious form of misinformation , perfectly designed to take advantage of the viral nature of the open Web . The question of what social-media companies should do , if anything , to combat its spread has been vexing . Earlier this year , Facebook came under fire for allegedly suppressing conservative stories in the trending-news section of its platform , which had been maintained and curated by human editors . The fallout was swift : forced to address the situation , Facebook at first denied any bias , then replaced its employees with software that purportedly could do the same job . The algorithm , not surprisingly , was less perceptive than its human predecessors .\nFake news began appearing with increased frequency in the trending-news bar , potentially misleading many millions of Facebook \u2019 s 1.79 billion monthly active users . Even more concerning was the spread of misleading stories shared by users themselves : according to one analysis by BuzzFeed News , in the last three months of the 2016 election , fake-news stories significantly outperformed real news stories across the social-media network . Many reportedly originated in Eastern Europe , where entrepreneurial teens and hostile foreign intelligence agencies alike fed a seemingly insatiable appetite for disinformation about America \u2019 s two deeply-disliked presidential candidates .\nSince Donald Trump won the election , shocking most political observers , C.E.O . Mark Zuckerberg has found himself on the defensive over the role fake news might have played in enabling the former reality-TV star \u2019 s rise from political punchline to president-elect . In less than two weeks , Zuckerberg went from arguing that it is \u201c pretty crazy \u201d to suggest that fake news on Facebook was at all responsible for Trump \u2019 s surprising electoral success , to posting a more nuanced mea culpa , in which he wrote that the company takes \u201c misinformation seriously \u201d and that Facebook is taking steps to address the problem .\nIn spite of its best efforts , however , Facebook may never be able to truly eradicate fake news on its platform , and not for lack of trying . Elliot Schrage , Facebook \u2019 s vice president of global communications , marketing , and public policy , said as much at a talk at Harvard on Wednesday evening . \u201c For so long , we had resisted having standards about whether something \u2019 s newsworthy because we did not consider ourselves a service that was predominantly for the distribution of news , \u201d Schrage said . \u201c And that was wrong ! We have a responsibility here . I think we recognize that . This has been a learning for us . \u201d\nFacebook is finally warming up to the idea that it must bear some responsibility for the content its users are sharing , but the question remains : What form does that responsibility take ? \u201c Until this election , our focus was on helping people share , \u201d Schrage explained . \u201c This election forced us to question whether we have a role in assessing the validity of content people share . And I have to tell you all , and one of the reasons I came here\u2014that \u2019 s a pretty damn scary role to play. \u201d And Facebook isn \u2019 t wrong to be worried . A user-based approach sounds nice in theory\u2014letting Facebook users flag posts they deem to be \u201c fake \u201d \u2014but placing that much faith in Facebook users would almost inevitably backfire . For one , such power could easily be weaponized online by users who dislike or disagree with a certain outlet \u2019 s perspective , manipulating Facebook to eliminate or hide credible news stories . The very act of labeling verified news stories , which Schrage suggested , could also backfire in the age of Trump , when so much of the populace distrusts establishment sources .",
    "content_original": "The utopian dream of the Internet as a place to connect the world and share ideas appears to have found its nemesis not in censorship, as some early Web pioneers feared, but in the proliferation of fake news, an even more pernicious form of misinformation, perfectly designed to take advantage of the viral nature of the open Web. The question of what social-media companies should do, if anything, to combat its spread has been vexing. Earlier this year, Facebook came under fire for allegedly suppressing conservative stories in the trending-news section of its platform, which had been maintained and curated by human editors. The fallout was swift: forced to address the situation, Facebook at first denied any bias, then replaced its employees with software that purportedly could do the same job. The algorithm, not surprisingly, was less perceptive than its human predecessors.\n\nFake news began appearing with increased frequency in the trending-news bar, potentially misleading many millions of Facebook\u2019s 1.79 billion monthly active users. Even more concerning was the spread of misleading stories shared by users themselves: according to one analysis by BuzzFeed News, in the last three months of the 2016 election, fake-news stories significantly outperformed real news stories across the social-media network. Many reportedly originated in Eastern Europe, where entrepreneurial teens and hostile foreign intelligence agencies alike fed a seemingly insatiable appetite for disinformation about America\u2019s two deeply-disliked presidential candidates.\n\nSince Donald Trump won the election, shocking most political observers, C.E.O. Mark Zuckerberg has found himself on the defensive over the role fake news might have played in enabling the former reality-TV star\u2019s rise from political punchline to president-elect. In less than two weeks, Zuckerberg went from arguing that it is \u201cpretty crazy\u201d to suggest that fake news on Facebook was at all responsible for Trump\u2019s surprising electoral success, to posting a more nuanced mea culpa, in which he wrote that the company takes \u201cmisinformation seriously\u201d and that Facebook is taking steps to address the problem.\n\nIn spite of its best efforts, however, Facebook may never be able to truly eradicate fake news on its platform, and not for lack of trying. Elliot Schrage, Facebook\u2019s vice president of global communications, marketing, and public policy, said as much at a talk at Harvard on Wednesday evening. \u201cFor so long, we had resisted having standards about whether something\u2019s newsworthy because we did not consider ourselves a service that was predominantly for the distribution of news,\u201d Schrage said. \u201cAnd that was wrong! We have a responsibility here. I think we recognize that. This has been a learning for us.\u201d\n\nFacebook is finally warming up to the idea that it must bear some responsibility for the content its users are sharing, but the question remains: What form does that responsibility take? \u201cUntil this election, our focus was on helping people share,\u201d Schrage explained. \u201cThis election forced us to question whether we have a role in assessing the validity of content people share. And I have to tell you all, and one of the reasons I came here\u2014that\u2019s a pretty damn scary role to play.\u201d And Facebook isn\u2019t wrong to be worried. A user-based approach sounds nice in theory\u2014letting Facebook users flag posts they deem to be \u201cfake\u201d\u2014but placing that much faith in Facebook users would almost inevitably backfire. For one, such power could easily be weaponized online by users who dislike or disagree with a certain outlet\u2019s perspective, manipulating Facebook to eliminate or hide credible news stories. The very act of labeling verified news stories, which Schrage suggested, could also backfire in the age of Trump, when so much of the populace distrusts establishment sources.",
    "source_url": "www.vanityfair.com",
    "bias_text": "left",
    "ID": "072KeBrT2b0K3HPy"
}