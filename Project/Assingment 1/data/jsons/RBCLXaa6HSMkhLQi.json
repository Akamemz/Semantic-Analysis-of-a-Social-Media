{
    "topic": "media_bias",
    "source": "Slate",
    "bias": 0,
    "url": "http://www.slate.com/articles/technology/technology/2016/05/yes_facebook_is_biased_now_it_should_admit_it.html",
    "title": "Of Course Facebook Is Biased",
    "date": "2016-05-10",
    "authors": "Will Oremus",
    "content": "Facebook must have thought the online news game was pretty easy . Two years ago , it plucked a small team of about a dozen bright , hungry twentysomethings fresh out of journalism school or entry-level reporting jobs . It stuck them in a basement , paid them contractor wages , and put them to work selecting and briefly summarizing the day \u2019 s top news stories and linking to the news sites that covered them . It called them curators , not reporters . Their work appeared in the \u201c Trending \u201d section of the Facebook home page and mobile app , where it helped to define the day \u2019 s news for millions of Facebook users .\nThat is , by any reasonable definition , a form of journalism . And it made Facebook a de facto news organization .\nBut Facebook refused to acknowledge that . It never bothered to reckon with the basic responsibilities that journalism entails , nor the ethical and epistemological challenges it presents\u2014probably because they \u2019 re messy and inconvenient and might get in the way of optimizing engagement . And now it \u2019 s paying the price .\nOn Tuesday , Facebook became the subject of a Senate inquiry over claims of anti-conservative bias in its Trending section . Senate Commerce Committee Chairman John Thune , a South Dakota Republican , sent Mark Zuckerberg a letter asking a series of pointed questions about how Facebook chooses stories for the section , how it trains its curators , who \u2019 s responsible for their decisions , and what steps it \u2019 s taking to investigate the bias claims . He also asks for detailed records of stories that the company decided not to include in the Trending section despite their popularity among Facebook users .\nThe inquiry followed a report by Gizmodo \u2019 s Michael Nunez on Monday , in which anonymous former Facebook \u201c curators \u201d described the subjective process by which they assembled the Trending section . Facebook had publicly portrayed the section\u2014which you can find near the top right of Facebook.com or under the search tab on the Facebook app\u2014as an algorithmically driven reflection of the most popular stories its users are reading at any given time . But the ex-curators said they often filtered out stories that were deemed questionable and added others they deemed worthy . One , a self-identified conservative , complained that this led to subtle yet pervasive liberal bias , since most of the curators were politically liberal themselves . Popular stories from conservative sites such as Breitbart , for instance , were allegedly omitted unless more mainstream publications such as the New York Times also picked them up .\nNone of this should come as a surprise to any thoughtful person who has worked as a journalist . Humans are biased . Objectivity is a myth , or at best an ideal that can be loosely approached through the very careful practice of trained professionals . The news simply is not neutral . Neither is \u201c curation , \u201d for that matter , in either the journalistic or artistic application of the term .\nTrending helps to define the day \u2019 s news for millions of Facebook users .\nThere are ways to grapple with this problem honestly\u2014to attempt to identify and correct for one \u2019 s biases , to scrupulously disclose them , to employ an ideologically diverse staff , perhaps even to reject objectivity as an ideal and embrace subjectivity . But you can \u2019 t begin to address the subjective nature of news without first acknowledging it . And Facebook has gone out of its way to avoid doing that , for reasons that are central to its identity as a technology company .\nHere \u2019 s how Facebook answers the question \u201c How does Facebook determine what topics are trending ? \u201d on its own help page :\nTrending shows you topics that have recently become popular on Facebook . The topics you see are based on a number of factors including engagement , timeliness , Pages you \u2019 ve liked and your location .\nNo mention of humans or subjectivity there . Similarly , Facebook told the tech blog Recode in 2015 that the Trending section was algorithmic , i.e. , that the stories were selected automatically by a computer program :\nOnce a topic is identified as trending , it \u2019 s approved by an actual human being , who also writes a short description for the story . These people don \u2019 t get to pick what Facebook adds to the trending section . That \u2019 s done automatically by the algorithm . They just get to pick the headline .\nBias in the selection of stories and sources ? Impossible . It \u2019 s all done \u201c automatically , \u201d by \u201c the algorithm \u201d ! Which is as good as saying \u201c by magic , \u201d for all it reveals about the process .\nIt \u2019 s not hard to fathom why Facebook is so determined to portray itself as objective . With more than 1.6 billion active users , it \u2019 s larger than any political party or movement in the world . And its wildly profitable $ 340 billion business is predicated on its near-universal appeal . You don \u2019 t get that big by taking sides .\nFor that matter , you don \u2019 t get that big by admitting that you \u2019 re a media company . As the New York Times \u2019 John Herrman and Mike Isaac point out , 65 percent of Americans surveyed by Pew view the news media as a \u201c negative influence on the country. \u201d For technology companies , that number is just 17 percent . It \u2019 s very much in Facebook \u2019 s interest to remain a social network in the public \u2019 s eyes , even in the face of mounting evidence that it \u2019 s something much bigger than that . And it \u2019 s in Facebook \u2019 s interest to shift responsibility for controversial decisions from humans , whom we know to be biased , to algorithms , which we tend to lionize .\nBut algorithms aren \u2019 t magic . They \u2019 re built by humans , they \u2019 re maintained and updated and overseen by humans , and they \u2019 re flawed like humans . Most importantly , they \u2019 re built to serve human ambitions , which are inherently subjective . I wrote in depth earlier this year about the human values and decisions that shape Facebook \u2019 s news feed algorithm . It \u2019 s built to execute goals that range from maximizing user engagement to making users feel good about the time they spend on Facebook .\nTrending is written by \u201c curators \u201d hired to summarize the news .\nHuman values shape the Trending section , too . The algorithm that surfaces the stories might skirt questions of bias by simply ranking them in order of popularity , thus delegating responsibility for story selection from Facebook \u2019 s employees to its users . Even that\u2014the notion that what \u2019 s popular is worth highlighting\u2014represents a human value judgment , albeit one that \u2019 s not particularly vulnerable to accusations of political bias . ( That \u2019 s why Twitter isn \u2019 t in the same hot water over its own simpler trending topics module . )\nThe problem with an algorithm that simply harnesses the wisdom of the crowd is that the crowd isn \u2019 t always wise . The most popular stories at any given time might well be misleading , or sensationalist , or even full of lies . That \u2019 s why Facebook felt the need to hire humans to oversee it . This is in keeping with the company \u2019 s broader push for what it calls quality content , another term that entails value judgments without copping to them .\nFacebook \u2019 s instinct to hire journalists was well-placed : As I \u2019 ve explained , no algorithm yet devised can fully substitute for a good human writer or editor .\nBut Facebook instead opted to hire cheap contractors and went on to claim that their role is simply to \u201c confirm that the topics are in fact trending news in the real world and not , for example , similar-sounding topics or misnomers. \u201d That \u2019 s a dubious claim , even if you think the allegations of liberal bias are trumped up . If the curators \u2019 job was really just about cleaning up the data , Facebook seems to have forgotten to tell that to the curators themselves , who described their mandate very differently to Gizmodo . They said they were encouraged to prioritize stories from certain outlets deemed reputable ; to avoid news about , among other topics , Facebook itself ; and to replace the word Twitter in headlines with something more vague , like social media . That may not be political bias , but it \u2019 s bias all the same . They also described choosing stories for the Trending section that may not have been surfaced by the algorithm but that seemed to them to be important or worthwhile , like stories about conflict in Syria or the Black Lives Matter movement .\nFacebook can and will dispute the specifics of these claims , as the company \u2019 s vice president of search , Tom Stocky , did in a Facebook post Tuesday morning . But they \u2019 re missing the point entirely . Facebook \u2019 s problem is not that its \u201c curators \u201d are biased . Facebook \u2019 s problem is that it refuses to admit that they \u2019 re biased\u2014or even really human .\nThe Senate inquiry is pure political theater , a delicious opportunity for Republican politicians to fuel conservatives \u2019 media-persecution complex . It is likely to answer few questions and solve fewer still . Yet Facebook brought this on itself by deliberately obscuring the process behind its Trending section and pretending to have a neutrality that its underpaid nonemployees couldn \u2019 t possibly earn .\nThe problem will not be solved by firing bad apples or instituting tougher guidelines . The only way for Facebook to extricate itself from this mess is to admit that journalism isn \u2019 t as simple as it thought . It \u2019 s to stop treating \u201c curators \u201d like drones and stop treating news like a data set to be optimized . It \u2019 s to build a real human curation team with a real editor in charge and an ethos and a mission and an understanding of the responsibilities involved in shaping how the news is framed to 1.6 billion people . Surely a company that pays its interns $ 11,000 a month in salary and benefits can afford it .\nEither that or\u2014what is more likely , given Facebook \u2019 s distaste for human judgment and fear of controversy\u2014take the humans back out of the loop . Turn Trending into the pure algorithmic leaderboard that Facebook pretended it was all along , and accept that it will be quite possibly be riddled with sensationalist junk . Or dispense with it entirely in its current form and bring it back later as a feature of the main news feed .\nEven that won \u2019 t remove all the bias from your Facebook feed , because that \u2019 s impossible . It will simply bury that bias deep within the company \u2019 s proprietary machine-learning algorithms , where real journalists can \u2019 t get at it .",
    "content_original": "Mark Zuckerberg is learning that online news isn\u2019t so simple. The Facebook founder and chief executive receiving the Axel Springer Award in Berlin on Feb. 25, 2016. Kay Nietfeld/Getty Images\n\nFacebook must have thought the online news game was pretty easy. Two years ago, it plucked a small team of about a dozen bright, hungry twentysomethings fresh out of journalism school or entry-level reporting jobs. It stuck them in a basement, paid them contractor wages, and put them to work selecting and briefly summarizing the day\u2019s top news stories and linking to the news sites that covered them. It called them curators, not reporters. Their work appeared in the \u201cTrending\u201d section of the Facebook home page and mobile app, where it helped to define the day\u2019s news for millions of Facebook users.\n\nThat is, by any reasonable definition, a form of journalism. And it made Facebook a de facto news organization.\n\nBut Facebook refused to acknowledge that. It never bothered to reckon with the basic responsibilities that journalism entails, nor the ethical and epistemological challenges it presents\u2014probably because they\u2019re messy and inconvenient and might get in the way of optimizing engagement. And now it\u2019s paying the price.\n\nOn Tuesday, Facebook became the subject of a Senate inquiry over claims of anti-conservative bias in its Trending section. Senate Commerce Committee Chairman John Thune, a South Dakota Republican, sent Mark Zuckerberg a letter asking a series of pointed questions about how Facebook chooses stories for the section, how it trains its curators, who\u2019s responsible for their decisions, and what steps it\u2019s taking to investigate the bias claims. He also asks for detailed records of stories that the company decided not to include in the Trending section despite their popularity among Facebook users.\n\nThe inquiry followed a report by Gizmodo\u2019s Michael Nunez on Monday, in which anonymous former Facebook \u201ccurators\u201d described the subjective process by which they assembled the Trending section. Facebook had publicly portrayed the section\u2014which you can find near the top right of Facebook.com or under the search tab on the Facebook app\u2014as an algorithmically driven reflection of the most popular stories its users are reading at any given time. But the ex-curators said they often filtered out stories that were deemed questionable and added others they deemed worthy. One, a self-identified conservative, complained that this led to subtle yet pervasive liberal bias, since most of the curators were politically liberal themselves. Popular stories from conservative sites such as Breitbart, for instance, were allegedly omitted unless more mainstream publications such as the New York Times also picked them up.\n\nNone of this should come as a surprise to any thoughtful person who has worked as a journalist. Humans are biased. Objectivity is a myth, or at best an ideal that can be loosely approached through the very careful practice of trained professionals. The news simply is not neutral. Neither is \u201ccuration,\u201d for that matter, in either the journalistic or artistic application of the term.\n\nTrending helps to define the day\u2019s news for millions of Facebook users.\n\nThere are ways to grapple with this problem honestly\u2014to attempt to identify and correct for one\u2019s biases, to scrupulously disclose them, to employ an ideologically diverse staff, perhaps even to reject objectivity as an ideal and embrace subjectivity. But you can\u2019t begin to address the subjective nature of news without first acknowledging it. And Facebook has gone out of its way to avoid doing that, for reasons that are central to its identity as a technology company.\n\nHere\u2019s how Facebook answers the question \u201cHow does Facebook determine what topics are trending?\u201d on its own help page:\n\nTrending shows you topics that have recently become popular on Facebook. The topics you see are based on a number of factors including engagement, timeliness, Pages you\u2019ve liked and your location.\n\nNo mention of humans or subjectivity there. Similarly, Facebook told the tech blog Recode in 2015 that the Trending section was algorithmic, i.e., that the stories were selected automatically by a computer program:\n\nOnce a topic is identified as trending, it\u2019s approved by an actual human being, who also writes a short description for the story. These people don\u2019t get to pick what Facebook adds to the trending section. That\u2019s done automatically by the algorithm. They just get to pick the headline.\n\nBias in the selection of stories and sources? Impossible. It\u2019s all done \u201cautomatically,\u201d by \u201cthe algorithm\u201d! Which is as good as saying \u201cby magic,\u201d for all it reveals about the process.\n\nIt\u2019s not hard to fathom why Facebook is so determined to portray itself as objective. With more than 1.6 billion active users, it\u2019s larger than any political party or movement in the world. And its wildly profitable $340 billion business is predicated on its near-universal appeal. You don\u2019t get that big by taking sides.\n\nFor that matter, you don\u2019t get that big by admitting that you\u2019re a media company. As the New York Times\u2019 John Herrman and Mike Isaac point out, 65 percent of Americans surveyed by Pew view the news media as a \u201cnegative influence on the country.\u201d For technology companies, that number is just 17 percent. It\u2019s very much in Facebook\u2019s interest to remain a social network in the public\u2019s eyes, even in the face of mounting evidence that it\u2019s something much bigger than that. And it\u2019s in Facebook\u2019s interest to shift responsibility for controversial decisions from humans, whom we know to be biased, to algorithms, which we tend to lionize.\n\nBut algorithms aren\u2019t magic. They\u2019re built by humans, they\u2019re maintained and updated and overseen by humans, and they\u2019re flawed like humans. Most importantly, they\u2019re built to serve human ambitions, which are inherently subjective. I wrote in depth earlier this year about the human values and decisions that shape Facebook\u2019s news feed algorithm. It\u2019s built to execute goals that range from maximizing user engagement to making users feel good about the time they spend on Facebook.\n\nTrending is written by \u201ccurators\u201d hired to summarize the news.\n\nHuman values shape the Trending section, too. The algorithm that surfaces the stories might skirt questions of bias by simply ranking them in order of popularity, thus delegating responsibility for story selection from Facebook\u2019s employees to its users. Even that\u2014the notion that what\u2019s popular is worth highlighting\u2014represents a human value judgment, albeit one that\u2019s not particularly vulnerable to accusations of political bias. (That\u2019s why Twitter isn\u2019t in the same hot water over its own simpler trending topics module.)\n\nThe problem with an algorithm that simply harnesses the wisdom of the crowd is that the crowd isn\u2019t always wise. The most popular stories at any given time might well be misleading, or sensationalist, or even full of lies. That\u2019s why Facebook felt the need to hire humans to oversee it. This is in keeping with the company\u2019s broader push for what it calls quality content, another term that entails value judgments without copping to them.\n\nFacebook\u2019s instinct to hire journalists was well-placed: As I\u2019ve explained, no algorithm yet devised can fully substitute for a good human writer or editor.\n\nBut Facebook instead opted to hire cheap contractors and went on to claim that their role is simply to \u201cconfirm that the topics are in fact trending news in the real world and not, for example, similar-sounding topics or misnomers.\u201d That\u2019s a dubious claim, even if you think the allegations of liberal bias are trumped up. If the curators\u2019 job was really just about cleaning up the data, Facebook seems to have forgotten to tell that to the curators themselves, who described their mandate very differently to Gizmodo. They said they were encouraged to prioritize stories from certain outlets deemed reputable; to avoid news about, among other topics, Facebook itself; and to replace the word Twitter in headlines with something more vague, like social media. That may not be political bias, but it\u2019s bias all the same. They also described choosing stories for the Trending section that may not have been surfaced by the algorithm but that seemed to them to be important or worthwhile, like stories about conflict in Syria or the Black Lives Matter movement.\n\nFacebook can and will dispute the specifics of these claims, as the company\u2019s vice president of search, Tom Stocky, did in a Facebook post Tuesday morning. But they\u2019re missing the point entirely. Facebook\u2019s problem is not that its \u201ccurators\u201d are biased. Facebook\u2019s problem is that it refuses to admit that they\u2019re biased\u2014or even really human.\n\nThe Senate inquiry is pure political theater, a delicious opportunity for Republican politicians to fuel conservatives\u2019 media-persecution complex. It is likely to answer few questions and solve fewer still. Yet Facebook brought this on itself by deliberately obscuring the process behind its Trending section and pretending to have a neutrality that its underpaid nonemployees couldn\u2019t possibly earn.\n\nThe problem will not be solved by firing bad apples or instituting tougher guidelines. The only way for Facebook to extricate itself from this mess is to admit that journalism isn\u2019t as simple as it thought. It\u2019s to stop treating \u201ccurators\u201d like drones and stop treating news like a data set to be optimized. It\u2019s to build a real human curation team with a real editor in charge and an ethos and a mission and an understanding of the responsibilities involved in shaping how the news is framed to 1.6 billion people. Surely a company that pays its interns $11,000 a month in salary and benefits can afford it.\n\nEither that or\u2014what is more likely, given Facebook\u2019s distaste for human judgment and fear of controversy\u2014take the humans back out of the loop. Turn Trending into the pure algorithmic leaderboard that Facebook pretended it was all along, and accept that it will be quite possibly be riddled with sensationalist junk. Or dispense with it entirely in its current form and bring it back later as a feature of the main news feed.\n\nEven that won\u2019t remove all the bias from your Facebook feed, because that\u2019s impossible. It will simply bury that bias deep within the company\u2019s proprietary machine-learning algorithms, where real journalists can\u2019t get at it.",
    "source_url": "www.slate.com",
    "bias_text": "left",
    "ID": "RBCLXaa6HSMkhLQi"
}