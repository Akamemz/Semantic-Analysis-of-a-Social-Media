{
    "topic": "media_bias",
    "source": "Nieman Lab",
    "bias": 1,
    "url": "https://www.niemanlab.org/2020/07/biased-algorithms-on-platforms-like-youtube-hurt-people-looking-for-information-on-health/",
    "title": "Biased algorithms on platforms like YouTube hurt people looking for information on health",
    "date": "",
    "authors": "Anjana Susarla, Sarah Scire, Caroline Crampton, Damian Radcliffe, Laura Hazard Owen, \"Hanaa Tameez\"",
    "content": "The Health Information National Trends Survey reports that 75 % of Americans go to the internet first when looking for information about health or medical topics . YouTube is one of the most popular online platforms , with billions of views every day , and has emerged as a significant source of health information .\nSeveral public health agencies , such as state health departments , have invested resources in YouTube as a channel for health communication . Patients with chronic health conditions especially rely on social media , including YouTube videos , to learn more about how to manage their conditions .\nBut video recommendations on such sites could exacerbate preexisting disparities in health .\nA significant fraction of the U.S. population is estimated to have limited health literacy , or the capacity to obtain , process and understand basic health information , such as the ability to read and comprehend prescription bottles , appointment slips or discharge instructions from health clinics .\nStudies of health literacy , such as the National Assessment of Adult Literacy conducted in 2003 , estimated that only 12 % of adults had proficient health literacy skills . This has been corroborated in subsequent studies .\nI \u2019 m a professor of information systems , and my own research has examined how social media platforms such as YouTube widen such health literacy disparities by steering users toward questionable content .\nExtracting thousands of videos purporting to be about diabetes , I verified whether the information shown conforms to valid medical guidelines .\nI found that the most popular and engaging videos are significantly less likely to have medically valid information .\nUsers typically encounter videos on health conditions through keyword searches on YouTube . YouTube then provides links to authenticated medical information , such as the top-ranked results . Several of these are produced by reputable health organizations .\nRecently , YouTube has adjusted how search results are displayed , allowing results to be ranked by \u201c relevance \u201d and providing links to verified medical information .\nHowever , when I recruited physicians to watch the videos and rate them on whether these would be considered valid and understandable from a patient education perspective , they rated YouTube \u2019 s recommendations poorly .\nI found that the most popular videos are the ones that tend to have easily understandable information but are not always medically valid . A study on the most popular videos on COVID-19 likewise found that a quarter of videos did not contain medically valid information .\nThis is because the algorithms \u2019 underlying recommendations on social media platforms are biased toward engagement and popularity .\nBased on how digital platforms provide information to search queries , a user with greater health literacy is more likely to discover usable medical advice from a reputed health care provider , such as the Mayo Clinic . The same algorithm will steer a less literate user toward fake cures or misleading medical advice .\nThis could be especially harmful for minority groups . Studies of health literacy in the United States have found that the impact of limited health literacy disproportionately impacts minorities .\nWe do not have enough studies on the state of health literacy among minority populations , especially in urban areas . That makes it challenging to design health communication aimed at minorities , and interventions to improve the utilization of existing health care resources .\nThere can also be cultural barriers regarding health care in minority populations that exacerbate the literacy barriers . Insufficient education and lack of self-management of chronic care have also been highlighted as challenges for minorities .\nCorrecting algorithmic biases and providing better information to users of technology platforms would go a long way in promoting equity .\nFor example , a pioneering study by the Gender Shades project examined disparities in identifying gender and skin type across different companies that provide commercial facial recognition software . It concluded that companies were able to make progress in reducing these disparities once issues were pointed out .\nAccording to some estimates , Google receives over a billion health questions everyday . Especially those with low health literacy have a substantial risk of encountering medically unsubstantiated information , such as popular myths or active conspiracy theories that are not based on scientific evidence .\nThe World Economic Forum has dubbed health-related misinformation an \u201c infodemic. \u201d Digital platforms where anyone can engage also make them vulnerable to misinformation , accentuating disparities in health literacy , as my own work shows .\nSocial media and search companies have partnered with health organizations such as the Mayo Clinic to provide validated information and reduce the spread of misinformation . To make health information on YouTube more equitable , those who design recommendation algorithms would have to incorporate feedback from clinicians and patients as well as end users .\nAnjana Susarla is a professor of information systems at Michigan State University . This article is republished from The Conversation under a Creative Commons license .",
    "content_original": "YouTube hosts millions of videos related to health care.\n\nThe Health Information National Trends Survey reports that 75% of Americans go to the internet first when looking for information about health or medical topics. YouTube is one of the most popular online platforms, with billions of views every day, and has emerged as a significant source of health information.\n\nSeveral public health agencies, such as state health departments, have invested resources in YouTube as a channel for health communication. Patients with chronic health conditions especially rely on social media, including YouTube videos, to learn more about how to manage their conditions.\n\nBut video recommendations on such sites could exacerbate preexisting disparities in health.\n\nA significant fraction of the U.S. population is estimated to have limited health literacy, or the capacity to obtain, process and understand basic health information, such as the ability to read and comprehend prescription bottles, appointment slips or discharge instructions from health clinics.\n\nStudies of health literacy, such as the National Assessment of Adult Literacy conducted in 2003, estimated that only 12% of adults had proficient health literacy skills. This has been corroborated in subsequent studies.\n\nI\u2019m a professor of information systems, and my own research has examined how social media platforms such as YouTube widen such health literacy disparities by steering users toward questionable content.\n\nOn YouTube\n\nExtracting thousands of videos purporting to be about diabetes, I verified whether the information shown conforms to valid medical guidelines.\n\nI found that the most popular and engaging videos are significantly less likely to have medically valid information.\n\nUsers typically encounter videos on health conditions through keyword searches on YouTube. YouTube then provides links to authenticated medical information, such as the top-ranked results. Several of these are produced by reputable health organizations.\n\nRecently, YouTube has adjusted how search results are displayed, allowing results to be ranked by \u201crelevance\u201d and providing links to verified medical information.\n\nHowever, when I recruited physicians to watch the videos and rate them on whether these would be considered valid and understandable from a patient education perspective, they rated YouTube\u2019s recommendations poorly.\n\nI found that the most popular videos are the ones that tend to have easily understandable information but are not always medically valid. A study on the most popular videos on COVID-19 likewise found that a quarter of videos did not contain medically valid information.\n\nThe health literacy divide\n\nThis is because the algorithms\u2019 underlying recommendations on social media platforms are biased toward engagement and popularity.\n\nBased on how digital platforms provide information to search queries, a user with greater health literacy is more likely to discover usable medical advice from a reputed health care provider, such as the Mayo Clinic. The same algorithm will steer a less literate user toward fake cures or misleading medical advice.\n\nThis could be especially harmful for minority groups. Studies of health literacy in the United States have found that the impact of limited health literacy disproportionately impacts minorities.\n\nWe do not have enough studies on the state of health literacy among minority populations, especially in urban areas . That makes it challenging to design health communication aimed at minorities, and interventions to improve the utilization of existing health care resources.\n\nThere can also be cultural barriers regarding health care in minority populations that exacerbate the literacy barriers. Insufficient education and lack of self-management of chronic care have also been highlighted as challenges for minorities.\n\nAlgorithmic biases\n\nCorrecting algorithmic biases and providing better information to users of technology platforms would go a long way in promoting equity.\n\nFor example, a pioneering study by the Gender Shades project examined disparities in identifying gender and skin type across different companies that provide commercial facial recognition software. It concluded that companies were able to make progress in reducing these disparities once issues were pointed out.\n\nAccording to some estimates, Google receives over a billion health questions everyday. Especially those with low health literacy have a substantial risk of encountering medically unsubstantiated information, such as popular myths or active conspiracy theories that are not based on scientific evidence.\n\nThe World Economic Forum has dubbed health-related misinformation an \u201cinfodemic.\u201d Digital platforms where anyone can engage also make them vulnerable to misinformation, accentuating disparities in health literacy, as my own work shows.\n\nSocial media and search companies have partnered with health organizations such as the Mayo Clinic to provide validated information and reduce the spread of misinformation. To make health information on YouTube more equitable, those who design recommendation algorithms would have to incorporate feedback from clinicians and patients as well as end users.\n\nAnjana Susarla is a professor of information systems at Michigan State University. This article is republished from The Conversation under a Creative Commons license.",
    "source_url": "www.niemanlab.org",
    "bias_text": "center",
    "ID": "X2hZJB1lTQURPbLv"
}