{
    "topic": "media_bias",
    "source": "Politico",
    "bias": 0,
    "url": "https://www.politico.com/story/2019/06/25/media-2020-misinformation-1378849",
    "title": "'It's kind of the Wild West': Media gears up for onslaught of deepfakes",
    "date": "2019-06-25",
    "authors": "Michael Calderone",
    "content": "YouTube removed the \u201c drunk \u201d House Speaker Nancy Pelosi video last month \u2014 which had been slowed to make it appear she was slurring her words \u2014 while Facebook allowed it to stay up . | J. Scott Applewhite/AP Photo Media 'It 's kind of the Wild West ' : Media gears up for onslaught of deepfakes A low-tech doctored clip of House Speaker Nancy Pelosi last month spotlighted the growing challenge of combating misinformation this election season .\nA video of Republican Mitt Romney saying in 2012 that 47 percent of Americans were dependent on the government helped sink his presidential bid , and an unearthed clip of President Donald Trump bragging about grabbing women shook up the 2016 campaign .\nIn 2020 , the race could again be rattled by video that emerges of candidates \u2014 but this time , media organizations are worried about being able to tell if it \u2019 s real .\nNews organizations are taking steps to tackle the problem of deepfakes , videos created through artificial intelligence technology to appear to show someone saying or doing things that never occurred . A more low-tech doctored clip , or \u201c cheapfake , \u201d of House Speaker Nancy Pelosi last month that tried to make her appear drunk spotlighted the growing challenge of combating misinformation this election season .\nIn an effort to prevent questionable clips from duping reporters , Reuters created its own deepfakes as a training exercise to see if journalists could tell they weren \u2019 t real . The Wall Street Journal \u2019 s ethics & standards and research & development teams launched a committee last fall to tackle the problem of doctored video , studying forensic technologies for identifying fakes and asking journalists to flag suspicious content .\nAnd on Tuesday , the Washington Post will launch a public-facing \u201c Fact Checker 's Guide to Manipulated Video , \u201d which will try to help voters spot misleading material by classifying videos into three categories : \u201c Missing Context , \u201d \u201c Deceptive Editing , \u201d and \u201c Malicious Transformation , \u201d which includes deepfakes .\nCOUNTDOWN TO 2020 The race for 2020 starts now . Stay in the know . Follow our presidential election coverage . Email Sign Up By signing up you agree to receive email newsletters or alerts from \u2588\u2588\u2588 . You can unsubscribe at any time .\nThe Washington Post \u2019 s Glenn Kessler said in an interview that his concern is \u201c extremely high \u201d that manipulated videos could be used to mislead the public .\n\u201c You \u2019 re just waiting for that kind of bomb to explode , \u201d Kessler told \u2588\u2588\u2588 . \u201c So , we \u2019 re trying to get ahead of these things . \u201d\nFrancesco Marconi , the Journal \u2019 s research and development chief , told \u2588\u2588\u2588 that media organizations will likely struggle to stay on top of what \u2019 s real and what \u2019 s fake in 2020 . Some methods of spotting fakes already appear obsolete as the technology to make them has progressed . For instance , people in early deepfakes didn \u2019 t blink ; now they can . And once-blurry backgrounds are crisper .\nSo-called fake news permeated the 2016 campaign , some of it spread intentionally by Russian-sponsored social media trolls as part of an effort to disrupt the election , special counsel Robert Mueller found . But advances in video editing and artificial intelligence software have made it even easier to create counterfeit clips .\nComplicating matters , major tech companies haven \u2019 t adopted consistent standards for dealing with such false material .\nYouTube removed the \u201c drunk \u201d Pelosi video last month \u2014 which had been slowed to make it appear she was slurring her words \u2014 while Facebook allowed it to stay up . Recently , Facebook-owned Instagram opted not to remove a deepfake video that purported to show Facebook chief Mark Zuckerberg bragging about controlling \u201c stolen data . \u201d\nInstagram head Adam Mosseri acknowledged Tuesday on \u201c CBS This Morning \u201d that \u201c we don \u2019 t have a policy against deepfakes currently . \u201d\nTwo academics wrote an essay for Harvard University \u2019 s Nieman Lab describing seven hypothetical scenarios in which manipulated video and audio could disrupt the 2020 election and even cast doubt on the democratic process itself . The scenarios ranged from relatively benign , such as supporters doctoring video to boost a candidate \u2019 s record , to more destabilizing , such as suppressing votes by telling Americans that fake videos of them engaged in incriminating behaviors will be released if they go to the polls .\nThe Post \u2019 s editorial board recently urged the government \u201c to invest in developing technology to detect deepfakes. \u201d And fears about this confusing new world prompted the first Congressional hearing on the matter this month .\n\u201c Thinking ahead to 2020 and beyond , one does not need any great imagination to envision even more nightmarish scenarios that would leave the government , the media , and the public struggling to discern what is real and what is fake , '' said House Intelligence Chairman Adam Schiff ( D-Calif. ) .\nHany Farid , a University of California , Berkeley professor and digital forensics expert , demonstrated software last week on CBS that he \u2019 s creating to detect altered videos and which he said could eventually be used by the news media .\nFarid told \u2588\u2588\u2588 he isn \u2019 t currently \u201c working with any specific news organizations , \u201d but \u201c as we roll out our analysis tools , we hope to begin to work with a range of organizations . \u201d\nThe WSJ \u2019 s Marconi told \u2588\u2588\u2588 that \u201c by 2020 , there will be massive proliferation \u201d of deepfakes , so the paper wanted to be proactive in addressing them . He said the Journal \u2019 s committee serves as a newsroom resource in providing training , webinars and arranging guest speakers on the topic .\n`` This is an issue the entire newsroom takes very seriously , \u201d Washington bureau chief Paul Beckett said in a statement . \u201c All of our reporters covering the 2020 campaigns are being trained to be aware of the potential for deep fakes . ''\nAnd Kessler and Nadine Ajaka , a senior video producer at the Post who is working with Kessler \u2019 s team , said they hope the Post \u2019 s classification system will prompt major platforms like YouTube to alert viewers when videos are found to have been manipulated .\n\u201c When you name something , it \u2019 s less terrifying , \u201d said Ajaka . The classification system , she added , is a step toward giving the public a greater understanding of \u201c a world in which you can \u2019 t trust everything you see . \u201d\n\u201c Right now , it \u2019 s kind of the Wild West , \u201d she said .",
    "content_original": "YouTube removed the \u201cdrunk\u201d House Speaker Nancy Pelosi video last month \u2014 which had been slowed to make it appear she was slurring her words \u2014 while Facebook allowed it to stay up. | J. Scott Applewhite/AP Photo Media 'It's kind of the Wild West': Media gears up for onslaught of deepfakes A low-tech doctored clip of House Speaker Nancy Pelosi last month spotlighted the growing challenge of combating misinformation this election season.\n\nA video of Republican Mitt Romney saying in 2012 that 47 percent of Americans were dependent on the government helped sink his presidential bid, and an unearthed clip of President Donald Trump bragging about grabbing women shook up the 2016 campaign.\n\nIn 2020, the race could again be rattled by video that emerges of candidates \u2014 but this time, media organizations are worried about being able to tell if it\u2019s real.\n\nStory Continued Below\n\nNews organizations are taking steps to tackle the problem of deepfakes, videos created through artificial intelligence technology to appear to show someone saying or doing things that never occurred. A more low-tech doctored clip, or \u201ccheapfake,\u201d of House Speaker Nancy Pelosi last month that tried to make her appear drunk spotlighted the growing challenge of combating misinformation this election season.\n\nIn an effort to prevent questionable clips from duping reporters, Reuters created its own deepfakes as a training exercise to see if journalists could tell they weren\u2019t real. The Wall Street Journal\u2019s ethics & standards and research & development teams launched a committee last fall to tackle the problem of doctored video, studying forensic technologies for identifying fakes and asking journalists to flag suspicious content.\n\nAnd on Tuesday, the Washington Post will launch a public-facing \u201cFact Checker's Guide to Manipulated Video,\u201d which will try to help voters spot misleading material by classifying videos into three categories: \u201cMissing Context,\u201d \u201cDeceptive Editing,\u201d and \u201cMalicious Transformation,\u201d which includes deepfakes.\n\nCOUNTDOWN TO 2020 The race for 2020 starts now. Stay in the know. Follow our presidential election coverage. Email Sign Up By signing up you agree to receive email newsletters or alerts from POLITICO. You can unsubscribe at any time.\n\nThe Washington Post\u2019s Glenn Kessler said in an interview that his concern is \u201cextremely high\u201d that manipulated videos could be used to mislead the public.\n\n\u201cYou\u2019re just waiting for that kind of bomb to explode,\u201d Kessler told POLITICO. \u201cSo, we\u2019re trying to get ahead of these things.\u201d\n\nFrancesco Marconi, the Journal\u2019s research and development chief, told POLITICO that media organizations will likely struggle to stay on top of what\u2019s real and what\u2019s fake in 2020. Some methods of spotting fakes already appear obsolete as the technology to make them has progressed. For instance, people in early deepfakes didn\u2019t blink; now they can. And once-blurry backgrounds are crisper.\n\n\u201cIt\u2019s a cat and mouse game,\u201d he said.\n\nSo-called fake news permeated the 2016 campaign, some of it spread intentionally by Russian-sponsored social media trolls as part of an effort to disrupt the election, special counsel Robert Mueller found. But advances in video editing and artificial intelligence software have made it even easier to create counterfeit clips.\n\nComplicating matters, major tech companies haven\u2019t adopted consistent standards for dealing with such false material.\n\nposter=\"http://v.politico.com/images/1155968404/201905/3355/1155968404_6042757706001_6042755175001-vs.jpg?pubId=1155968404\"\n\nYouTube removed the \u201cdrunk\u201d Pelosi video last month \u2014 which had been slowed to make it appear she was slurring her words \u2014 while Facebook allowed it to stay up. Recently, Facebook-owned Instagram opted not to remove a deepfake video that purported to show Facebook chief Mark Zuckerberg bragging about controlling \u201cstolen data.\u201d\n\nInstagram head Adam Mosseri acknowledged Tuesday on \u201cCBS This Morning\u201d that \u201cwe don\u2019t have a policy against deepfakes currently.\u201d\n\nTwo academics wrote an essay for Harvard University\u2019s Nieman Lab describing seven hypothetical scenarios in which manipulated video and audio could disrupt the 2020 election and even cast doubt on the democratic process itself. The scenarios ranged from relatively benign, such as supporters doctoring video to boost a candidate\u2019s record, to more destabilizing, such as suppressing votes by telling Americans that fake videos of them engaged in incriminating behaviors will be released if they go to the polls.\n\nThe Post\u2019s editorial board recently urged the government \u201cto invest in developing technology to detect deepfakes.\u201d And fears about this confusing new world prompted the first Congressional hearing on the matter this month.\n\n\u201cThinking ahead to 2020 and beyond, one does not need any great imagination to envision even more nightmarish scenarios that would leave the government, the media, and the public struggling to discern what is real and what is fake,\" said House Intelligence Chairman Adam Schiff (D-Calif.).\n\nHany Farid, a University of California, Berkeley professor and digital forensics expert, demonstrated software last week on CBS that he\u2019s creating to detect altered videos and which he said could eventually be used by the news media.\n\nFarid told POLITICO he isn\u2019t currently \u201cworking with any specific news organizations,\u201d but \u201cas we roll out our analysis tools, we hope to begin to work with a range of organizations.\u201d\n\nThe WSJ\u2019s Marconi told POLITICO that \u201cby 2020, there will be massive proliferation\u201d of deepfakes, so the paper wanted to be proactive in addressing them. He said the Journal\u2019s committee serves as a newsroom resource in providing training, webinars and arranging guest speakers on the topic.\n\n\"This is an issue the entire newsroom takes very seriously,\u201d Washington bureau chief Paul Beckett said in a statement. \u201cAll of our reporters covering the 2020 campaigns are being trained to be aware of the potential for deep fakes.\"\n\nAnd Kessler and Nadine Ajaka, a senior video producer at the Post who is working with Kessler\u2019s team, said they hope the Post\u2019s classification system will prompt major platforms like YouTube to alert viewers when videos are found to have been manipulated.\n\n\u201cWhen you name something, it\u2019s less terrifying,\u201d said Ajaka. The classification system, she added, is a step toward giving the public a greater understanding of \u201ca world in which you can\u2019t trust everything you see.\u201d\n\n\u201cRight now, it\u2019s kind of the Wild West,\u201d she said.\n\n",
    "source_url": "www.politico.com",
    "bias_text": "left",
    "ID": "YEfAydLYaNuyJnMM"
}