{
    "topic": "media_bias",
    "source": "Grist",
    "bias": 0,
    "url": "http://grist.org/politics/science-confirms-politics-wrecks-your-ability-to-do-math/",
    "title": "Science confirms: Politics wrecks your ability to do math",
    "date": "2013-09-08",
    "authors": "Chris Mooney",
    "content": "Everybody knows that our political views can sometimes get in the way of thinking clearly . But perhaps we don \u2019 t realize how bad the problem actually is . According to a new psychology paper , our political passions can even undermine our very basic reasoning skills . More specifically , the study finds that people who are otherwise very good at math may totally flunk a problem that they would otherwise probably be able to solve , simply because giving the right answer goes against their political beliefs .\nThe study , by Yale law professor Dan Kahan and his colleagues , has an ingenious design . At the outset , 1,111 study participants were asked about their political views and also asked a series of questions designed to gauge their \u201c numeracy , \u201d that is , their mathematical reasoning ability . Participants were then asked to solve a fairly difficult problem that involved interpreting the results of a ( fake ) scientific study . But here was the trick : While the fake study data that they were supposed to assess remained the same , sometimes the study was described as measuring the effectiveness of a \u201c new cream for treating skin rashes. \u201d But in other cases , the study was described as involving the effectiveness of \u201c a law banning private citizens from carrying concealed handguns in public . \u201d\nThe result ? Survey respondents performed wildly differently on what was in essence the same basic problem , simply depending upon whether they had been told that it involved guns or whether they had been told that it involved a new skin cream . What \u2019 s more , it turns out that highly numerate liberals and conservatives were even more \u2014 not less \u2014 susceptible to letting politics skew their reasoning than were those with less mathematical ability .\nBut we \u2019 re getting a little ahead of ourselves \u2014 to fully grasp the Enlightenment-destroying nature of these results , we first need to explore the tricky problem that the study presented in a little bit more detail .\nLet \u2019 s start with the \u201c skin cream \u201d version of this brain twister . You can peruse the image below to see exactly what research subjects read ( and try out your own skill at solving it ) , or skip on for a brief explanation :\nAs you can see above , the survey respondents were presented with a fictional study purporting to assess the effectiveness of a new skin cream , and informed at the outset that \u201c new treatments often work but sometimes make rashes worse \u201d and that \u201c even when treatments don \u2019 t work , skin rashes sometimes get better and sometimes get worse on their own. \u201d They were then presented with a table of experimental results , and asked whether the data showed that the new skin cream \u201c is likely to make the skin condition better or worse . \u201d\nSo do the data suggest that the skin cream works ? The correct answer in the scenario above is actually that patients who used the skin cream were \u201c more likely to get worse than those who didn \u2019 t. \u201d That \u2019 s because the ratio of those who saw their rash improve to those whose rash got worse is roughly 3 to 1 in the \u201c skin cream \u201d group , but roughly 5 to 1 in the control group \u2014 which means that if you want your rash to get better , you are better off not using the skin cream at all . ( For half of study subjects asked to solve the skin cream problem , the data were reversed and presented in such a way that they did actually suggest that the skin cream works . )\nThis is no easy problem for most people to solve : Across all conditions of the study , 59 percent of respondents got the answer wrong . That is , in significant part , because trying to intuit the right answer by quickly comparing two numbers will lead you astray ; you have to take the time to compute the ratios .\nNot surprisingly , Kahan \u2019 s study found that the more numerate you are , the more likely you are to get the answer to this \u201c skin cream \u201d problem right . Moreover , it found no substantial difference between highly numerate Democrats and highly numerate Republicans in this regard . The better members of both political groups were at math , the better they were at solving the skin cream problem .\nBut now take the same basic study design and data , and simply label it differently . Rather than reading about a skin cream study , half of Kahan \u2019 s research subjects were asked to determine the effectiveness of laws \u201c banning private citizens from carrying concealed handguns in public. \u201d Accordingly , these respondents were presented not with data about rashes and whether they got better or worse , but rather with data about cities that had or hadn \u2019 t passed concealed carry bans , and whether crime in these cities had or had not decreased .\nOverall , then , study respondents were presented with one of four possible scenarios , depicted below with the correct answer in bold :\nSo how did people fare on the handgun version of the problem ? They performed quite differently than on the skin cream version , and strong political patterns emerged in the results \u2014 especially among people who are good at mathematical reasoning . Most strikingly , highly numerate liberal Democrats did almost perfectly when the right answer was that the concealed weapons ban does indeed work to decrease crime ( version C of the experiment ) \u2014 an outcome that favors their pro-gun-control predilections . But they did much worse when the correct answer was that crime increases in cities that enact the ban ( version D of the experiment ) .\nThe opposite was true for highly numerate conservative Republicans : They did just great when the right answer was that the ban didn \u2019 t work ( version D ) , but poorly when the right answer was that it did ( version C ) .\nHere are the results overall , comparing subjects \u2019 performances on the \u201c skin cream \u201d versions of the problem ( above ) and the \u201c gun ban \u201d versions of the problem ( below ) , and relating this performance to their political affiliations and numeracy scores :\nFor study author Kahan , these results are a fairly strong refutation of what is called the \u201c deficit model \u201d in the field of science and technology studies \u2014 the idea that if people just had more knowledge , or more reasoning ability , then they would be better able to come to consensus with scientists and experts on issues like climate change , evolution , the safety of vaccines , and pretty much anything else involving science or data ( for instance , whether concealed weapons bans work ) . Kahan \u2019 s data suggest the opposite \u2014 that political biases skew our reasoning abilities , and this problem seems to be worse for people with advanced capacities like scientific literacy and numeracy . \u201c If the people who have the greatest capacities are the ones most prone to this , that \u2019 s reason to believe that the problem isn \u2019 t some kind of deficit in comprehension , \u201d Kahan explained in an interview .\nSo what are smart , numerate liberals and conservatives actually doing in the gun control version of the study , leading them to give such disparate answers ? It \u2019 s kind of tricky , but here \u2019 s what Kahan thinks is happening .\nOur first instinct , in all versions of the study , is to leap instinctively to the wrong conclusion . If you just compare which number is bigger in the first column , for instance , you \u2019 ll be quickly led astray . But more numerate people , when they sense an apparently wrong answer that offends their political sensibilities , are both motivated and equipped to dig deeper , think harder , and even start performing some calculations \u2014 which in this case would have led to a more accurate response .\n\u201c If the wrong answer is contrary to their ideological positions , we hypothesize that that is going to create the incentive to scrutinize that information and figure out another way to understand it , \u201d says Kahan . In other words , more numerate people perform better when identifying study results that support their views \u2014 but may have a big blind spot when it comes to identifying results that undermine those views .\nWhat \u2019 s happening when highly numerate liberals and conservatives actually get it wrong ? Either they \u2019 re intuiting an incorrect answer that is politically convenient and feels right to them , leading them to inquire no further \u2014 or else they \u2019 re stopping to calculate the correct answer , but then refusing to accept it and coming up with some elaborate reason why 1 + 1 doesn \u2019 t equal 2 in this particular instance . ( Kahan suspects it \u2019 s mostly the former , rather than the latter . )\nThe Scottish Enlightenment philosopher David Hume famously described reason as a \u201c slave of the passions. \u201d Today \u2019 s political scientists and political psychologists , like Kahan , are now affirming Hume \u2019 s statement with reams of new data . This new study is just one out of many in this respect , but it provides perhaps the most striking demonstration yet of just how motivated , just how biased , reasoning can be \u2014 especially about politics .\nThis story was produced as part of the Climate Desk collaboration .",
    "content_original": "Everybody knows that our political views can sometimes get in the way of thinking clearly. But perhaps we don\u2019t realize how bad the problem actually is. According to a new psychology paper, our political passions can even undermine our very basic reasoning skills. More specifically, the study finds that people who are otherwise very good at math may totally flunk a problem that they would otherwise probably be able to solve, simply because giving the right answer goes against their political beliefs.\n\nThe study, by Yale law professor Dan Kahan and his colleagues, has an ingenious design. At the outset, 1,111 study participants were asked about their political views and also asked a series of questions designed to gauge their \u201cnumeracy,\u201d that is, their mathematical reasoning ability. Participants were then asked to solve a fairly difficult problem that involved interpreting the results of a (fake) scientific study. But here was the trick: While the fake study data that they were supposed to assess remained the same, sometimes the study was described as measuring the effectiveness of a \u201cnew cream for treating skin rashes.\u201d But in other cases, the study was described as involving the effectiveness of \u201ca law banning private citizens from carrying concealed handguns in public.\u201d\n\nThe result? Survey respondents performed wildly differently on what was in essence the same basic problem, simply depending upon whether they had been told that it involved guns or whether they had been told that it involved a new skin cream. What\u2019s more, it turns out that highly numerate liberals and conservatives were even more \u2014 not less \u2014 susceptible to letting politics skew their reasoning than were those with less mathematical ability.\n\nBut we\u2019re getting a little ahead of ourselves \u2014 to fully grasp the Enlightenment-destroying nature of these results, we first need to explore the tricky problem that the study presented in a little bit more detail.\n\nLet\u2019s start with the \u201cskin cream\u201d version of this brain twister. You can peruse the image below to see exactly what research subjects read (and try out your own skill at solving it), or skip on for a brief explanation:\n\nAs you can see above, the survey respondents were presented with a fictional study purporting to assess the effectiveness of a new skin cream, and informed at the outset that \u201cnew treatments often work but sometimes make rashes worse\u201d and that \u201ceven when treatments don\u2019t work, skin rashes sometimes get better and sometimes get worse on their own.\u201d They were then presented with a table of experimental results, and asked whether the data showed that the new skin cream \u201cis likely to make the skin condition better or worse.\u201d\n\nSo do the data suggest that the skin cream works? The correct answer in the scenario above is actually that patients who used the skin cream were \u201cmore likely to get worse than those who didn\u2019t.\u201d That\u2019s because the ratio of those who saw their rash improve to those whose rash got worse is roughly 3 to 1 in the \u201cskin cream\u201d group, but roughly 5 to 1 in the control group \u2014 which means that if you want your rash to get better, you are better off not using the skin cream at all. (For half of study subjects asked to solve the skin cream problem, the data were reversed and presented in such a way that they did actually suggest that the skin cream works.)\n\nThis is no easy problem for most people to solve: Across all conditions of the study, 59 percent of respondents got the answer wrong. That is, in significant part, because trying to intuit the right answer by quickly comparing two numbers will lead you astray; you have to take the time to compute the ratios.\n\nNot surprisingly, Kahan\u2019s study found that the more numerate you are, the more likely you are to get the answer to this \u201cskin cream\u201d problem right. Moreover, it found no substantial difference between highly numerate Democrats and highly numerate Republicans in this regard. The better members of both political groups were at math, the better they were at solving the skin cream problem.\n\nBut now take the same basic study design and data, and simply label it differently. Rather than reading about a skin cream study, half of Kahan\u2019s research subjects were asked to determine the effectiveness of laws \u201cbanning private citizens from carrying concealed handguns in public.\u201d Accordingly, these respondents were presented not with data about rashes and whether they got better or worse, but rather with data about cities that had or hadn\u2019t passed concealed carry bans, and whether crime in these cities had or had not decreased.\n\nOverall, then, study respondents were presented with one of four possible scenarios, depicted below with the correct answer in bold:\n\nSo how did people fare on the handgun version of the problem? They performed quite differently than on the skin cream version, and strong political patterns emerged in the results \u2014 especially among people who are good at mathematical reasoning. Most strikingly, highly numerate liberal Democrats did almost perfectly when the right answer was that the concealed weapons ban does indeed work to decrease crime (version C of the experiment) \u2014 an outcome that favors their pro-gun-control predilections. But they did much worse when the correct answer was that crime increases in cities that enact the ban (version D of the experiment).\n\nThe opposite was true for highly numerate conservative Republicans: They did just great when the right answer was that the ban didn\u2019t work (version D), but poorly when the right answer was that it did (version C).\n\nHere are the results overall, comparing subjects\u2019 performances on the \u201cskin cream\u201d versions of the problem (above) and the \u201cgun ban\u201d versions of the problem (below), and relating this performance to their political affiliations and numeracy scores:\n\nFor study author Kahan, these results are a fairly strong refutation of what is called the \u201cdeficit model\u201d in the field of science and technology studies \u2014 the idea that if people just had more knowledge, or more reasoning ability, then they would be better able to come to consensus with scientists and experts on issues like climate change, evolution, the safety of vaccines, and pretty much anything else involving science or data (for instance, whether concealed weapons bans work). Kahan\u2019s data suggest the opposite \u2014 that political biases skew our reasoning abilities, and this problem seems to be worse for people with advanced capacities like scientific literacy and numeracy. \u201cIf the people who have the greatest capacities are the ones most prone to this, that\u2019s reason to believe that the problem isn\u2019t some kind of deficit in comprehension,\u201d Kahan explained in an interview.\n\nSo what are smart, numerate liberals and conservatives actually doing in the gun control version of the study, leading them to give such disparate answers? It\u2019s kind of tricky, but here\u2019s what Kahan thinks is happening.\n\nOur first instinct, in all versions of the study, is to leap instinctively to the wrong conclusion. If you just compare which number is bigger in the first column, for instance, you\u2019ll be quickly led astray. But more numerate people, when they sense an apparently wrong answer that offends their political sensibilities, are both motivated and equipped to dig deeper, think harder, and even start performing some calculations \u2014 which in this case would have led to a more accurate response.\n\n\u201cIf the wrong answer is contrary to their ideological positions, we hypothesize that that is going to create the incentive to scrutinize that information and figure out another way to understand it,\u201d says Kahan. In other words, more numerate people perform better when identifying study results that support their views \u2014 but may have a big blind spot when it comes to identifying results that undermine those views.\n\nWhat\u2019s happening when highly numerate liberals and conservatives actually get it wrong? Either they\u2019re intuiting an incorrect answer that is politically convenient and feels right to them, leading them to inquire no further \u2014 or else they\u2019re stopping to calculate the correct answer, but then refusing to accept it and coming up with some elaborate reason why 1 + 1 doesn\u2019t equal 2 in this particular instance. (Kahan suspects it\u2019s mostly the former, rather than the latter.)\n\nThe Scottish Enlightenment philosopher David Hume famously described reason as a \u201cslave of the passions.\u201d Today\u2019s political scientists and political psychologists, like Kahan, are now affirming Hume\u2019s statement with reams of new data. This new study is just one out of many in this respect, but it provides perhaps the most striking demonstration yet of just how motivated, just how biased, reasoning can be \u2014 especially about politics.\n\nThis story was produced as part of the Climate Desk collaboration.",
    "source_url": "www.grist.org",
    "bias_text": "left",
    "ID": "hsB2ob0EsCIvdmwS"
}