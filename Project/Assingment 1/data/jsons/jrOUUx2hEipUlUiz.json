{
    "topic": "media_bias",
    "source": "The Conversation",
    "bias": 1,
    "url": "https://theconversation.com/how-fake-accounts-constantly-manipulate-what-you-see-on-social-media-and-what-you-can-do-about-it-139610",
    "title": "How fake accounts constantly manipulate what you see on social media \u2013 and what you can do about it",
    "date": "2020-06-24",
    "authors": "Jeanna Matthews",
    "content": "Social media platforms like Facebook , Twitter and Instagram started out as a way to connect with friends , family and people of interest . But anyone on social media these days knows it \u2019 s increasingly a divisive landscape .\nUndoubtedly you \u2019 ve heard reports that hackers and even foreign governments are using social media to manipulate and attack you . You may wonder how that is possible . As a professor of computer science who researches social media and security , I can explain \u2013 and offer some ideas for what you can do about it .\nSocial media platforms don \u2019 t simply feed you the posts from the accounts you follow . They use algorithms to curate what you see based in part on \u201c likes \u201d or \u201c votes. \u201d A post is shown to some users , and the more those people react \u2013 positively or negatively \u2013 the more it will be highlighted to others . Sadly , lies and extreme content often garner more reactions and so spread quickly and widely .\nBut who is doing this \u201c voting \u201d ? Often it \u2019 s an army of accounts , called bots , that do not correspond to real people . In fact , they \u2019 re controlled by hackers , often on the other side of the world . For example , researchers have reported that more than half of the Twitter accounts discussing COVID-19 are bots .\nAs a social media researcher , I \u2019 ve seen thousands of accounts with the same profile picture \u201c like \u201d posts in unison . I \u2019 ve seen accounts post hundreds of times per day , far more than a human being could . I \u2019 ve seen an account claiming to be an \u201c All-American patriotic army wife \u201d from Florida post obsessively about immigrants in English , but whose account history showed it used to post in Ukranian .\nFake accounts like this are called \u201c sock puppets \u201d \u2013 suggesting a hidden hand speaking through another identity . In many cases , this deception can easily be revealed with a look at the account history . But in some cases , there is a big investment in making sock puppet accounts seem real .\nFor example , Jenna Abrams , an account with 70,000 followers , was quoted by mainstream media outlets like The New York Times for her xenophobic and far-right opinions , but was actually an invention controlled by the Internet Research Agency , a Russian government-funded troll farm and not a living , breathing person .\nTrolls often don \u2019 t care about the issues as much as they care about creating division and distrust . For example , researchers in 2018 concluded that some of the most influential accounts on both sides of divisive issues , like Black Lives Matter and Blue Lives Matter , were controlled by troll farms .\nMore than just fanning disagreement , trolls want to encourage a belief that truth no longer exists . Divide and conquer . Distrust anyone who might serve as a leader or trusted voice . Cut off the head . Demoralize . Confuse . Each of these is a devastating attack strategy .\nEven as a social media researcher , I underestimate the degree to which my opinion is shaped by these attacks . I think I am smart enough to read what I want , discard the rest and step away unscathed . Still , when I see a post that has millions of likes , part of me thinks it must reflect public opinion . The social media feeds I see are affected by it and , what \u2019 s more , I am affected by the opinions of my real friends , who are also influenced .\nThe entire society is being subtly manipulated to believe they are on opposite sides of many issues when legitimate common ground exists .\nI have focused primarily on U.S.-based examples , but the same types of attacks are playing out around the world . By turning the voices of democracies against each other , authoritarian regimes may begin to look preferable to chaos .\nPlatforms have been slow to act . Sadly , misinformation and disinformation drives usage and is good for business . Failure to act has often been justified with concerns about freedom of speech . Does freedom of speech include the right to create 100,000 fake accounts with the express purpose of spreading lies , division and chaos ?\nSo what can you do about it ? You probably already know to check the sources and dates of what you read and forward , but common-sense media literacy advice is not enough .\nFirst , use social media more deliberately . Choose to catch up with someone in particular , rather than consuming only the default feed . You might be amazed to see what you \u2019 ve been missing . Help your friends and family find your posts by using features like pinning key messages to the top of your feed .\nSecond , pressure social media platforms to remove accounts with clear signs of automation . Ask for more controls to manage what you see and which posts are amplified . Ask for more transparency in how posts are promoted and who is placing ads . For example , complain directly about the Facebook news feed here or tell legislators about your concerns .\nThird , be aware of the trolls \u2019 favorite issues and be skeptical of them . They may be most interested in creating chaos , but they also show clear preferences on some issues . For example , trolls want to reopen economies quickly without real management to flatten the COVID-19 curve . They also clearly supported one of the 2016 U.S. presidential candidates over the other . It \u2019 s worth asking yourself how these positions might be good for Russian trolls , but bad for you and your family .\nPerhaps most importantly , use social media sparingly , like any other addictive , toxic substance , and invest in more real-life community building conversations . Listen to real people , real stories and real opinions , and build from there .\n[ You \u2019 re smart and curious about the world . So are \u2588\u2588\u2588 \u2019 s authors and editors . You can get our highlights each weekend . ]",
    "content_original": "Social media platforms like Facebook, Twitter and Instagram started out as a way to connect with friends, family and people of interest. But anyone on social media these days knows it\u2019s increasingly a divisive landscape.\n\nUndoubtedly you\u2019ve heard reports that hackers and even foreign governments are using social media to manipulate and attack you. You may wonder how that is possible. As a professor of computer science who researches social media and security, I can explain \u2013 and offer some ideas for what you can do about it.\n\nBots and sock puppets\n\nSocial media platforms don\u2019t simply feed you the posts from the accounts you follow. They use algorithms to curate what you see based in part on \u201clikes\u201d or \u201cvotes.\u201d A post is shown to some users, and the more those people react \u2013 positively or negatively \u2013 the more it will be highlighted to others. Sadly, lies and extreme content often garner more reactions and so spread quickly and widely.\n\nBut who is doing this \u201cvoting\u201d? Often it\u2019s an army of accounts, called bots, that do not correspond to real people. In fact, they\u2019re controlled by hackers, often on the other side of the world. For example, researchers have reported that more than half of the Twitter accounts discussing COVID-19 are bots.\n\nAs a social media researcher, I\u2019ve seen thousands of accounts with the same profile picture \u201clike\u201d posts in unison. I\u2019ve seen accounts post hundreds of times per day, far more than a human being could. I\u2019ve seen an account claiming to be an \u201cAll-American patriotic army wife\u201d from Florida post obsessively about immigrants in English, but whose account history showed it used to post in Ukranian.\n\nFake accounts like this are called \u201csock puppets\u201d \u2013 suggesting a hidden hand speaking through another identity. In many cases, this deception can easily be revealed with a look at the account history. But in some cases, there is a big investment in making sock puppet accounts seem real.\n\nFor example, Jenna Abrams, an account with 70,000 followers, was quoted by mainstream media outlets like The New York Times for her xenophobic and far-right opinions, but was actually an invention controlled by the Internet Research Agency, a Russian government-funded troll farm and not a living, breathing person.\n\nSowing chaos\n\nTrolls often don\u2019t care about the issues as much as they care about creating division and distrust. For example, researchers in 2018 concluded that some of the most influential accounts on both sides of divisive issues, like Black Lives Matter and Blue Lives Matter, were controlled by troll farms.\n\nMore than just fanning disagreement, trolls want to encourage a belief that truth no longer exists. Divide and conquer. Distrust anyone who might serve as a leader or trusted voice. Cut off the head. Demoralize. Confuse. Each of these is a devastating attack strategy.\n\nEven as a social media researcher, I underestimate the degree to which my opinion is shaped by these attacks. I think I am smart enough to read what I want, discard the rest and step away unscathed. Still, when I see a post that has millions of likes, part of me thinks it must reflect public opinion. The social media feeds I see are affected by it and, what\u2019s more, I am affected by the opinions of my real friends, who are also influenced.\n\nThe entire society is being subtly manipulated to believe they are on opposite sides of many issues when legitimate common ground exists.\n\nI have focused primarily on U.S.-based examples, but the same types of attacks are playing out around the world. By turning the voices of democracies against each other, authoritarian regimes may begin to look preferable to chaos.\n\nPlatforms have been slow to act. Sadly, misinformation and disinformation drives usage and is good for business. Failure to act has often been justified with concerns about freedom of speech. Does freedom of speech include the right to create 100,000 fake accounts with the express purpose of spreading lies, division and chaos?\n\nTaking control\n\nSo what can you do about it? You probably already know to check the sources and dates of what you read and forward, but common-sense media literacy advice is not enough.\n\nFirst, use social media more deliberately. Choose to catch up with someone in particular, rather than consuming only the default feed. You might be amazed to see what you\u2019ve been missing. Help your friends and family find your posts by using features like pinning key messages to the top of your feed.\n\nSecond, pressure social media platforms to remove accounts with clear signs of automation. Ask for more controls to manage what you see and which posts are amplified. Ask for more transparency in how posts are promoted and who is placing ads. For example, complain directly about the Facebook news feed here or tell legislators about your concerns.\n\nThird, be aware of the trolls\u2019 favorite issues and be skeptical of them. They may be most interested in creating chaos, but they also show clear preferences on some issues. For example, trolls want to reopen economies quickly without real management to flatten the COVID-19 curve. They also clearly supported one of the 2016 U.S. presidential candidates over the other. It\u2019s worth asking yourself how these positions might be good for Russian trolls, but bad for you and your family.\n\nPerhaps most importantly, use social media sparingly, like any other addictive, toxic substance, and invest in more real-life community building conversations. Listen to real people, real stories and real opinions, and build from there.\n\n[You\u2019re smart and curious about the world. So are The Conversation\u2019s authors and editors. You can get our highlights each weekend.]",
    "source_url": "www.theconversation.com",
    "bias_text": "center",
    "ID": "jrOUUx2hEipUlUiz"
}