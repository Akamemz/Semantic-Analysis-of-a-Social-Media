{
    "topic": "fake_news",
    "source": "Christian Science Monitor",
    "bias": 1,
    "url": "http://www.csmonitor.com/Technology/2017/0124/A-novel-way-to-help-readers-spot-fake-news",
    "title": "A novel way to help readers spot fake news",
    "date": "2017-01-24",
    "authors": "Patrick Reilly",
    "content": "The old saying \u201c forewarned is forearmed \u201d applies to the fight against fake news .\nPutting a short , contextualizing message before spurious news stories can keep readers from accepting their claims , according to a paper published Monday in the journal Global Challenges .\nThe paper \u2019 s authors \u2013 Anthony Leiserowitz and Seth Rosenthal at Yale University ; Sander van der Linden at Churchill College , Cambridge , England ; and Edward Maibach at George Mason University \u2013 wanted to investigate public understanding of the scientific consensus that humans are causing climate change .\nTo this end , they divided a national sample of the American public into six different groups . Several of them read the Oregon Petition , which claims to have received the signatures of more than 31,000 climate-skeptic scientists \u2013 and which Professor Leiserowitz calls a \u201c classic piece of disinformation. \u201d Some of its signatories include the long-deceased Charles Darwin and members of the Spice Girls .\nWith the help of social media , sketchy information like this often gets taken as fact , circulates freely , and causes widespread damage before it \u2019 s debunked . The researchers say they \u2019 ve found a solution , but it \u2019 s up to newsreaders and the media to adopt it .\n\u201c You can inoculate against the effects of fake news , \u201d Leiserowitz , director of the Yale Program on Climate Change Communication , tells The \u2588\u2588\u2588 in a phone interview . He and his colleagues gave one group just the petition . Another group instead viewed a pie chart showing that , in reality , 97 percent of climate scientists agree that humans are driving climate change . A third group saw the pie chart , then read the bogus petition .\nTwo other groups read the petition after reading what Leiserowitz calls \u201c inoculations : \u201d warnings that politically motivated groups try to use misleading tactics to raise doubts among the public about the scientific consensus , along with specific warnings about the Oregon Petition , followed by the pie chart . \u201d If you can give people a little pre-awareness that what they are likely to hear is bogus , you can inoculate against disinformation , \u201d he says .\nThe pie charts served that role . Leiserowitz explains that \u201c when we give both messages \u201d \u2013 the petition and the pie chart \u2013 \u201c side-by-side , they basically cancel each other out , \u201d and that perceptions of the \u201c scientific consensus \u201d did not change . But when readers read inoculation messages before the fake Oregon petition , their own estimate of the degree of scientific consensus still increased . The effect , the researchers noted , was similar \u201c across political party affiliation . \u201d\nThis means that such \u201c inoculations \u201d can help preserve the truth \u2013 and not just with scientific stories . Professor Leiserowitz suggested that similar warnings could also have helped rebut false claims the number of attendees at President Trump \u2019 s inauguration before they gained traction .\nBut these messages will only work if news organizations use them . Some news websites have doubled down on their commitment to fact-checking : The Washington Post , for instance , recently introduced a Twitter plug-in that checks the veracity of Mr. Trump \u2019 s tweets in real time .\nBut readers of other publications may be less receptive to these messages . Leiserowitz acknowledged that many news sites \u201c basically say , \u2018 Do not trust any information that comes from outside news sources .... ' That increasingly walls us off from one another . \u201d\nJack Zhou , an instructor in environmental politics at Duke University in Durham , N.C. , says some occupants of so-called \u201c news bubbles \u201d may prefer to accept fake news as truth . \u201c The state of fragmented media may dull the potential practical impact of inoculation messages , particularly in terms of the audiences serviced by those media , \u201d Mr. Zhou , who has researched the identity politics of climate change , tells the Monitor in an email .\nSocial-media giant Facebook recognizes this as a problem . After chief executive officer Mark Zuckerberg initially denied that Facebook \u2019 s carrying fake news was harming public discourse , the company announced a campaign to detect and flag unfounded stories .\nThe campaign was announced in mid-December , before the inoculation paper was published . But it also fights fake news by putting it in context . Facebook has partnered with online fact-checking services to spot dubious links . TechCrunch reports that , when they find one , Facebook will `` show posts of those links lower in the News Feed . It will also attach a warning label noting 'Disputed by [ one or more of the fact checkers ] ' with a link to the debunking post on News Feed stories and in the status composer if users are about to share a dubious link . ''\nGet the Monitor Stories you care about delivered to your inbox . By signing up , you agree to our Privacy Policy\nThe same article reported that 44 percent of US adults get news from Facebook . The study of inoculation messages released Monday suggests that its plan to flag and debunk fake news could keep those users from accepting it \u2013 if they click at all after seeing a warning label .\nThat , in turn , could benefit civic discourse . Without a broadly accepted set of facts , Professor Leiserowitz explains , \u201c it gets harder and harder to have rational conversations . \u201d",
    "content_original": "The old saying \u201cforewarned is forearmed\u201d applies to the fight against fake news.\n\nPutting a short, contextualizing message before spurious news stories can keep readers from accepting their claims, according to a paper published Monday in the journal Global Challenges.\n\nThe paper\u2019s authors \u2013 Anthony Leiserowitz and Seth Rosenthal at Yale University; Sander van der Linden at Churchill College, Cambridge, England; and Edward Maibach at George Mason University \u2013 wanted to investigate public understanding of the scientific consensus that humans are causing climate change.\n\nTo this end, they divided a national sample of the American public into six different groups. Several of them read the Oregon Petition, which claims to have received the signatures of more than 31,000 climate-skeptic scientists \u2013 and which Professor Leiserowitz calls a \u201cclassic piece of disinformation.\u201d Some of its signatories include the long-deceased Charles Darwin and members of the Spice Girls.\n\nWith the help of social media, sketchy information like this often gets taken as fact, circulates freely, and causes widespread damage before it\u2019s debunked. The researchers say they\u2019ve found a solution, but it\u2019s up to newsreaders and the media to adopt it.\n\n\u201cYou can inoculate against the effects of fake news,\u201d Leiserowitz, director of the Yale Program on Climate Change Communication, tells The Christian Science Monitor in a phone interview. He and his colleagues gave one group just the petition. Another group instead viewed a pie chart showing that, in reality, 97 percent of climate scientists agree that humans are driving climate change. A third group saw the pie chart, then read the bogus petition.\n\nTwo other groups read the petition after reading what Leiserowitz calls \u201cinoculations:\u201d warnings that politically motivated groups try to use misleading tactics to raise doubts among the public about the scientific consensus, along with specific warnings about the Oregon Petition, followed by the pie chart. \u201dIf you can give people a little pre-awareness that what they are likely to hear is bogus, you can inoculate against disinformation,\u201d he says.\n\nThe pie charts served that role. Leiserowitz explains that \u201cwhen we give both messages\u201d \u2013 the petition and the pie chart \u2013 \u201cside-by-side, they basically cancel each other out,\u201d and that perceptions of the \u201cscientific consensus\u201d did not change. But when readers read inoculation messages before the fake Oregon petition, their own estimate of the degree of scientific consensus still increased. The effect, the researchers noted, was similar \u201cacross political party affiliation.\u201d\n\nThis means that such \u201cinoculations\u201d can help preserve the truth \u2013 and not just with scientific stories. Professor Leiserowitz suggested that similar warnings could also have helped rebut false claims the number of attendees at President Trump\u2019s inauguration before they gained traction.\n\nBut these messages will only work if news organizations use them. Some news websites have doubled down on their commitment to fact-checking: The Washington Post, for instance, recently introduced a Twitter plug-in that checks the veracity of Mr. Trump\u2019s tweets in real time.\n\nBut readers of other publications may be less receptive to these messages. Leiserowitz acknowledged that many news sites \u201cbasically say, \u2018Do not trust any information that comes from outside news sources....' That increasingly walls us off from one another.\u201d\n\nJack Zhou, an instructor in environmental politics at Duke University in Durham, N.C., says some occupants of so-called \u201cnews bubbles\u201d may prefer to accept fake news as truth. \u201cThe state of fragmented media may dull the potential practical impact of inoculation messages, particularly in terms of the audiences serviced by those media,\u201d Mr. Zhou, who has researched the identity politics of climate change, tells the Monitor in an email.\n\nAfter all, sites with fake news are only catering to their audiences. Paul Levinson, a communications professor at Fordham University in New York, told the Monitor in December that, \u201cThese bubbles have not been imposed upon the public \u2013 it was what the people want. As long as social media continues to provide a very easy forum for these news bubbles ... it is not going to stop.\u201d [Editor's note: An earlier version of this story misspelled Mr. Levinson's first name.]\n\nSocial-media giant Facebook recognizes this as a problem. After chief executive officer Mark Zuckerberg initially denied that Facebook\u2019s carrying fake news was harming public discourse, the company announced a campaign to detect and flag unfounded stories.\n\nThe campaign was announced in mid-December, before the inoculation paper was published. But it also fights fake news by putting it in context. Facebook has partnered with online fact-checking services to spot dubious links. TechCrunch reports that, when they find one, Facebook will \"show posts of those links lower in the News Feed. It will also attach a warning label noting 'Disputed by [one or more of the fact checkers]' with a link to the debunking post on News Feed stories and in the status composer if users are about to share a dubious link.\"\n\nGet the Monitor Stories you care about delivered to your inbox. By signing up, you agree to our Privacy Policy\n\nThe same article reported that 44 percent of US adults get news from Facebook. The study of inoculation messages released Monday suggests that its plan to flag and debunk fake news could keep those users from accepting it \u2013 if they click at all after seeing a warning label.\n\nThat, in turn, could benefit civic discourse. Without a broadly accepted set of facts, Professor Leiserowitz explains, \u201cit gets harder and harder to have rational conversations.\u201d",
    "source_url": "www.csmonitor.com",
    "bias_text": "center",
    "ID": "vsnEhpcZFBYNj1L2"
}