{
    "topic": "race_and_racism",
    "source": "The Intercept",
    "bias": 0,
    "url": "https://theintercept.com/2020/06/03/amazon-police-racism-tech-black-lives-matter/",
    "title": "Amazon \u201cStands in Solidarity\u201d Against Police Racism While Selling Racist Tech to Police",
    "date": "2020-06-03",
    "authors": "",
    "content": "It is a week of renewed social crisis in the United States , which means American companies are quickly lining up to pay lip service to the cause . Just like its tech giant competitors at Facebook , Apple , and Google , Amazon tweeted vaguely in favor of the principles of social justice and equitable policing , a predictable and predictably tinny expression of corporate solidarity with \u201c the fight against systemic racism and injustice. \u201d But Amazon is arguably singular among its mega-tech peers in its determination to provide American law enforcement with tools experts say only enable racist policing .\nIn their rush to appear sympathetic to the rough contours of social justice \u2014 while keeping their legal , public relations , and social media teams in agreement \u2014 some companies seem to be forgetting what it is they actually do . When Nextdoor , a social network with a well-documented pattern of stoking the worst kinds of racial panic , tweets an image reading \u201c BLACK LIVES MATTER , \u201d it \u2019 s difficult to take seriously . But while Nextdoor is merely content to rationalize and streamline urban and suburban residential paranoia into a tidy algorithmic feed , a growing portion of Amazon \u2019 s business , as Wired \u2019 s Sidney Fussell noted yesterday , is expanding its public/private video surveillance dragnet across the country with an explicitly \u201c anti-crime \u201d mission .\n\u201c Surveillance is a racial justice issue . The two can not be separated . \u201d\nIn 2018 , the ACLU published a report showing that Amazon \u2019 s \u201c Rekognition \u201d facial recognition software was fundamentally racially biased , disproportionately misidentifying , in ACLU \u2019 s test , black members of Congress as people who were arrested and had their mugshot in a police database . \u201c The false matches were disproportionately of people of color , including six members of the Congressional Black Caucus , among them civil rights legend Rep. John Lewis ( D-Ga. ) , \u201d read the report . \u201c Nearly 40 percent of Rekognition \u2019 s false matches in our test were of people of color , even though they make up only 20 percent of Congress. \u201d A report published that same year by an MIT team found , similarly , that Rekognition misclassified darker-skinned women as men 31 percent of the time . The ACLU report added , \u201c People of color are already disproportionately harmed by police practices , and it \u2019 s easy to see how Rekognition could exacerbate that. \u201d As the ACLU and other artificial intelligence researchers have made clear , the threat of computerized misidentification isn \u2019 t just an academic error , but a potentially ruinous one that could improperly influence police officers prior to an encounter , or even cause them to seek a search warrant , by presenting them with a false criminal history . It \u2019 s difficult to reconcile this reality with a recent tweet from Amazon executive Andy Jassy , chief of Amazon Web Services , the cloud computing division which operates Rekognition :\n* What * will it take for us to refuse to accept these unjust killings of black people ? How many people must die , how many generations must endure , how much eyewitness video is required ? What else do we need ? We need better than what we 're getting from courts and political leaders . \u2014 Andy Jassy ( @ ajassy ) May 30 , 2020",
    "content_original": "Photo illustration: Soohee Cho/The Intercept, Getty Images\n\nIt is a week of renewed social crisis in the United States, which means American companies are quickly lining up to pay lip service to the cause. Just like its tech giant competitors at Facebook, Apple, and Google, Amazon tweeted vaguely in favor of the principles of social justice and equitable policing, a predictable and predictably tinny expression of corporate solidarity with \u201cthe fight against systemic racism and injustice.\u201d But Amazon is arguably singular among its mega-tech peers in its determination to provide American law enforcement with tools experts say only enable racist policing.\n\nIn their rush to appear sympathetic to the rough contours of social justice \u2014 while keeping their legal, public relations, and social media teams in agreement \u2014 some companies seem to be forgetting what it is they actually do. When Nextdoor, a social network with a well-documented pattern of stoking the worst kinds of racial panic, tweets an image reading \u201cBLACK LIVES MATTER,\u201d it\u2019s difficult to take seriously. But while Nextdoor is merely content to rationalize and streamline urban and suburban residential paranoia into a tidy algorithmic feed, a growing portion of Amazon\u2019s business, as Wired\u2019s Sidney Fussell noted yesterday, is expanding its public/private video surveillance dragnet across the country with an explicitly \u201canti-crime\u201d mission.\n\n\u201cSurveillance is a racial justice issue. The two cannot be separated.\u201d\n\nIn 2018, the ACLU published a report showing that Amazon\u2019s \u201cRekognition\u201d facial recognition software was fundamentally racially biased, disproportionately misidentifying, in ACLU\u2019s test, black members of Congress as people who were arrested and had their mugshot in a police database. \u201cThe false matches were disproportionately of people of color, including six members of the Congressional Black Caucus, among them civil rights legend Rep. John Lewis (D-Ga.),\u201d read the report. \u201cNearly 40 percent of Rekognition\u2019s false matches in our test were of people of color, even though they make up only 20 percent of Congress.\u201d A report published that same year by an MIT team found, similarly, that Rekognition misclassified darker-skinned women as men 31 percent of the time. The ACLU report added, \u201cPeople of color are already disproportionately harmed by police practices, and it\u2019s easy to see how Rekognition could exacerbate that.\u201d As the ACLU and other artificial intelligence researchers have made clear, the threat of computerized misidentification isn\u2019t just an academic error, but a potentially ruinous one that could improperly influence police officers prior to an encounter, or even cause them to seek a search warrant, by presenting them with a false criminal history. It\u2019s difficult to reconcile this reality with a recent tweet from Amazon executive Andy Jassy, chief of Amazon Web Services, the cloud computing division which operates Rekognition:\n\n*What* will it take for us to refuse to accept these unjust killings of black people? How many people must die, how many generations must endure, how much eyewitness video is required? What else do we need? We need better than what we're getting from courts and political leaders. \u2014 Andy Jassy (@ajassy) May 30, 2020",
    "source_url": "www.theintercept.com",
    "bias_text": "left",
    "ID": "BLEhBaxQaKeIbl2P"
}