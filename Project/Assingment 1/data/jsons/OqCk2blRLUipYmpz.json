{
    "topic": "coronavirus",
    "source": "The Atlantic",
    "bias": 0,
    "url": "https://www.theatlantic.com/technology/archive/2020/04/coronavirus-models-arent-supposed-be-right/609271/",
    "title": "Don\u2019t Believe the COVID-19 Models",
    "date": "2020-04-02",
    "authors": "Zeynep Tufekci",
    "content": "Exponential growth isn \u2019 t the only tricky part of epidemiological models . These models also need to use parameters to plug into the variables in the equations . But where should those parameters come from ? Model-makers have to work with the data they have , yet a novel virus , such as the one that causes COVID-19 , has a lot of unknowns .\nFor example , the Imperial College model uses numbers from Wuhan , China , along with some early data from Italy . This is a reasonable choice , as those are the pandemic \u2019 s largest epicenters . But many of these data are not yet settled , and many questions remain . What \u2019 s the attack rate\u2014the number of people who get infected within an exposed group , like a household ? Do people who recover have immunity ? How widespread are asymptomatic cases , and how infectious are they ? Are there super-spreaders\u2014people who seemingly infect everyone they breathe near\u2014as there were with SARS , and how prevalent are they ? What are the false positive and false negative rates of our tests ? And so on , and on and on .\nTo make models work , epidemiologists also have to estimate the impact of interventions like social isolation . But here , too , the limited data we have are imperfect , perhaps censored , perhaps inapplicable . For example , China underwent a period in which the government yanked infected patients and even their healthy close contacts from their homes , and sent them into special quarantine wards . That seems to have dramatically cut down infections within a household and within the city . Relatively few infected people in the United States or the United Kingdom have been similarly quarantined . In general , the lockdown in China was much more severe . Planes are still taking off from New York , New Jersey , and everywhere else , even as we speak of \u201c social isolation. \u201d And more complications remain . We aren \u2019 t even sure we can trust China \u2019 s numbers . Italy \u2019 s health statistics are likely more trustworthy , but its culture of furbizia\u2014or flouting the rules , part of the country \u2019 s charm as well as its dysfunction\u2014increases the difficulty of knowing how applicable its outcomes are to our projections .\nRead : The four possible timelines for life returning to normal\nA model \u2019 s robustness depends on how often it gets tried out and tweaked based on data and its performance . For example , many models predicting presidential elections are based on data from presidential elections since 1972 . That \u2019 s all the elections we have polling data for , but it \u2019 s only 12 elections , and prior to 2016 , only two happened in the era of Facebook . So when Donald Trump , the candidate that was projected to be less likely to win the presidency in 2016 , won anyway , did that mean that our models with TV-era parameters don \u2019 t work anymore ? Or is it merely that a less likely but possible outcome happened ? ( If you \u2019 re flipping a coin , you \u2019 ll get four heads in a row about one every 16 tries , meaning that you can \u2019 t know if the coin is loaded just because something seemingly unusual happens ) . With this novel coronavirus , there are a lot of things we don \u2019 t know because we \u2019 ve never tested our models , and we have no way to do so .",
    "content_original": "Exponential growth isn\u2019t the only tricky part of epidemiological models. These models also need to use parameters to plug into the variables in the equations. But where should those parameters come from? Model-makers have to work with the data they have, yet a novel virus, such as the one that causes COVID-19, has a lot of unknowns.\n\nFor example, the Imperial College model uses numbers from Wuhan, China, along with some early data from Italy. This is a reasonable choice, as those are the pandemic\u2019s largest epicenters. But many of these data are not yet settled, and many questions remain. What\u2019s the attack rate\u2014the number of people who get infected within an exposed group, like a household? Do people who recover have immunity? How widespread are asymptomatic cases, and how infectious are they? Are there super-spreaders\u2014people who seemingly infect everyone they breathe near\u2014as there were with SARS, and how prevalent are they? What are the false positive and false negative rates of our tests? And so on, and on and on.\n\nTo make models work, epidemiologists also have to estimate the impact of interventions like social isolation. But here, too, the limited data we have are imperfect, perhaps censored, perhaps inapplicable. For example, China underwent a period in which the government yanked infected patients and even their healthy close contacts from their homes, and sent them into special quarantine wards. That seems to have dramatically cut down infections within a household and within the city. Relatively few infected people in the United States or the United Kingdom have been similarly quarantined. In general, the lockdown in China was much more severe. Planes are still taking off from New York, New Jersey, and everywhere else, even as we speak of \u201csocial isolation.\u201d And more complications remain. We aren\u2019t even sure we can trust China\u2019s numbers. Italy\u2019s health statistics are likely more trustworthy, but its culture of furbizia\u2014or flouting the rules, part of the country\u2019s charm as well as its dysfunction\u2014increases the difficulty of knowing how applicable its outcomes are to our projections.\n\nRead: The four possible timelines for life returning to normal\n\nA model\u2019s robustness depends on how often it gets tried out and tweaked based on data and its performance. For example, many models predicting presidential elections are based on data from presidential elections since 1972. That\u2019s all the elections we have polling data for, but it\u2019s only 12 elections, and prior to 2016, only two happened in the era of Facebook. So when Donald Trump, the candidate that was projected to be less likely to win the presidency in 2016, won anyway, did that mean that our models with TV-era parameters don\u2019t work anymore? Or is it merely that a less likely but possible outcome happened? (If you\u2019re flipping a coin, you\u2019ll get four heads in a row about one every 16 tries, meaning that you can\u2019t know if the coin is loaded just because something seemingly unusual happens). With this novel coronavirus, there are a lot of things we don\u2019t know because we\u2019ve never tested our models, and we have no way to do so.",
    "source_url": "www.theatlantic.com",
    "bias_text": "left",
    "ID": "OqCk2blRLUipYmpz"
}