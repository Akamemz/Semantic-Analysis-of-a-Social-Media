{
    "topic": "media_bias",
    "source": "Christian Science Monitor",
    "bias": 1,
    "url": "https://www.csmonitor.com/USA/Politics/2020/0128/Whose-reality-Propaganda-in-the-age-of-social-media",
    "title": "Whose reality? Propaganda in the age of social media",
    "date": "2020-01-28",
    "authors": "\"Eoin OCarroll\"",
    "content": "If you do spot misinformation in your newsfeed , one option , Professor Cull suggests , might be to send that friend an email rather than responding publicly and inadvertently boosting engagement to the original post .\nSo what \u2019 s a social media user to do ? Katy Byron , the editor and program manager of MediaWise , advises online readers to ask three simple questions : Who is behind the information ? What is the evidence ? And what are other sources saying ?\nDraft rumors are nothing new , says University of Southern California historian Nicholas Cull . But modern technology confounds our efforts to tell fact from fiction . \u201c We \u2019 re living in one of those dangerous moments right now , \u201d he says .\nThe killing of Maj. Gen. Qassem Soleimani of Iran on Jan. 3 sent waves of diplomatic uncertainty throughout the Middle East . But the U.S. drone strike that led to his death also released a cloud of uncertainty in the United States . One prominent series of rumors circulating on social media claimed that the United States had instituted the draft . By the end of the day of the drone strike , the servers for the U.S . Selective Service System \u2019 s website had crashed .\nTruth , it is often said , is the first casualty of war , and in the wake of the assassination of Maj. Gen. Qassem Soleimani of Iran on Jan. 3 , misinformation ran rampant .\nIn the days following the U.S.-led drone strike , the White House \u2019 s rationales for the attack shifted wildly . Initially , the Trump administration claimed that the general was plotting an \u201c imminent \u201d attack against Americans . Less than a week later , it was to prevent an attack on a U.S. embassy , or four embassies . Or maybe it was U.S. military bases . In the end , \u201c it doesn \u2019 t really matter , \u201d the president tweeted , \u201c because of [ Soleimani \u2019 s ] horrible past ! \u201d\nAt the same time , social networks like TikTok , Instagram , and Facebook began to overflow with doctored photos and outdated images , false rumors about the draft , and fake tweets from administration officials . In one sense , this is nothing new ; war fighting has always had a psychological component , which includes spreading lies . But in another sense , the informational fog speaks to the defining epistemological issue of our era : the fracturing of the American public \u2019 s shared sense of reality .\n\u201c The objective seems to be to question the idea that anything is certain , \u201d says University of Southern California historian Nicholas Cull . \u201c In a world of uncertainty , the only one you can trust is the strongest guy in the room . \u201d\nOne rumor claimed that the U.S. had instituted the draft . Another rumor claimed that LGBT people were exempt . Another claimed that felons were exempt . By the end of the day of the drone strike , the servers for the U.S . Selective Service System \u2019 s website had crashed .\n\u201c The two-day period after the news broke were very confusing to young people , \u201d says Katy Byron , the editor and program manager of MediaWise , a Poynter Institute for Media Studies project aimed at helping teenagers identify online misinformation .\nProfessor Cull points out that draft rumors are nothing new ; a prevalent rumor in the spring of 1942 claimed Jews were exempt . But , he says , modern technology confounds our efforts to tell fact from fiction . \u201c We \u2019 re living in one of those dangerous moments right now . [ There is a ] tremendous instability from the overlap of social media and big data-powered targeting of social media that we are in the process of learning to deal with . \u201d\nMisinformation on social media presents a thorny problem . Recommendation algorithms , like the kind that determine what appears in your Facebook newsfeed or YouTube \u2019 s \u201c up next \u201d list , can not by themselves distinguish truth from lies . All they can do is measure how people \u201c engage \u201d with the content : whether they scroll past it or linger on it , whether they click on the thumbs , hearts , or other icons associated with the post , and how much time they spend interacting with it .\nThis algorithmic agnosticism often leads to perverse results . Social networks assign higher ranks to content that prompts more engagement , regardless of whether the content is true or whether it improves the engager \u2019 s life . And the more highly ranked a piece of content is , the more likely people will see it . That means that , if you come across a Facebook post that you think is false and you write a thoughtful point-by-point rebuttal of it , you \u2019 ve made it more likely that the misinformation will appear in more peoples \u2019 Facebook news feeds .\nWhat \u2019 s more , today \u2019 s media landscape is immeasurably more fragmented than it was in 1967 . To reach its audience , misinformation \u2013 and its deliberate subset , disinformation \u2013 no longer needs to travel the highways afforded by the major news outlets ; instead , it can travel the backroads created by niche targeting . That means that what you see may not be what everyone else , including professional fact-checkers , see .\n\u201c The beauty of freedom of speech , historically , is that the freedom of speech is constrained by the ability to observe and respond to problematic speech , \u201d says Josh Pasek , a media professor at the University of Michigan . \u201c The challenge in this social media environment is that you can \u2019 t necessarily do that . \u201d\nProfessor Pasek suggests that one way for the government to curb misinformation without running afoul of free speech protections would be to require social media companies to be transparent about who is targeting what content to which users .\n\u201c You don \u2019 t have the right to not have your speech known about just because you \u2019 re trying to hide it from someone , \u201d he says .\nIf you spot misinformation in your news feed , one option , Professor Cull suggests , might be to go outside the infrastructure . In other words , if a friend posts a false news report on Twitter , instead of responding via Twitter and inadvertently boosting engagement to the original post , you could send that friend an email instead .\nMs. Byron of MediaWise , whose project is backed by Google \u2019 s charitable arm , Google.org , advises online readers to ask three simple questions : Who is behind the information ? What is the evidence ? And what are other sources saying ?\nIf you \u2019 re still not sure , she says , you can tag the post with # IsThisLegit and @ mediawise . \u201c We \u2019 ll help you figure out if what you \u2019 re seeing is real or not , \u201d she says .\nGet the Monitor Stories you care about delivered to your inbox . By signing up , you agree to our Privacy Policy\nProfessor Cull says that the combination of rapid technological shifts and political instability places society in a dangerous situation , but , if we survive this moment , our minds will eventually adjust to the new media landscape , just as we adjusted to television and radio in the past .\n\u201c In a couple of years , \u201d he says , \u201c we \u2019 ll be able to look back on it and think , \u2018 Wow , can you imagine that we didn \u2019 t understand that ? Now we understand it . It \u2019 s second nature . We can move beyond it . \u2019 \u201d",
    "content_original": "If you do spot misinformation in your newsfeed, one option, Professor Cull suggests, might be to send that friend an email rather than responding publicly and inadvertently boosting engagement to the original post.\n\nSo what\u2019s a social media user to do? Katy Byron, the editor and program manager of MediaWise, advises online readers to ask three simple questions: Who is behind the information? What is the evidence? And what are other sources saying?\n\nDraft rumors are nothing new, says University of Southern California historian Nicholas Cull. But modern technology confounds our efforts to tell fact from fiction. \u201cWe\u2019re living in one of those dangerous moments right now,\u201d he says.\n\nThe killing of Maj. Gen. Qassem Soleimani of Iran on Jan. 3 sent waves of diplomatic uncertainty throughout the Middle East. But the U.S. drone strike that led to his death also released a cloud of uncertainty in the United States. One prominent series of rumors circulating on social media claimed that the United States had instituted the draft. By the end of the day of the drone strike, the servers for the U.S. Selective Service System\u2019s website had crashed.\n\nTruth, it is often said, is the first casualty of war, and in the wake of the assassination of Maj. Gen. Qassem Soleimani of Iran on Jan. 3, misinformation ran rampant.\n\nIn the days following the U.S.-led drone strike, the White House\u2019s rationales for the attack shifted wildly. Initially, the Trump administration claimed that the general was plotting an \u201cimminent\u201d attack against Americans. Less than a week later, it was to prevent an attack on a U.S. embassy, or four embassies. Or maybe it was U.S. military bases. In the end, \u201cit doesn\u2019t really matter,\u201d the president tweeted, \u201cbecause of [Soleimani\u2019s] horrible past!\u201d\n\nAt the same time, social networks like TikTok, Instagram, and Facebook began to overflow with doctored photos and outdated images, false rumors about the draft, and fake tweets from administration officials. In one sense, this is nothing new; war fighting has always had a psychological component, which includes spreading lies. But in another sense, the informational fog speaks to the defining epistemological issue of our era: the fracturing of the American public\u2019s shared sense of reality.\n\n\u201cThe objective seems to be to question the idea that anything is certain,\u201d says University of Southern California historian Nicholas Cull. \u201cIn a world of uncertainty, the only one you can trust is the strongest guy in the room.\u201d\n\nA fog of misinformation\n\nOne rumor claimed that the U.S. had instituted the draft. Another rumor claimed that LGBT people were exempt. Another claimed that felons were exempt. By the end of the day of the drone strike, the servers for the U.S. Selective Service System\u2019s website had crashed.\n\n\u201cThe two-day period after the news broke were very confusing to young people,\u201d says Katy Byron, the editor and program manager of MediaWise, a Poynter Institute for Media Studies project aimed at helping teenagers identify online misinformation.\n\nProfessor Cull points out that draft rumors are nothing new; a prevalent rumor in the spring of 1942 claimed Jews were exempt. But, he says, modern technology confounds our efforts to tell fact from fiction. \u201cWe\u2019re living in one of those dangerous moments right now. [There is a] tremendous instability from the overlap of social media and big data-powered targeting of social media that we are in the process of learning to deal with.\u201d\n\nProgrammed to spread\n\nMisinformation on social media presents a thorny problem. Recommendation algorithms, like the kind that determine what appears in your Facebook newsfeed or YouTube\u2019s \u201cup next\u201d list, cannot by themselves distinguish truth from lies. All they can do is measure how people \u201cengage\u201d with the content: whether they scroll past it or linger on it, whether they click on the thumbs, hearts, or other icons associated with the post, and how much time they spend interacting with it.\n\nThis algorithmic agnosticism often leads to perverse results. Social networks assign higher ranks to content that prompts more engagement, regardless of whether the content is true or whether it improves the engager\u2019s life. And the more highly ranked a piece of content is, the more likely people will see it. That means that, if you come across a Facebook post that you think is false and you write a thoughtful point-by-point rebuttal of it, you\u2019ve made it more likely that the misinformation will appear in more peoples\u2019 Facebook news feeds.\n\nWhat\u2019s more, today\u2019s media landscape is immeasurably more fragmented than it was in 1967. To reach its audience, misinformation \u2013 and its deliberate subset, disinformation \u2013 no longer needs to travel the highways afforded by the major news outlets; instead, it can travel the backroads created by niche targeting. That means that what you see may not be what everyone else, including professional fact-checkers, see.\n\n\u201cThe beauty of freedom of speech, historically, is that the freedom of speech is constrained by the ability to observe and respond to problematic speech,\u201d says Josh Pasek, a media professor at the University of Michigan. \u201cThe challenge in this social media environment is that you can\u2019t necessarily do that.\u201d\n\nProfessor Pasek suggests that one way for the government to curb misinformation without running afoul of free speech protections would be to require social media companies to be transparent about who is targeting what content to which users.\n\n\u201cYou don\u2019t have the right to not have your speech known about just because you\u2019re trying to hide it from someone,\u201d he says.\n\nHow to respond?\n\nIf you spot misinformation in your news feed, one option, Professor Cull suggests, might be to go outside the infrastructure. In other words, if a friend posts a false news report on Twitter, instead of responding via Twitter and inadvertently boosting engagement to the original post, you could send that friend an email instead.\n\nMs. Byron of MediaWise, whose project is backed by Google\u2019s charitable arm, Google.org, advises online readers to ask three simple questions: Who is behind the information? What is the evidence? And what are other sources saying?\n\nIf you\u2019re still not sure, she says, you can tag the post with #IsThisLegit and @mediawise. \u201cWe\u2019ll help you figure out if what you\u2019re seeing is real or not,\u201d she says.\n\nGet the Monitor Stories you care about delivered to your inbox. By signing up, you agree to our Privacy Policy\n\nProfessor Cull says that the combination of rapid technological shifts and political instability places society in a dangerous situation, but, if we survive this moment, our minds will eventually adjust to the new media landscape, just as we adjusted to television and radio in the past.\n\n\u201cIn a couple of years,\u201d he says, \u201cwe\u2019ll be able to look back on it and think, \u2018Wow, can you imagine that we didn\u2019t understand that? Now we understand it. It\u2019s second nature. We can move beyond it.\u2019\u201d",
    "source_url": "www.csmonitor.com",
    "bias_text": "center",
    "ID": "j2zXfOmi2wBGZh3Z"
}