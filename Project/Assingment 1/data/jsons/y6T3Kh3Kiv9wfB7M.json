{
    "topic": "media_bias",
    "source": "New York Times - News",
    "bias": 0,
    "url": "http://www.nytimes.com/roomfordebate/2016/05/17/is-facebook-saving-journalism-or-ruining-it/providing-balanced-information-is-not-facebooks-goal",
    "title": "Providing Balanced Information Is Not Facebook\u2019s Goal",
    "date": "2016-05-17",
    "authors": "Annalee Newitz, Robyn Caplan",
    "content": "Catherine R. Squires is a professor of communication studies at the University of Minnesota , Twin Cities . She is also the director of the Race , Indigeneity , Gender and Sexuality Studies Initiative .\nFacebook is a for-profit company that makes money packaging its users ' information to sell to advertisers and other entities . The company 's goal is not to produce a `` balanced '' information diet for its users . People who are shocked that Facebook might be skewing their newsfeed probably should n't have trusted them with their news diet in the first place , given its history . Remember those confusing and ever-changing privacy settings , and that experiment to see whether users ' moods could be manipulated by changing the newsfeed ? This is not the company I 'd trust to tell me what 's important in the world .\nPeople who are shocked that Facebook might be skewing their newsfeed probably should n't have trusted them with their news diet in the first place .\nBut the uproar over the role of human editors at Facebook \u2014 or at least , in the `` Trending Topics '' section \u2014 does revive an important question : In an information age when people can customize their news diet , how should Facebook editors decide what issues , opinions or events deserve prominence ?\nGiven their newfound reliance on social media companies like Facebook , traditional media editors have been grappling with the same question . Any news publication with a website makes ad revenue off of popular articles , but that can be a dangerous incentive . Though important news can also be popular , all of the major publications are guilty of publishing dumbed down `` clickbait '' to attract wider audiences .\nSo then , perhaps the question is whether Facebook , or even the news media , is narrowing the field of news so that we , as citizens , are unable to engage in effective political and social discussions .\nA Facebook newsfeed that was completely dictated by algorithms without human interference would n't be any better . Algorithms reflect the imperfect biases of the humans that build them . Algorithms rely on data sets , which are structured by the decisions of data gatherers guided by particular goals . For example , as most of the people who work in computing are male , it 's not surprising that scholars found a gender bias in the Google 's Image search : In searches for C.E.O. , 11 percent of the people depicted were women , compared with 27 percent of U.S. C.E.O.s who are actually women .\nData and news can be skewed on many levels on the Internet , but competent editors could explain how they and their algorithms work . Then , at least , the public would know how and why news sites elevate certain stories .\nBut bias in the media is not new . These basic questions have to be worked out by each generation , confronted by each new development in media technology . They are ethical and practical questions that require a human touch .",
    "content_original": "Catherine R. Squires is a professor of communication studies at the University of Minnesota, Twin Cities. She is also the director of the Race, Indigeneity, Gender and Sexuality Studies Initiative.\n\nFacebook is a for-profit company that makes money packaging its users' information to sell to advertisers and other entities. The company's goal is not to produce a \"balanced\" information diet for its users. People who are shocked that Facebook might be skewing their newsfeed probably shouldn't have trusted them with their news diet in the first place, given its history. Remember those confusing and ever-changing privacy settings, and that experiment to see whether users' moods could be manipulated by changing the newsfeed? This is not the company I'd trust to tell me what's important in the world.\n\nPeople who are shocked that Facebook might be skewing their newsfeed probably shouldn't have trusted them with their news diet in the first place.\n\nBut the uproar over the role of human editors at Facebook \u2014 or at least, in the \"Trending Topics\" section \u2014 does revive an important question: In an information age when people can customize their news diet, how should Facebook editors decide what issues, opinions or events deserve prominence?\n\nGiven their newfound reliance on social media companies like Facebook, traditional media editors have been grappling with the same question. Any news publication with a website makes ad revenue off of popular articles, but that can be a dangerous incentive. Though important news can also be popular, all of the major publications are guilty of publishing dumbed down \"clickbait\" to attract wider audiences.\n\nSo then, perhaps the question is whether Facebook, or even the news media, is narrowing the field of news so that we, as citizens, are unable to engage in effective political and social discussions.\n\nA Facebook newsfeed that was completely dictated by algorithms without human interference wouldn't be any better. Algorithms reflect the imperfect biases of the humans that build them. Algorithms rely on data sets, which are structured by the decisions of data gatherers guided by particular goals. For example, as most of the people who work in computing are male, it's not surprising that scholars found a gender bias in the Google's Image search: In searches for C.E.O., 11 percent of the people depicted were women, compared with 27 percent of U.S. C.E.O.s who are actually women.\n\nData and news can be skewed on many levels on the Internet, but competent editors could explain how they and their algorithms work. Then, at least, the public would know how and why news sites elevate certain stories.\n\nBut bias in the media is not new. These basic questions have to be worked out by each generation, confronted by each new development in media technology. They are ethical and practical questions that require a human touch.\n\n\n\nJoin Opinion on Facebook and follow updates on twitter.com/roomfordebate.\n\n",
    "source_url": "www.nytimes.com",
    "bias_text": "left",
    "ID": "y6T3Kh3Kiv9wfB7M"
}