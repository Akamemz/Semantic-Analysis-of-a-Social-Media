{
    "topic": "free_speech",
    "source": "Washington Times",
    "bias": 2,
    "url": "https://www.washingtontimes.com/news/2018/apr/22/facebook-hate-speech-censorship-policies-upset-bot/",
    "title": "Thumbs down: Facebook\u2019s hate speech and censorship policies no easy fix",
    "date": "2018-04-22",
    "authors": "Ben Wolfgang",
    "content": "Under more scrutiny than ever , Facebook finds itself caught in a no-man \u2019 s land between activists who say it needs to adopt much stricter definitions governing hate speech and critics on the right who feel the social media giant is censoring conservative voices .\nThe company \u2019 s policy now largely depends on humans reviewing content flagged by others as offensive \u2014 a system Facebook CEO Mark Zuckerberg told Congress he hopes to change within 10 years by integrating artificial intelligence that can identify questionable content immediately .\nBy some accounts , the current policy has been a failure , and Mr. Zuckerberg \u2019 s claim that the site doesn \u2019 t house hateful posts is simply wrong . They also contend that Facebook needs to become much more aggressive , perhaps tying its definition of hate speech to the one used by the controversial Southern Poverty Law Center .\n\u201c We \u2019 re shocked by Zuckerberg \u2019 s claim that Facebook does not allow any hate groups on their platform . For years , civil rights groups have been urging Facebook to address the discrimination and bigotry on its platform , and , for years , the company has done little to meaningfully address our concerns , \u201d said Madihha Ahussain , special counsel for anti-Muslim bigotry at Muslim Advocates .\n\u201c Today , to our knowledge , at least 23 of them are still organizing on Facebook , \u201d she said . \u201c That list only accounts for Southern Poverty Law Center \u2019 s compilation of anti-Muslim groups and doesn \u2019 t include the thousands of others organized to hate against other communities . \u201d\nBut conservatives say adopting the Southern Poverty Law Center \u2019 s definition of a hate group would lead to even bigger problems and more bias . The organization , for example , classifies the Family Research Council as a hate group because of its stand on same-sex marriage and other LGBT issues .\nUsing that definition would deepen the fear and anger among conservatives toward the Silicon Valley behemoth . Facebook already has faced intense criticism from the political right for suspected censoring of posts from the popular pro-Trump duo Diamond and Silk , among a host of other content that Republicans say is filtered on solely political grounds .\nDiamond and Silk , whose posts in the past have been considered \u201c unsafe \u201d by Facebook , will appear Thursday before the House Judiciary Committee .\nFacebook \u2019 s handling of the duo has become a rallying point for conservative critics , and it was the latest in a string of controversial steps . The company two years ago came under fire for appearing to suppress conservative news sources in its trending topics feed , and its actions since then have done little to calm those who say Facebook \u2019 s liberal bias is out of control .\n\u201c I think this is going to be a controversial topic perpetually , for several reasons . First and foremost , they can \u2019 t get out of their own bubble , and until they do they won \u2019 t even realize they have a problem , \u201d said Christie-Lee McNally , founder of the conservative group Free Our Internet and a former Trump campaign official who believes Facebook \u2019 s human review system is inherently flawed because of the company \u2019 s progressive leanings .\nOn Capitol Hill , the issue of whether Facebook suppresses conservative content has raised the ire of Republican lawmakers , some of whom argue that Facebook has become so big and powerful that its handling of speech \u2014 such as what to censor and what to allow \u2014 creates ripples across the American cultural and political landscape .\n\u201c If they \u2019 re behaving like Big Brother and censoring political speech , I think that raises very serious legal questions that I expect to see a whole lot more scrutiny devoted to , \u201d Sen. Ted Cruz , Texas Republican , said last week .\nFacebook says it defines hate speech as \u201c content that attacks people based on their actual or perceived race , ethnicity , national origin , religion , sex , gender or gender identity , sexual orientation , disability or disease . \u201d\nIt specifies that it does allow satire , comedy , music and other types of performance art that some people may find offensive .\nIssues arise , of course , because what some consider to be offensive , racially tinged attacks are seen by others as political statements . Rhetoric surrounding illegal immigration , for example , often falls into that category .\n\u201c At the end of the day , it will be tough to keep 2 billion people happy all of the time , \u201d said Emma Llanso , director of the Freedom of Expression Project at the Center for Democracy and Technology .\nMs. Llanso said she believes that Facebook and other massive social media firms that have become ubiquitous parts of pop culture may end up adopting more stringent standards on speech , while other companies could cast themselves as more open and , in some cases , willfully controversial .\n\u201c I \u2019 d rather see a situation with multiple different competing platforms that each have their own tailor-made content policies , \u201d she said . \u201c I feel like that creates less of a risk that an entire group of speakers or topic won \u2019 t find anywhere on the internet that will host their speech . \u201d\nMr. Zuckerberg told lawmakers that the human element of flagging offensive content will be removed within the next decade , though that doesn \u2019 t mean Facebook \u2019 s automated system won \u2019 t also ruffle feathers .\n\u201c Hate speech \u2014 I \u2019 m optimistic that over a five , 10-year period we will have AI tools that get into some of the nuances , the linguistic nuances , of different types of content to be more accurate in flagging things for our systems , \u201d he said this month . \u201c But today we \u2019 re just not there on that , so a lot of this is still reactive . People flag it to us , we have people look at it , we have policies to try and make it as not subjective as possible , but until we get it more automated there \u2019 s a higher error rate than I \u2019 m happy with . \u201d",
    "content_original": "Under more scrutiny than ever, Facebook finds itself caught in a no-man\u2019s land between activists who say it needs to adopt much stricter definitions governing hate speech and critics on the right who feel the social media giant is censoring conservative voices.\n\nThe company\u2019s policy now largely depends on humans reviewing content flagged by others as offensive \u2014 a system Facebook CEO Mark Zuckerberg told Congress he hopes to change within 10 years by integrating artificial intelligence that can identify questionable content immediately.\n\nBy some accounts, the current policy has been a failure, and Mr. Zuckerberg\u2019s claim that the site doesn\u2019t house hateful posts is simply wrong. They also contend that Facebook needs to become much more aggressive, perhaps tying its definition of hate speech to the one used by the controversial Southern Poverty Law Center.\n\n\u201cWe\u2019re shocked by Zuckerberg\u2019s claim that Facebook does not allow any hate groups on their platform. For years, civil rights groups have been urging Facebook to address the discrimination and bigotry on its platform, and, for years, the company has done little to meaningfully address our concerns,\u201d said Madihha Ahussain, special counsel for anti-Muslim bigotry at Muslim Advocates.\n\n\u201cToday, to our knowledge, at least 23 of them are still organizing on Facebook,\u201d she said. \u201cThat list only accounts for Southern Poverty Law Center\u2019s compilation of anti-Muslim groups and doesn\u2019t include the thousands of others organized to hate against other communities.\u201d\n\nBut conservatives say adopting the Southern Poverty Law Center\u2019s definition of a hate group would lead to even bigger problems and more bias. The organization, for example, classifies the Family Research Council as a hate group because of its stand on same-sex marriage and other LGBT issues.\n\nUsing that definition would deepen the fear and anger among conservatives toward the Silicon Valley behemoth. Facebook already has faced intense criticism from the political right for suspected censoring of posts from the popular pro-Trump duo Diamond and Silk, among a host of other content that Republicans say is filtered on solely political grounds.\n\nDiamond and Silk, whose posts in the past have been considered \u201cunsafe\u201d by Facebook, will appear Thursday before the House Judiciary Committee.\n\nFacebook\u2019s handling of the duo has become a rallying point for conservative critics, and it was the latest in a string of controversial steps. The company two years ago came under fire for appearing to suppress conservative news sources in its trending topics feed, and its actions since then have done little to calm those who say Facebook\u2019s liberal bias is out of control.\n\n\u201cI think this is going to be a controversial topic perpetually, for several reasons. First and foremost, they can\u2019t get out of their own bubble, and until they do they won\u2019t even realize they have a problem,\u201d said Christie-Lee McNally, founder of the conservative group Free Our Internet and a former Trump campaign official who believes Facebook\u2019s human review system is inherently flawed because of the company\u2019s progressive leanings.\n\nOn Capitol Hill, the issue of whether Facebook suppresses conservative content has raised the ire of Republican lawmakers, some of whom argue that Facebook has become so big and powerful that its handling of speech \u2014 such as what to censor and what to allow \u2014 creates ripples across the American cultural and political landscape.\n\n\u201cIf they\u2019re behaving like Big Brother and censoring political speech, I think that raises very serious legal questions that I expect to see a whole lot more scrutiny devoted to,\u201d Sen. Ted Cruz, Texas Republican, said last week.\n\nFacebook says it defines hate speech as \u201ccontent that attacks people based on their actual or perceived race, ethnicity, national origin, religion, sex, gender or gender identity, sexual orientation, disability or disease.\u201d\n\nIt specifies that it does allow satire, comedy, music and other types of performance art that some people may find offensive.\n\nIssues arise, of course, because what some consider to be offensive, racially tinged attacks are seen by others as political statements. Rhetoric surrounding illegal immigration, for example, often falls into that category.\n\n\u201cAt the end of the day, it will be tough to keep 2 billion people happy all of the time,\u201d said Emma Llanso, director of the Freedom of Expression Project at the Center for Democracy and Technology.\n\nMs. Llanso said she believes that Facebook and other massive social media firms that have become ubiquitous parts of pop culture may end up adopting more stringent standards on speech, while other companies could cast themselves as more open and, in some cases, willfully controversial.\n\n\u201cI\u2019d rather see a situation with multiple different competing platforms that each have their own tailor-made content policies,\u201d she said. \u201cI feel like that creates less of a risk that an entire group of speakers or topic won\u2019t find anywhere on the internet that will host their speech.\u201d\n\nMr. Zuckerberg told lawmakers that the human element of flagging offensive content will be removed within the next decade, though that doesn\u2019t mean Facebook\u2019s automated system won\u2019t also ruffle feathers.\n\n\u201cHate speech \u2014 I\u2019m optimistic that over a five, 10-year period we will have AI tools that get into some of the nuances, the linguistic nuances, of different types of content to be more accurate in flagging things for our systems,\u201d he said this month. \u201cBut today we\u2019re just not there on that, so a lot of this is still reactive. People flag it to us, we have people look at it, we have policies to try and make it as not subjective as possible, but until we get it more automated there\u2019s a higher error rate than I\u2019m happy with.\u201d\n\nSign up for Daily Newsletters\n\nCopyright \u00a9 2019 The Washington Times, LLC. Click here for reprint permission.",
    "source_url": "www.washingtontimes.com",
    "bias_text": "right",
    "ID": "3lGpniBALUGf1kCn"
}