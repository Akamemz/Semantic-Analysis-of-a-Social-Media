{
    "topic": "race_and_racism",
    "source": "Mother Jones",
    "bias": 0,
    "url": "https://www.motherjones.com/politics/2020/03/facebook-just-revealed-its-secret-strategy-for-taking-down-hate-groups/",
    "title": "Facebook Just Revealed Its Secret Strategy for Taking Down Hate Groups",
    "date": "",
    "authors": "Ali Breland, Fernanda Echavarri, Jesse Eisinger, James Bandler, Kara Voght, Tim Murphy, Daniel King, Alexia Fern\u00e1ndez Campbell, Will Peischel, Brian Barth",
    "content": "For indispensable reporting on the coronavirus crisis and more , subscribe to \u2588\u2588\u2588 ' newsletters\nThe members of Northwest Front have been called the \u201c worst racists \u201d in America , amid stiff competition . On Wednesday , Facebook told \u2588\u2588\u2588 that it had used a new enforcement strategy to take down a network of Northwest Front accounts that tried to circumvent the platform \u2019 s ban on white nationalists .\n\u201c This organization has been banned on Facebook for years now . We recently identified that they had tried to reestablish a presence on the platform . What we decided to do is identify as many of their assets as we could , identities of their supporters and members , groups , pages , and then take them all down at once , \u201d Brian Fishman , Facebook \u2019 s director of counterterrorism and dangerous organizations policy , explained on the phone .\nThe action against the Northwest Front that Fishman outlined is a strategy that Facebook occasionally uses to stop the most egregious and dangerous groups from using its tools . Until Wednesday , the company had not shared any details of that strategy publicly .\nThe group had been organizing on Facebook and attempting to use the platform to recruit potentially sympathetic minds into the neo-Nazi group .\nTypically , Fishman explained , most content that violates Facebook \u2019 s terms of service is reviewed and taken down as quickly as the company can manage it ; the takedowns are accompanied by messages to violators about how they \u2019 d breached platform rules . In the case of the recent move against Northwest Front , though , the company instead opted to monitor accounts of individuals associated with the Northwest Front , in the hopes of finding a larger chunk of the network and taking it all down at once , with no explanations given .\n\u201c This is different than our normal operations . The reason for doing things like this is to make it more difficult to rebuild a network , \u201d Fishman said . \u201c If you take out one piece or consistently takedown pieces , then they still can try to rebuild . \u201d\nFishman emphasized that Facebook was not ignoring normal policy violations while monitoring the group . \u201c If something came into standard enforcement flows , it would come down , \u201d he said .\n\u201c Also if we recognize something that was an imminent threat , we wouldn \u2019 t delay . If we identify something that indicated that there \u2019 s potential for harm , we \u2019 ll take enforcement action , \u201d Sarah Pollack , a spokesperson for Facebook , added .\nFacebook would contact law enforcement if the group posed an imminent threat , Fishman said . It would also work with its lawyers to loop in law enforcement , the military , or other government groups if its investigators came across any white nationalists working in their ranks .\nFacebook has been deliberately opaque about its strategy in the past . That \u2019 s because the company wanted to make it harder for groups like the Northwest Front to understand what was happening and figure out how to dodge detection in the future . Fishman was light on a lot of details about what Facebook looks for in monitoring these types of groups . Often , he said , Facebook won \u2019 t say that it took action on a set of accounts , leaving users puzzled as their accounts , pages , and groups are deleted without explanation .\n\u201c Sometimes these groups are confused about actions . That \u2019 s a positive effect from my perspective , \u201d he said . \u201c When we \u2019 re talking about terror groups and hate groups , ambiguity can be a useful tool . \u201d\nThe overall scope of the takedown was small , at 36 Facebook users , 10 Instagram users , nine groups , and nine pages .\nFishman said that this isn \u2019 t the first time Facebook has taken action of this kind . He and Pollack explained that the company had used the same strategy against other American right-wing hate organizations , including The Right Stuff and Identity Dixie , two alt-right podcasts , as well as the Revolutionary Armed Forces of Colombia ( aka FARC ) , a leftist rebel group in Columbia .\n\u201c We \u2019 ve always wanted to explain that we \u2019 re using this approach , \u201d Pollack said , \u201c but we wanted to do it now to highlight [ that ] our work on dangerous organizations continues even in this moment where Facebook and the world is focused on COVID-19 . \u201d",
    "content_original": "For indispensable reporting on the coronavirus crisis and more, subscribe to Mother Jones' newsletters\n\nThe members of Northwest Front have been called the \u201cworst racists\u201d in America, amid stiff competition. On Wednesday, Facebook told Mother Jones that it had used a new enforcement strategy to take down a network of Northwest Front accounts that tried to circumvent the platform\u2019s ban on white nationalists.\n\n\u201cThis organization has been banned on Facebook for years now. We recently identified that they had tried to reestablish a presence on the platform. What we decided to do is identify as many of their assets as we could, identities of their supporters and members, groups, pages, and then take them all down at once,\u201d Brian Fishman, Facebook\u2019s director of counterterrorism and dangerous organizations policy, explained on the phone.\n\nThe action against the Northwest Front that Fishman outlined is a strategy that Facebook occasionally uses to stop the most egregious and dangerous groups from using its tools. Until Wednesday, the company had not shared any details of that strategy publicly.\n\nThe group had been organizing on Facebook and attempting to use the platform to recruit potentially sympathetic minds into the neo-Nazi group.\n\nTypically, Fishman explained, most content that violates Facebook\u2019s terms of service is reviewed and taken down as quickly as the company can manage it; the takedowns are accompanied by messages to violators about how they\u2019d breached platform rules. In the case of the recent move against Northwest Front, though, the company instead opted to monitor accounts of individuals associated with the Northwest Front, in the hopes of finding a larger chunk of the network and taking it all down at once, with no explanations given.\n\n\u201cThis is different than our normal operations. The reason for doing things like this is to make it more difficult to rebuild a network,\u201d Fishman said. \u201cIf you take out one piece or consistently takedown pieces, then they still can try to rebuild.\u201d\n\nFishman emphasized that Facebook was not ignoring normal policy violations while monitoring the group. \u201cIf something came into standard enforcement flows, it would come down,\u201d he said.\n\n\u201cAlso if we recognize something that was an imminent threat, we wouldn\u2019t delay. If we identify something that indicated that there\u2019s potential for harm, we\u2019ll take enforcement action,\u201d Sarah Pollack, a spokesperson for Facebook, added.\n\nFacebook would contact law enforcement if the group posed an imminent threat, Fishman said. It would also work with its lawyers to loop in law enforcement, the military, or other government groups if its investigators came across any white nationalists working in their ranks.\n\nFacebook has been deliberately opaque about its strategy in the past. That\u2019s because the company wanted to make it harder for groups like the Northwest Front to understand what was happening and figure out how to dodge detection in the future. Fishman was light on a lot of details about what Facebook looks for in monitoring these types of groups. Often, he said, Facebook won\u2019t say that it took action on a set of accounts, leaving users puzzled as their accounts, pages, and groups are deleted without explanation.\n\n\u201cSometimes these groups are confused about actions. That\u2019s a positive effect from my perspective,\u201d he said. \u201cWhen we\u2019re talking about terror groups and hate groups, ambiguity can be a useful tool.\u201d\n\nThe overall scope of the takedown was small, at 36 Facebook users, 10 Instagram users, nine groups, and nine pages.\n\nFishman said that this isn\u2019t the first time Facebook has taken action of this kind. He and Pollack explained that the company had used the same strategy against other American right-wing hate organizations, including The Right Stuff and Identity Dixie, two alt-right podcasts, as well as the Revolutionary Armed Forces of Colombia (aka FARC), a leftist rebel group in Columbia.\n\n\u201cWe\u2019ve always wanted to explain that we\u2019re using this approach,\u201d Pollack said, \u201cbut we wanted to do it now to highlight [that] our work on dangerous organizations continues even in this moment where Facebook and the world is focused on COVID-19.\u201d",
    "source_url": "www.motherjones.com",
    "bias_text": "left",
    "ID": "HQ6X6gxmz0CwFxZg"
}