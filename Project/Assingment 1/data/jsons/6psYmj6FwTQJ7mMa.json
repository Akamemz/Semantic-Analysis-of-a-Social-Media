{
    "topic": "privacy",
    "source": "The Verge",
    "bias": 0,
    "url": "https://www.theverge.com/21289164/facebook-deepfake-detection-challenge-unsolved-problem-ai",
    "title": "Facebook contest reveals deepfake detection is still an \u2018unsolved problem\u2019",
    "date": "2020-06-12",
    "authors": "James Vincent",
    "content": "Facebook has announced the results of its first Deepfake Detection Challenge , an open competition to find algorithms that can spot AI-manipulated videos . The results , while promising , show there \u2019 s still lots of work to be done before automated systems can reliably spot deepfake content , with researchers describing the issue as an \u201c unsolved problem . \u201d\nFacebook says the winning algorithm in the contest was able to spot \u201c challenging real world examples \u201d of deepfakes with an average accuracy of 65.18 percent . That \u2019 s not bad , but it \u2019 s not the sort of hit-rate you would want for any automated system .\nDeepfakes have proven to be something of an exaggerated menace for social media . Although the technology prompted much handwringing about the erosion of reliable video evidence , the political effects of deepfakes have so far been minimal . Instead , the more immediate harm has been the creation of nonconsensual pornography , a category of content that \u2019 s easier for social media platforms to identify and remove .\nMike Schroepfer , Facebook \u2019 s chief technology officer , told journalists in a press call that he was pleased by the results of the challenge , which he said would create a benchmark for researchers and guide their work in the future . \u201c Honestly the contest has been more of a success than I could have ever hoped for , \u201d he said .\nSome 2,114 participants submitted more than 35,000 detection algorithms to the competition . They were tested on their ability to identify deepfake videos from a dataset of around 100,000 short clips . Facebook hired more than 3,000 actors to create these clips , who were recorded holding conversations in naturalistic environments . Some clips were altered using AI by having other actors \u2019 faces pasted on to their videos .\nResearchers were given access to this data to train their algorithms , and when tested on this material , they produced accuracy rates as high as 82.56 percent . However , when the same algorithms were tested against a \u201c black box \u201d dataset consisting of unseen footage , they performed much worse , with the best-scoring model achieving an accuracy rate of 65.18 percent . This shows detecting deepfakes in the wild is a very challenging problem .\nSchroepfer said Facebook is currently developing its own deepfake detection technology separate from this competition . \u201c We have deepfake detection technology in production and we will be improving it based on this context , \u201d he said . The company announced it was banning deepfakes earlier this year , but critics pointed out that the far greater threat to disinformation was from so-called \u201c shallowfakes \u201d \u2014 videos edited using traditional means .\nThe winning algorithms from this challenge will be released as open-source code to help other researchers , but Facebook said it would be keeping its own detection technology secret to prevent it from being reverse-engineered .\nSchroepfer added that while deepfakes were \u201c currently not a big issue \u201d for Facebook , the company wanted to have the tools ready to detect this content in the future \u2014 just in case . Some experts have said the upcoming 2020 election could be a prime moment for deepfakes to be used for serious political influence .\n\u201c The lesson I learned the hard way over the last couple of years , is I want to be prepared in advance and not be caught flat footed , \u201d said Schroepfer . \u201c I want to be really prepared for a lot of bad stuff that never happens rather than the other way around . \u201d",
    "content_original": "Facebook has announced the results of its first Deepfake Detection Challenge, an open competition to find algorithms that can spot AI-manipulated videos. The results, while promising, show there\u2019s still lots of work to be done before automated systems can reliably spot deepfake content, with researchers describing the issue as an \u201cunsolved problem.\u201d\n\nFacebook says the winning algorithm in the contest was able to spot \u201cchallenging real world examples\u201d of deepfakes with an average accuracy of 65.18 percent. That\u2019s not bad, but it\u2019s not the sort of hit-rate you would want for any automated system.\n\nDeepfakes have proven to be something of an exaggerated menace for social media. Although the technology prompted much handwringing about the erosion of reliable video evidence, the political effects of deepfakes have so far been minimal. Instead, the more immediate harm has been the creation of nonconsensual pornography, a category of content that\u2019s easier for social media platforms to identify and remove.\n\nMike Schroepfer, Facebook\u2019s chief technology officer, told journalists in a press call that he was pleased by the results of the challenge, which he said would create a benchmark for researchers and guide their work in the future. \u201cHonestly the contest has been more of a success than I could have ever hoped for,\u201d he said.\n\nRelated Deepfake detection algorithms will never be enough\n\nSome 2,114 participants submitted more than 35,000 detection algorithms to the competition. They were tested on their ability to identify deepfake videos from a dataset of around 100,000 short clips. Facebook hired more than 3,000 actors to create these clips, who were recorded holding conversations in naturalistic environments. Some clips were altered using AI by having other actors\u2019 faces pasted on to their videos.\n\nResearchers were given access to this data to train their algorithms, and when tested on this material, they produced accuracy rates as high as 82.56 percent. However, when the same algorithms were tested against a \u201cblack box\u201d dataset consisting of unseen footage, they performed much worse, with the best-scoring model achieving an accuracy rate of 65.18 percent. This shows detecting deepfakes in the wild is a very challenging problem.\n\nSchroepfer said Facebook is currently developing its own deepfake detection technology separate from this competition. \u201cWe have deepfake detection technology in production and we will be improving it based on this context,\u201d he said. The company announced it was banning deepfakes earlier this year, but critics pointed out that the far greater threat to disinformation was from so-called \u201cshallowfakes\u201d \u2014 videos edited using traditional means.\n\nThe winning algorithms from this challenge will be released as open-source code to help other researchers, but Facebook said it would be keeping its own detection technology secret to prevent it from being reverse-engineered.\n\nSchroepfer added that while deepfakes were \u201ccurrently not a big issue\u201d for Facebook, the company wanted to have the tools ready to detect this content in the future \u2014 just in case. Some experts have said the upcoming 2020 election could be a prime moment for deepfakes to be used for serious political influence.\n\n\u201cThe lesson I learned the hard way over the last couple of years, is I want to be prepared in advance and not be caught flat footed,\u201d said Schroepfer. \u201cI want to be really prepared for a lot of bad stuff that never happens rather than the other way around.\u201d",
    "source_url": "www.theverge.com",
    "bias_text": "left",
    "ID": "6psYmj6FwTQJ7mMa"
}