{
    "topic": "polarization",
    "source": "New York Magazine",
    "bias": 0,
    "url": "http://nymag.com/scienceofus/2016/11/how-facebook-and-the-filter-bubble-pushed-trump-to-victory.html",
    "title": "The \u2018Filter Bubble\u2019 Explains Why Trump Won and You Didn\u2019t See It Coming",
    "date": "2016-11-09",
    "authors": "Drake Baer",
    "content": "Donald Trump \u2019 s victory is blindsiding , like stepping into a crosswalk and getting slammed into by a delivery guy cycling the wrong way down a one-way street . This is because , as media scholars understand it , we increasingly live in a \u201c filter bubble \u201d : The information we take in is so personalized that we \u2019 re blind to other perspectives . It simultaneously explains why Trumpism has flourished and why so many of us are insulated from it .\nTo George Washington University media-studies assistant professor Nikki Usher Layser , the filter-bubbledness of the Trump victory speaks to how , more than ever before , people now have the ability for \u201c mass self-communication , \u201d where you can share your perspectives , with friends you don \u2019 t see in person everyday , with the push of a button . Not just the people you see in real life , but that girl from high school you never really got along with but who agrees with your opinions today .\n\u201c We have always surrounded ourselves with people who agree with us [ and ] sought information we agree with , but there was at least a chance for serendipity , \u201d she says , the chance that you \u2019 d discover something outside what you \u2019 d ordinarily choose to read yourself , even if you spend all day reading content . The big difference now , she told Science of Us , is the \u201c autonomous decision-making \u201d governing what stories you see . While newsrooms aren \u2019 t perfect , they can at least have the contextual awareness to offer contrasting narratives of what \u2019 s going in the news . \u201c We can \u2019 t break out of patterns if we only consume information online , through our social feeds , \u201d she says . It \u2019 s like explaining water to fish , this invisible , enveloping filter bubble .\nThe phrase got coined by MoveOn and Upworthy activist Eli Pariser , with his 2011 best seller , The Filter Bubble : What the Internet Is Hiding from You . His thesis was that while we might think of the internet as an impartial , universal library with Google serving as a superhuman Dewey decimal system , it \u2019 s remarkably , and perhaps pathologically , individualized . \u201c Your filter bubble is this unique , personal universe of information created just for you by this array of personalizing filters , \u201d he said in an interview with Amazon . \u201c It \u2019 s invisible and it \u2019 s becoming more and more difficult to escape. \u201d Back then , Pariser liked to say that Google used 57 signals to tailor its search results to you ; today , the search giant says it \u2019 s over 200 .\nGiven the events of last night \u2014 and the last year \u2014 this passage is strikingly prescient :\n\u201c Ultimately , democracy works only if we citizens are capable of thinking beyond our narrow self-interest . But to do so , we need a shared view of the world we cohabit . We need to come into contact with other people \u2019 s lives and needs and desires . The filter bubble pushes us in the opposite direction \u2013 it creates the impression that our narrow self-interest is all that exists . And while this is great for getting people to shop online , it \u2019 s not great for getting people to make better decisions together .\nIn a review of the book that same year , Slate head Jacob Weisberg argued that Pariser \u2019 s worries were of a piece with other web skeptics , a class of critics who worried that the web would turn \u201c into everybody \u2019 s narcissistic \u2018 Daily Me \u2019 feed , \u201d though he thought that the web \u2019 s development in the previous 15 years didn \u2019 t attest to that . He quipped that Watson wasn \u2019 t going to beat Jill Abramson in news judgment any time soon , but here \u2019 s the thing : These algorithms aren \u2019 t optimizing for journalism , they \u2019 re optimizing for engagement .\nConsider Facebook . The social network reaches 67 percent of American adults , Pew reports , and over 40 percent get news from the platform . It has \u201c centralized online news consumption in an unprecedented way , \u201d Jon Herrman wrote in the New York Times this August , and as such , it \u2019 s \u201c hosting a huge portion of the political conversation in America. \u201d It \u2019 s incredibly potent , and not just in the sense that manipulating people \u2019 s news feeds makes them more likely to vote .\nIn a 2015 study run by Facebook data scientists and published in Nature , researchers set out to test the filter-bubble hypothesis by looking at ten million de-identified Facebook users who self-reported their ideological affiliation over a six-month period . They found that users only clicked on 7 percent of \u201c hard \u201d content ( politics , national news ) in their feeds , as opposed to \u201c soft \u201d content like entertainment , sports , or travel . The researchers found that conservatives see about 5 percent less ideologically diverse content than their more moderate friends , with liberals at 8 percent . The Facebook algorithm , they concluded , makes it 1 percent less likely that people are exposed to cross-cutting content . More than anything , it \u2019 s the friends you have : \u201c We show that the composition of our social networks is the most important factor limiting the mix of content encountered in social media. \u201d While \u201c news feed \u201d is clever , sticky branding , it \u2019 s more \u201c \u2019 my friend \u2019 s opinions \u2019 feed. \u201d Notably , the study with the largest data set on Facebook virality , out earlier this year , found that feelings of dominance predicted sharing , while arousal \u2014 getting angry or upset \u2014 predicted commenting .\nAs patterns of media consumption change , so do media structures \u2014 creating the space for extreme , identity-validating sites like Breitbart to flourish , as well as news and advocacy pages built specifically for Facebook , which Herrman , the Times media reporter , so precisely identified , and basically just exist on the platform , with names like \u201c Occupy Democrats ; The Angry Patriot ; US Chronicle ; Addicting Info ; RightAlerts ; Being Liberal ; Opposing Views ; Fed-Up Americans ; American News ; and hundreds more , \u201d he writes . This also allows for the proliferation of disinformation sites run by Balkan teens . It \u2019 s \u201c ideological media , \u201d says Usher Layser , and it \u2019 s booming .\n\u201c Ideological media has grown to significant degrees , it can be automated , done by people who can put up decent websites and content that looks real , and people turn to \u2018 information \u2019 that isn \u2019 t information , \u201d she says . \u201c What we see now is the birth of highly profitable small-scale ideological media that scales big on social because only one viral hit on one of these is enough to keep it afloat , and no original reporting is required . It \u2019 s genius . No infrastructure required to put these up. \u201d Tiny sites like that shouldn \u2019 t be able to thrive , she says , since usually small sites are crowded out of the currents of virality . But today , there \u2019 s a \u201c there \u2019 s a greater connection between the ideological media ( even batshit sites ) and elites , \u201d like a Drudge or a Trump , she says . \u201c Basically , the tie between right-wing crap sites and elites is stronger than ever before , and add Facebook + filter bubbles = viral splash. \u201d The dark side of viral news isn \u2019 t cat listicles . It \u2019 s ideological scaling .",
    "content_original": "Photo: Mark Wilson/Getty Images\n\nDonald Trump\u2019s victory is blindsiding, like stepping into a crosswalk and getting slammed into by a delivery guy cycling the wrong way down a one-way street. This is because, as media scholars understand it, we increasingly live in a \u201cfilter bubble\u201d: The information we take in is so personalized that we\u2019re blind to other perspectives. It simultaneously explains why Trumpism has flourished and why so many of us are insulated from it.\n\nTo George Washington University media-studies assistant professor Nikki Usher Layser, the filter-bubbledness of the Trump victory speaks to how, more than ever before, people now have the ability for \u201cmass self-communication,\u201d where you can share your perspectives, with friends you don\u2019t see in person everyday, with the push of a button. Not just the people you see in real life, but that girl from high school you never really got along with but who agrees with your opinions today.\n\n\u201cWe have always surrounded ourselves with people who agree with us [and] sought information we agree with, but there was at least a chance for serendipity,\u201d she says, the chance that you\u2019d discover something outside what you\u2019d ordinarily choose to read yourself, even if you spend all day reading content. The big difference now, she told Science of Us, is the \u201cautonomous decision-making\u201d governing what stories you see. While newsrooms aren\u2019t perfect, they can at least have the contextual awareness to offer contrasting narratives of what\u2019s going in the news. \u201cWe can\u2019t break out of patterns if we only consume information online, through our social feeds,\u201d she says. It\u2019s like explaining water to fish, this invisible, enveloping filter bubble.\n\nThe phrase got coined by MoveOn and Upworthy activist Eli Pariser, with his 2011 best seller, The Filter Bubble: What the Internet Is Hiding from You. His thesis was that while we might think of the internet as an impartial, universal library with Google serving as a superhuman Dewey decimal system, it\u2019s remarkably, and perhaps pathologically, individualized. \u201cYour filter bubble is this unique, personal universe of information created just for you by this array of personalizing filters,\u201d he said in an interview with Amazon. \u201cIt\u2019s invisible and it\u2019s becoming more and more difficult to escape.\u201d Back then, Pariser liked to say that Google used 57 signals to tailor its search results to you; today, the search giant says it\u2019s over 200.\n\nGiven the events of last night \u2014 and the last year \u2014 this passage is strikingly prescient:\n\n\u201cUltimately, democracy works only if we citizens are capable of thinking beyond our narrow self-interest. But to do so, we need a shared view of the world we cohabit. We need to come into contact with other people\u2019s lives and needs and desires. The filter bubble pushes us in the opposite direction \u2013 it creates the impression that our narrow self-interest is all that exists. And while this is great for getting people to shop online, it\u2019s not great for getting people to make better decisions together.\n\nIn a review of the book that same year, Slate head Jacob Weisberg argued that Pariser\u2019s worries were of a piece with other web skeptics, a class of critics who worried that the web would turn \u201cinto everybody\u2019s narcissistic \u2018Daily Me\u2019 feed,\u201d though he thought that the web\u2019s development in the previous 15 years didn\u2019t attest to that. He quipped that Watson wasn\u2019t going to beat Jill Abramson in news judgment any time soon, but here\u2019s the thing: These algorithms aren\u2019t optimizing for journalism, they\u2019re optimizing for engagement.\n\nConsider Facebook. The social network reaches 67 percent of American adults, Pew reports, and over 40 percent get news from the platform. It has \u201ccentralized online news consumption in an unprecedented way,\u201d Jon Herrman wrote in the New York Times this August, and as such, it\u2019s \u201chosting a huge portion of the political conversation in America.\u201d It\u2019s incredibly potent, and not just in the sense that manipulating people\u2019s news feeds makes them more likely to vote.\n\nIn a 2015 study run by Facebook data scientists and published in Nature, researchers set out to test the filter-bubble hypothesis by looking at ten million de-identified Facebook users who self-reported their ideological affiliation over a six-month period. They found that users only clicked on 7 percent of \u201chard\u201d content (politics, national news) in their feeds, as opposed to \u201csoft\u201d content like entertainment, sports, or travel. The researchers found that conservatives see about 5 percent less ideologically diverse content than their more moderate friends, with liberals at 8 percent. The Facebook algorithm, they concluded, makes it 1 percent less likely that people are exposed to cross-cutting content. More than anything, it\u2019s the friends you have: \u201cWe show that the composition of our social networks is the most important factor limiting the mix of content encountered in social media.\u201d While \u201cnews feed\u201d is clever, sticky branding, it\u2019s more \u201c\u2019my friend\u2019s opinions\u2019 feed.\u201d Notably, the study with the largest data set on Facebook virality, out earlier this year, found that feelings of dominance predicted sharing, while arousal \u2014 getting angry or upset \u2014 predicted commenting.\n\nAs patterns of media consumption change, so do media structures \u2014 creating the space for extreme, identity-validating sites like Breitbart to flourish, as well as news and advocacy pages built specifically for Facebook, which Herrman, the Times media reporter, so precisely identified, and basically just exist on the platform, with names like \u201cOccupy Democrats; The Angry Patriot; US Chronicle; Addicting Info; RightAlerts; Being Liberal; Opposing Views; Fed-Up Americans; American News; and hundreds more,\u201d he writes. This also allows for the proliferation of disinformation sites run by Balkan teens. It\u2019s \u201cideological media,\u201d says Usher Layser, and it\u2019s booming.\n\n\u201cIdeological media has grown to significant degrees, it can be automated, done by people who can put up decent websites and content that looks real, and people turn to \u2018information\u2019 that isn\u2019t information,\u201d she says. \u201cWhat we see now is the birth of highly profitable small-scale ideological media that scales big on social because only one viral hit on one of these is enough to keep it afloat, and no original reporting is required. It\u2019s genius. No infrastructure required to put these up.\u201d Tiny sites like that shouldn\u2019t be able to thrive, she says, since usually small sites are crowded out of the currents of virality. But today, there\u2019s a \u201cthere\u2019s a greater connection between the ideological media (even batshit sites) and elites,\u201d like a Drudge or a Trump, she says. \u201cBasically, the tie between right-wing crap sites and elites is stronger than ever before, and add Facebook + filter bubbles = viral splash.\u201d The dark side of viral news isn\u2019t cat listicles. It\u2019s ideological scaling.",
    "source_url": "www.nymag.com",
    "bias_text": "left",
    "ID": "1o4oAvIlIkyA55BK"
}