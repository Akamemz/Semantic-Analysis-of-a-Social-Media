{
    "topic": "media_bias",
    "source": "USA TODAY",
    "bias": 1,
    "url": "https://www.usatoday.com/story/tech/2020/01/08/deepfakes-facebook-youtube-donald-trump-election/2836428001/",
    "title": "Fake Trump video? How to spot deepfakes on Facebook and YouTube ahead of the presidential election",
    "date": "2020-01-08",
    "authors": "",
    "content": "Just months before the presidential election , Facebook says it 's taking steps to combat deepfakes , videos that have been manipulated using artificial intelligence to make it appear that someone has said or done something they have n't .\nFacebook is banning videos that are `` edited or synthesized '' to fool users but will allow parody and satire .\nWhy now ? Many fear this insidious form of digital disinformation could be used to mislead voters , much the same way that fabricated news stories influenced public opinion in 2016 .\nSo what are deepfakes anyway and just how worried should you be that the video you are watching is n't real ?\nDeepfakes are videos doctored using cutting-edge artificial intelligence , or AI , to distort reality . The technology , which analyzes real images to generate fake ones , is a growing form of disinformation and social media platforms have been struggling with how to deal with it .\nFacebook and other tech companies are sponsoring a `` Deepfake Detection Challenge '' to encourage AI researchers to develop new ways to automatically detect doctored videos .\nWait , is that video real ? The dangers of manipulated recordings\nThe ability to create fake videos or manipulate existing videos has been around for decades but typically required some software or skill . In recent years , tools have become popular on social media and elsewhere that allow anyone to manipulate images and video , though this footage usually appears obviously manipulated .\nToday , powerful new technologies are making it cheaper , faster and easier to produce deepfakes that are \u201c nearly indistinguishable from reality , \u201d says Hao Li , associate professor of computer science at the University of Southern California .\nThere are also simpler but still effective ways to hoodwink social media users called `` cheap fakes , '' which typically involve editing videos to spread disinformation or propaganda .\nDigitally manipulated video is dangerous because we tend to have faith in what we see , Li says . \u201c It \u2019 s a real problem , and it \u2019 s something that is advancing really quickly , \u201d he says . \u201c Regulators and lawmakers are not catching up with this kind of technology . \u201d\nFacebook 's new deepfake policy is too narrow , says Hany Farid , a computer science professor at University of California , Berkeley specializing in digital forensics .\nUnder the policy , Facebook would not prohibit videos using lower-tech methods of spreading disinformation , such as last year 's video of House Speaker Nancy Pelosi which was edited to make it seem as though she was slurring her speech , Monika Bickert , vice president of global policy management , told lawmakers during a Wednesday congressional hearing .\n`` What they are saying is : If it \u2019 s a misleading video of someone saying something they didn \u2019 t say and it was created using this specific type of technology , deepfakes , then we reserve the right to take it down , but if it was generated using some other kind of technique , we don \u2019 t have a problem with that , \u201d Farid says . \u201c That doesn \u2019 t really make sense . The issue is not how it was made , the issue is : Is it misleading and is it harmful ? \u201d\nRachel Thomas , director of the Center for Applied Data Ethics at University of San Francisco , says she expects `` cheap fakes '' and the more sophisticated deepfakes to proliferate ahead of the presidential election as part of shadowy campaigns to sway public opinion .\nImagine a fake Donald Trump or a fake Joe Biden simulated saying a racial slur . Then imagine how quickly those videos would spread on Facebook or YouTube .\n`` The stakes are very high , '' Thomas says . `` This kind of misinformation can have a big impact . ''\nWhen used to target elected officials or political candidates , doctored video can erode trust . Nearly two-thirds of Americans recently surveyed by Pew Research said altered images and videos caused a great deal of confusion in understanding the basic facts of current events .\nHow can you tell if the video you 're watching is a deepfake ?\n\u201c That is becoming incredibly difficult . The technology behind fake videos is improving almost on a continuous basis , \u201d says Siwei Lyu , computer science professor at the State University of New York at Albany and a member of the Deepfake Detection Challenge \u2019 s advisory group .\nHe recommends \u201c psychological preparedness , \u201d as in being constantly on the alert for videos , images and audio that have been altered .\n\u201c Whenever you see an interesting video showing something that is bizarre or exceptional , a certain vigilance should be raised , \u201d he says .\nExamine the video carefully before sharing it on social media . Is the video low-resolution or grainy ? Is it a single person talking in the video ? Is it relatively short , say 30 seconds or 60 seconds long ?\nIs the lighting strange or the face discolored or blurry ? Is there blurriness between the face and neck or between the face and the hair ? Is the sound not synced with the images ?\nSome of the other tell-tale signs discernible to the naked eye , according to Subbarao Kambhampati , a computer science professor at Arizona State University : different-sized eyes or ill-formed teeth , or more than two eyes , or inconsistencies in the background of the video .\nBut , says Kambhampati , the rapid improvements in deepfake technology means that we will soon have to rely on AI techniques to detect what the human eye can not .\n`` There is not a 100 % foolproof way of identifying deepfakes , not even for AI researchers , '' Thomas says . `` Detection is always going to be an arms race . As people develop more accurate detection algorithms , fakers will develop even more sophisticated frauds . ''\nThere are non-technical ways to sniff out a deepfake , just like other forms of disinformation . Ask yourself : Who is the person publishing this information ? Is this person reliable ? What else has this person posted ? Are the claims in the post backed up by sources you trust ?\nWhen in doubt , turn to nonpartisan fact-checkers who 've spent hours , sometimes days , tracking down accurate information , Farid says .\n`` You never want to jump to a conclusion one way or another , you never want to say : I looked at this and I \u2019 m sure it \u2019 s real or I looked at this and I \u2019 m sure it \u2019 s fake , '' he says . `` The best you can really hope to do is to say : You know what ? I should be careful here because I \u2019 m not sure , and then research it . \u201d\nLi says his company , Pinscreen , will demonstrate for attendees of the World Economic Forum in Davos how to livestream fake video .\nHe says it 's part of an effort to raise awareness of the need for technologies that root out deepfakes .\n\u201c In real-time , you can reenact yourself as Will Smith or some celebrity or a politician . You can be George Bush , '' he says . `` The results are very convincing . ''",
    "content_original": "USA TODAY\n\nJust months before the presidential election, Facebook says it's taking steps to combat deepfakes, videos that have been manipulated using artificial intelligence to make it appear that someone has said or done something they haven't.\n\nFacebook is banning videos that are \"edited or synthesized\" to fool users but will allow parody and satire.\n\nWhy now? Many fear this insidious form of digital disinformation could be used to mislead voters, much the same way that fabricated news stories influenced public opinion in 2016.\n\nSo what are deepfakes anyway and just how worried should you be that the video you are watching isn't real?\n\nFake but convincing videos\n\nDeepfakes are videos doctored using cutting-edge artificial intelligence, or AI, to distort reality. The technology, which analyzes real images to generate fake ones, is a growing form of disinformation and social media platforms have been struggling with how to deal with it.\n\nFacebook and other tech companies are sponsoring a \"Deepfake Detection Challenge\" to encourage AI researchers to develop new ways to automatically detect doctored videos.\n\nFacebook disinformation:What you can do to stop its spread\n\nWait, is that video real? The dangers of manipulated recordings\n\nThe ability to create fake videos or manipulate existing videos has been around for decades but typically required some software or skill. In recent years, tools have become popular on social media and elsewhere that allow anyone to manipulate images and video, though this footage usually appears obviously manipulated.\n\nToday, powerful new technologies are making it cheaper, faster and easier to produce deepfakes that are \u201cnearly indistinguishable from reality,\u201d says Hao Li, associate professor of computer science at the University of Southern California.\n\nThere are also simpler but still effective ways to hoodwink social media users called \"cheap fakes,\" which typically involve editing videos to spread disinformation or propaganda.\n\nDigitally manipulated video is dangerous because we tend to have faith in what we see, Li says. \u201cIt\u2019s a real problem, and it\u2019s something that is advancing really quickly,\u201d he says. \u201cRegulators and lawmakers are not catching up with this kind of technology.\u201d\n\nFacebook's new deepfake policy is too narrow, says Hany Farid, a computer science professor at University of California, Berkeley specializing in digital forensics.\n\nUnder the policy, Facebook would not prohibit videos using lower-tech methods of spreading disinformation, such as last year's video of House Speaker Nancy Pelosi which was edited to make it seem as though she was slurring her speech, Monika Bickert, vice president of global policy management, told lawmakers during a Wednesday congressional hearing.\n\n\"What they are saying is: If it\u2019s a misleading video of someone saying something they didn\u2019t say and it was created using this specific type of technology, deepfakes, then we reserve the right to take it down, but if it was generated using some other kind of technique, we don\u2019t have a problem with that,\u201d Farid says. \u201cThat doesn\u2019t really make sense. The issue is not how it was made, the issue is: Is it misleading and is it harmful?\u201d\n\nWhy you should worry (no, really)\n\nRachel Thomas, director of the Center for Applied Data Ethics at University of San Francisco, says she expects \"cheap fakes\" and the more sophisticated deepfakes to proliferate ahead of the presidential election as part of shadowy campaigns to sway public opinion.\n\nImagine a fake Donald Trump or a fake Joe Biden simulated saying a racial slur. Then imagine how quickly those videos would spread on Facebook or YouTube.\n\n\"The stakes are very high,\" Thomas says. \"This kind of misinformation can have a big impact.\"\n\nWhen used to target elected officials or political candidates, doctored video can erode trust. Nearly two-thirds of Americans recently surveyed by Pew Research said altered images and videos caused a great deal of confusion in understanding the basic facts of current events.\n\nHow can you spot deepfakes?\n\nHow can you tell if the video you're watching is a deepfake?\n\n\u201cThat is becoming incredibly difficult. The technology behind fake videos is improving almost on a continuous basis,\u201d says Siwei Lyu, computer science professor at the State University of New York at Albany and a member of the Deepfake Detection Challenge\u2019s advisory group.\n\nHe recommends \u201cpsychological preparedness,\u201d as in being constantly on the alert for videos, images and audio that have been altered.\n\n\u201cWhenever you see an interesting video showing something that is bizarre or exceptional, a certain vigilance should be raised,\u201d he says.\n\nExamine the video carefully before sharing it on social media. Is the video low-resolution or grainy? Is it a single person talking in the video? Is it relatively short, say 30 seconds or 60 seconds long?\n\nIs the lighting strange or the face discolored or blurry? Is there blurriness between the face and neck or between the face and the hair? Is the sound not synced with the images?\n\nSome of the other tell-tale signs discernible to the naked eye, according to Subbarao Kambhampati, a computer science professor at Arizona State University: different-sized eyes or ill-formed teeth, or more than two eyes, or inconsistencies in the background of the video.\n\nBut, says Kambhampati, the rapid improvements in deepfake technology means that we will soon have to rely on AI techniques to detect what the human eye cannot.\n\n\"There is not a 100% foolproof way of identifying deepfakes, not even for AI researchers,\" Thomas says. \"Detection is always going to be an arms race. As people develop more accurate detection algorithms, fakers will develop even more sophisticated frauds.\"\n\nThere are non-technical ways to sniff out a deepfake, just like other forms of disinformation. Ask yourself: Who is the person publishing this information? Is this person reliable? What else has this person posted? Are the claims in the post backed up by sources you trust?\n\nWhen in doubt, turn to nonpartisan fact-checkers who've spent hours, sometimes days, tracking down accurate information, Farid says.\n\n\"You never want to jump to a conclusion one way or another, you never want to say: I looked at this and I\u2019m sure it\u2019s real or I looked at this and I\u2019m sure it\u2019s fake,\" he says. \"The best you can really hope to do is to say: You know what? I should be careful here because I\u2019m not sure, and then research it.\u201d\n\nFair warning: It's going to get worse\n\nLi says his company, Pinscreen, will demonstrate for attendees of the World Economic Forum in Davos how to livestream fake video.\n\nHe says it's part of an effort to raise awareness of the need for technologies that root out deepfakes.\n\n\u201cIn real-time, you can reenact yourself as Will Smith or some celebrity or a politician. You can be George Bush,\" he says. \"The results are very convincing.\"",
    "source_url": "www.usatoday.com",
    "bias_text": "center",
    "ID": "8UKw1oKaG5djEm2b"
}