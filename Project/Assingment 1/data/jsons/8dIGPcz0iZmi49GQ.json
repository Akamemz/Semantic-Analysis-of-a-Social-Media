{
    "topic": "privacy",
    "source": "Bloomberg",
    "bias": 1,
    "url": "https://www.bloomberg.com/news/features/2019-12-11/silicon-valley-got-millions-to-let-siri-and-alexa-listen-in?srnd=businessweek-v2&cmpid=socialflow-twitter-businessweek&utm_campaign=socialflow-organic&utm_medium=social&utm_source=twitter&utm_content=businessweek",
    "title": "Silicon Valley Is Listening to Your Most Intimate Moments",
    "date": "2019-12-11",
    "authors": "Austin Carr, Matt Day, Sarah Frier, Mark Gurman",
    "content": "Ruthy Hope Slatis couldn \u2019 t believe what she was hearing . She \u2019 d been hired by a temp agency outside Boston for a vague job : transcribing audio files for Amazon.com Inc. For $ 12 an hour , she and her fellow contractors , or \u201c data associates , \u201d listened to snippets of random conversations and jotted down every word on their laptops . Amazon would only say the work was critical to a top-secret speech-recognition product . The clips included recordings of intimate moments inside people \u2019 s homes .\nThis was in fall 2014 , right around the time Amazon unveiled the Echo speaker featuring Alexa , its voice-activated virtual-assistant software . Amazon pitched Alexa as a miracle of artificial intelligence in its first Echo ad , in which a family asked for and received news updates , answers to trivia questions , and help with the kids \u2019 homework . But Slatis soon began to grasp the extent to which humans were behind the robotic magic she saw in the commercial . \u201c Oh my God , that \u2019 s what I \u2019 m working on , \u201d she remembers thinking . Amazon was capturing every voice command in the cloud and relying on data associates like her to train the system . Slatis first figured she \u2019 d been listening to paid testers who \u2019 d volunteered their vocal patterns in exchange for a few bucks . She realized that couldn \u2019 t be .\nThe recordings she and her co-workers were listening to were often intense , awkward , or intensely awkward . Lonely sounding people confessing intimate secrets and fears : a boy expressing a desire to rape ; men hitting on Alexa like a crude version of Joaquin Phoenix in Her . And as the transcription program grew along with Alexa \u2019 s popularity , so did the private information revealed in the recordings . Other contractors recall hearing kids share their home address and phone number , a man trying to order sex toys , a dinner party guest wondering aloud whether Amazon was snooping on them at that very instant . \u201c There \u2019 s no frickin \u2019 way they knew they were being listened to , \u201d Slatis says . \u201c These people didn \u2019 t agree to this. \u201d She quit in 2016 .\nIn the five years since Slatis first felt her skin crawl , a quarter of Americans have bought \u201c smart speaker \u201d devices such as the Echo , Google Home , and Apple HomePod . ( A relative few have even bought Facebook \u2019 s Portal , an adjacent smart video screen . ) Amazon is winning the sales battle so far , reporting that more than 100 million Alexa devices have been purchased . But now a war is playing out between the world \u2019 s biggest companies to weave Alexa , Apple \u2019 s Siri , Alphabet \u2019 s Google Assistant , Microsoft \u2019 s Cortana , and Facebook \u2019 s equivalent service much deeper into people \u2019 s lives . Mics are built into phones , smartwatches , TVs , fridges , SUVs , and everything in between . Consulting firm Juniper Research Ltd. estimates that by 2023 the global annual market for smart speakers will reach $ 11 billion , and there will be about 7.4 billion voice-controlled devices in the wild . That \u2019 s about one for every person on Earth .\nThe question is , then what ? These machines are not creating audio files of your every decibel\u2014tech companies say their smart speakers record audio only when users activate them\u2014but they are introducing always-on mics to kitchens and bedrooms , which could inadvertently capture sounds users never intended to share . \u201c Having microphones that listen all the time is concerning . We \u2019 ve found that users of these devices close their eyes and trust that companies are not going to do anything bad with their recorded data , \u201d says Florian Schaub , a University of Michigan professor who studies human behavior around voice-command software . \u201c There \u2019 s this creeping erosion of privacy that just keeps going and going . People don \u2019 t know how to protect themselves . \u201d\nAmazon declined interview requests for this story . In an emailed statement , a spokeswoman wrote , \u201c Privacy is foundational to how every team and employee designs and develops Alexa features and Echo devices . All Alexa employees are trained on customer data handling as part of our security training. \u201d The company and its competitors have said computers perform the vast majority of voice requests without human review .\nYet so-called smart devices inarguably depend on thousands of low-paid humans who annotate sound snippets so tech companies can upgrade their electronic ears ; our faintest whispers have become one of their most valuable datasets . Earlier this year , \u2588\u2588\u2588 News was first to report on the scope of the technology industry \u2019 s use of humans to review audio collected from their users without disclosures , including at Apple , Amazon , and Facebook . Few executives and engineers who spoke with \u2588\u2588\u2588 Businessweek for this story say they anticipated that setting up vast networks of human listeners would be problematic or intrusive . To them , it was and is simply an obvious way to improve their products .\nCurrent and former contractors such as Slatis make clear that the downsides of pervasive audio surveillance were obvious to those with much less financial upside at stake . \u201c It never felt right , \u201d says a voice transcriber for an Alexa rival who , like most of the contractors , signed a nondisclosure agreement and spoke on condition of anonymity for fear of reprisals . \u201c What are they really selling to customers ? \u201d\nNerds have imagined voice commands to be the future of computing for more than a half-century . ( Thank Star Trek . ) But for most of that time , teaching machines to identify and respond to spoken sentences required matching audio files verbatim to transcribed text , a slow and expensive process . Early pioneers bought or built massive libraries of recordings\u2014people reading newspapers or other prewritten material into mics . The Sisyphean nature of the projects eventually became an industry joke . In the 1990s , a former product manager on the speech team at Apple Inc. recalls , it offered each volunteer willing to record voice patterns at their lab a T-shirt emblazoned with the phrase \u201c I Helped Apple Wreck a Nice Beach , \u201d a computer \u2019 s garble of \u201c recognize speech . \u201d\nFeatured in \u2588\u2588\u2588 Businessweek , Dec. 16 , 2019 . Subscribe now Illustration : Scott Gelber for \u2588\u2588\u2588 Businessweek\nApple , which declined to comment for this story , became the first major company to flip the model in 2011 , when it shipped the iPhone 4S with Siri , acquired the year before from a Pentagon-funded research spinoff . No longer did recordings have to be scripted and amassed in labs . Apple sold more than 4 million 4S phones within days , and soon began piling up an incalculable mountain of free , natural voice data . For the first few years , the company largely trusted outside speech-software specialists to use the data to improve Siri \u2019 s abilities , but Apple retook control around 2014 . \u201c The work was very tedious : After listening for 15 or 30 minutes , you \u2019 d get headaches , \u201d Tao Ma , a former senior Siri speech scientist , says of transcribing user recordings . The in-house team farmed out much of this work to IT contractors in Europe , including Ireland-based GlobeTech .\nOver the past few years , Apple has grown more aggressive in its harvesting and analysis of people \u2019 s voices , worried that Siri \u2019 s comprehension and speed were falling behind those of Alexa and Google Assistant . Apple treated Siri \u2019 s development like a verbal search engine that it had to prep to fulfill endless user queries and ramped up its dependence on audio analysis to feed the assistant \u2019 s lexicon . Temps were expected to account for the clips \u2019 various languages , dialects , and cultural idiosyncrasies .\nFormer contractors describe the system as something out of the Tower of Babel or George Orwell \u2019 s 1984 . At a GlobeTech office near an airport in Cork , Ireland , some say , they sat in silence at MacBooks wearing headphones , tasked with transcribing 1,300 clips a day , each of which could be a single sentence or an entire conversation . ( This quota was reduced from as many as 2,500 clips , others say , to improve accuracy rates . ) When a contractor clicked play on a voice recording , the computer filled a text box with the words it thought Siri \u201c heard , \u201d then prompted the worker to approve or correct the translation and move on . GlobeTech didn \u2019 t respond to requests for comment .\nA program the workers used , called CrowdCollect , included buttons to skip recordings for a variety of reasons\u2014accidental trigger , missing audio , wrong language\u2014but contractors say there was no specific mechanism to report or delete offensive or inappropriate audio , such as drunk-sounding users slurring demands into the mics or people dictating sexts . Contractors who asked managers whether they could skip overly private clips were told no clips were too private . They were expected to transcribe anything that came in . Contractors often lasted only a couple of months , and training on privacy issues was minimal . One former contractor who had no qualms about the work says listening in on real-world users was \u201c absolutely hilarious . \u201d\nIn 2015 , the same year Apple Chief Executive Officer Tim Cook called privacy a \u201c fundamental human right , \u201d Apple \u2019 s machines were processing more than a billion requests a week . By then , users could turn on a feature so they no longer had to push a button on the iPhone to activate the voice assistant ; it was always listening . Deep in its user agreement legalese , Apple said voice data might be recorded and analyzed to improve Siri , but nowhere did it mention that fellow humans might listen . \u201c I felt extremely uncomfortable overhearing people , \u201d says one of the former contractors , especially given how often the recordings were of children .\nTen former Apple executives in the Siri division say they didn \u2019 t and still don \u2019 t see this system as a violation of privacy . These former executives say recordings were disassociated from Apple user IDs , and they assumed users understood the company was processing their audio clips , so what did it matter if humans helped with the processing ? \u201c We felt emotionally safe , that this was the right thing to do , \u201d says John Burkey , who worked in Siri \u2019 s advanced development group until 2016 . \u201c It wasn \u2019 t spying . It was , \u2018 This [ Siri request ] doesn \u2019 t work . Let \u2019 s fix it. \u2019 It \u2019 s the same as when an app crashes and asks if you want to send the report to Apple . This is just a voice bug . \u201d\nThe difference between this system and a bug on a MacBook , of course , is that MacOS clearly asks users if they \u2019 d like to submit a report directly after a program crashes . It \u2019 s an opt-in prompt for each malfunction , as opposed to Siri \u2019 s blanket consent . Current and former contractors say most Siri requests are banal\u2014 \u201c play a Justin Bieber song , \u201d \u201c where \u2019 s the nearest McDonald \u2019 s \u201d \u2014but they also recall hearing extremely graphic messages and lengthy racist or homophobic rants . A former data analyst who worked on Siri transcriptions for several years says workers in Cork swapped horror stories during smoke breaks . A current analyst , asked to recount the most outrageous clip to come through CrowdCollect , says it was akin to a scene from Fifty Shades of Grey .\nApple has said less than 0.2 % of Siri requests undergo human analysis , and former managers dismiss the contractors \u2019 accounts as overemphases on mere rounding errors . \u201c \u2018 Oh , I heard someone having sex \u2019 or whatever . You also hear people farting and sneezing\u2014there \u2019 s all kind of noise out there when you turn a microphone on , \u201d says Tom Gruber , a Siri co-founder who led its advanced development group through 2018 . \u201c It \u2019 s not like the machine has an intention to record people making certain kinds of sounds . It \u2019 s like a statistical fluke . \u201d\nBy 2019 , after Apple brought Siri to products such as its wireless headphones and HomePod speaker , it was processing 15 billion voice commands a month ; 0.2 % of 15 billion is still 30 million potential flukes a month , or 360 million a year . The risks of inadvertent recording grew along with the use cases , says Mike Bastian , a former principal research scientist on the Siri team who left Apple earlier this year . He cites the Apple Watch \u2019 s \u201c raise to speak \u201d feature , which automatically activates Siri when it detects a wearer \u2019 s wrist being lifted , as especially dicey . \u201c There was a high false positive rate , \u201d he says .\nIn the smart speaker business , Apple \u2019 s HomePod is estimated to account for only 5 % of the U.S. market . Amazon has an estimated 70 % . In 2011 CEO and massive Star Trek fan Jeff Bezos ordered a team that showed him an early voice-controlled music app to build the software into a hardware product . They produced the Echo , with its seven microphones constantly listening for a \u201c wake word \u201d that will trigger a fresh recording . Each clip , as with Apple \u2019 s , goes to the company \u2019 s servers , where a portion of them are then routed to one of hundreds of data associates for review .\nBezos and David Limp , Amazon \u2019 s senior vice president for devices , weren \u2019 t blind to the creep factor . They made design choices aimed at keeping Echo users from freaking out about being recorded , says an early Alexa product manager . When a user says \u201c Alexa , \u201d a ring of light appears around the Echo , as though the assistant were coming to life . A dedicated \u201c personality team \u201d scripted jokey answers to hundreds of frequently asked questions . And developers created an online portal where users could play and delete their audio clips . An Amazon spokeswoman says privacy standards were built into Alexa from the start .\nThe fine print grants Amazon the right to retain and experiment on its voice clips far beyond what Apple does with Siri . By default , the company retains recordings indefinitely . Amazon discloses few specifics on how this data is used , except to say its human transcriptions have proved an enormous advantage in translating Alexa into new languages around the world and expanding its response capabilities .\nIn 2016 , Amazon created the Frequent Utterance Database , or FUD , to help Alexa add answers to common requests . Former employees who worked with FUD say there was tension between product teams eager to mine the data more aggressively and the security team charged with protecting user info , such as phone numbers that could easily identify a given customer . In 2017 , Amazon introduced the camera-equipped Echo Look , which was pitched as an AI stylist that could recommend outfit pairings . Its developers considered programming the camera to switch on automatically when a user asked Alexa to make a joke , say people familiar with the matter . The idea was to record a video of the user \u2019 s face and assess whether she was laughing . Amazon ultimately shelved the idea , these people say . Amazon says Alexa doesn \u2019 t use facial recognition technology today .\nThe company has set up transcription farms in cities around the world , from Bucharest to Chennai . Several times this year , it \u2019 s held walk-in recruiting events for transcribers overseas . A speech technologist who \u2019 s spent decades developing recognition systems for tech companies says the scale of Amazon \u2019 s audio data analysis as outlined in a recent recruiting effort was terrifying . Amazon says it takes the \u201c security of customers and their voice recordings seriously , \u201d and that it needs a complete understanding of regional accents and colloquialisms to make Alexa global .\nThis August , Microsoft acknowledged that humans help review voice data generated through its speech-recognition technology\u2014in products including its Cortana assistant and Skype messaging app\u2014which businesses such as BMW , HP Inc. , and Humana are integrating into their own products and services . Chinese tech companies including marketplace Alibaba , search giant Baidu , and phone maker Xiaomi are churning out millions of smart speakers each quarter . Industry analysts say Google and Facebook Inc. are likewise betting audio data will greatly enhance their mammoth ad businesses . Internet browsing tells these companies a tremendous amount about people , but audio recordings could make it much easier for AI to approximate ages , genders , emotions , and even locations and interests , says Schaub , the University of Michigan professor . \u201c People often don \u2019 t realize what their voice commands reveal , \u201d he says . \u201c If you \u2019 re asking about football a lot , you \u2019 re likely an NFL fan . If a baby is crying in the background , they can infer you have a family . \u201d\nSeveral big tech companies tweaked their virtual-assistant programs this year after a steady drip of news reports\nGoogle Assistant feeds its namesake search engine with queries from a billion devices it \u2019 s available on , including Android smartphones and tablets , Nest thermostats , and Sony TVs . Google , which has hired temp workers overseas to transcribe clips to improve the system \u2019 s accuracy , has promised that reviewed voice recordings aren \u2019 t linked to any personal information . But this summer a Google contractor shared more than 1,000 user recordings with Belgian broadcaster VRT NWS . The outlet was able to figure out who some of the people in the recordings were based on things they said , to the shock of those identified . Roughly 10 % of the leaked clips were also recorded without these users \u2019 consent , because of devices erroneously detecting the activation phrase \u201c OK , Google . \u201d\nA Google spokeswoman says , \u201c Since hearing concerns , we have been committed to pausing this human transcription of Assistant audio while we enhance our privacy controls. \u201d The company declined to comment on whether humans transcribe voice data collected from other Google services . A senior engineer involved with Google Assistant who recently left the company says people would overlook concerns about snooping if voice assistants , including Google \u2019 s , were more useful .\nFacebook , where data privacy scandals have become routine , drew scoffs when it introduced Portal , a combination smart speaker and videophone , in November 2018 . The company had wanted to hold off on releasing Portal until the heat from its Cambridge Analytica debacle had died down , but it wound up unveiling the device , which includes a built-in microphone and camera , soon after a different shocking data leak . Incredibly , Facebook billed the Portal as a privacy-centric project , promising that any stored mic or camera data would be kept on the device and off the cloud . Who wouldn \u2019 t want a Facebook camera tracking them around the living room as they walk and talk ? Besides CEO Mark Zuckerberg , who keeps his laptop \u2019 s mic and camera covered and nonfunctional .\nAt one point or another , pretty much every Facebook user has heard the rumor that the company sharpens its ad targeting by secretly listening to people through the mics in their phones or other devices . When Congress called him to testify last year , Zuckerberg labeled that concern a \u201c conspiracy theory. \u201d Yet Facebook , too , has been relying on transcribed recordings to train its AI , and not just with audio from its users . In one instance , a contractor hired through Accenture Plc was instructed to use her personal Facebook account to call friends and family to create new audio , without telling them why . ( She says this caused her anxiety . ) A source within Facebook confirms the commands were recorded , but the company says it never instructed the actual calls to be captured , saying it \u2019 s \u201c not something we would ever direct to be done. \u201d Accenture referred a request for comment to Facebook .\nFacebook has also relied on human transcribers for its chat app Messenger , which allows users to exchange audio clips instead of texting . The company prompted users with an option to have its AI auto-transcribe these voice messages but didn \u2019 t tell them these clips also went to contractor TaskUs Inc. for manual review . Facebook didn \u2019 t inform the TaskUs workers where the audio clips came from , so they assumed Facebook was using exactly the kind of surveillance dragnet Zuckerberg had told Congress didn \u2019 t exist . It didn \u2019 t help that TaskUs referred to its Facebook contract internally as \u201c Prism , \u201d the same code name used for a National Security Agency spying program revealed in 2013 by whistleblower Edward Snowden .\nAlong with separating voice files from user IDs the way Apple does , Facebook \u2019 s software slightly alters each person \u2019 s vocal pitch before relaying the files to contractors , says Andrew Bosworth , the vice president who oversees Facebook \u2019 s hardware division . He acknowledges that using voice command and video chat tools should require \u201c a lot of faith in the technology distributors behind those tools \u201d but says he trusts Google and Amazon , as well as his own company , to use voice data to improve their services rather than take advantage of sensitive information in the clips . His home in San Mateo , Calif. , is sprinkled with three Portals and four other devices that use either Alexa or Google Assistant , including in his kitchen and his kids \u2019 playroom .\nSeveral of the big tech companies tweaked their virtual-assistant programs this year after a steady drip of news reports . While Google has paused human transcriptions of Assistant audio , Apple has begun letting users delete their Siri history and opt out of sharing more , made sharing recordings optional , and hired many former contractors directly to increase its control over human listening . Facebook and Microsoft have added clearer disclaimers to their privacy policies . And Amazon has introduced a similar disclosure and started letting Alexa users opt out of manual reviews . \u201c It \u2019 s a well-known thing in the industry , \u201d Amazon \u2019 s Limp recently said about human transcription teams . \u201c Whether it was well known among press or customers , it \u2019 s pretty clear we weren \u2019 t good enough there . \u201d\nIt \u2019 s easy to fathom how an authoritarian government or unscrupulous three-letter agency could take advantage of these ubiquitous surveillance networks . The U.S. House of Representatives is considering legislation to curb automated eavesdropping by digital assistants , and a bipartisan group of senators has called for the Federal Trade Commission to investigate Amazon \u2019 s recordings of children , but all the relevant authorities are moving slowly . \u201c Are users aware this processing is happening ? If not , they need to be , \u201d says Dale Sunderland , deputy commissioner of Ireland \u2019 s Data Protection Commission , which supervises tech companies \u2019 compliance with European Union privacy rules and is reviewing the industry \u2019 s audio collection practices . \u201c We want these companies to demonstrate to us how they \u2019 ve built in necessary safeguards. \u201d A June Pew Research Center survey estimated that most Americans are concerned about the data collection practices of smart speakers and similar listening devices . Still , adoption rates keep rising .\nSome researchers say advances in smartphone processing power and a form of computer modeling called federated learning may eventually render this kind of eavesdropping obsolete\u2014that the machines will get smart enough to figure out things without help from the contractors . For now , absent tougher laws or consumer backlash , the ranks of human audio reviewers will almost certainly continue growing to keep pace as listening devices proliferate .\nMany former contractors say they \u2019 ve stopped using virtual assistants and unplugged their listening devices . The audio sexts were awkward and all , but some are more haunted by the idea that people are listening even to the most quotidian of conversations , like a father chatting with his son after school , or a husband and wife talking in the kitchen after work . \u201c In my head , I would say , I shouldn \u2019 t be listening to this , \u201d says a former contractor who spent months working on Siri transcriptions . \u201c This is none of my business. \u201d \u2014With Mark Bergen , Gerrit De Vynck , Natalia Drozdiak , and Giles Turner\nRead more : I Tried Hiding From Silicon Valley in a Pile of Privacy Gadgets",
    "content_original": "SHARE THIS ARTICLE Share Tweet Post Email\n\nRuthy Hope Slatis couldn\u2019t believe what she was hearing. She\u2019d been hired by a temp agency outside Boston for a vague job: transcribing audio files for Amazon.com Inc. For $12 an hour, she and her fellow contractors, or \u201cdata associates,\u201d listened to snippets of random conversations and jotted down every word on their laptops. Amazon would only say the work was critical to a top-secret speech-recognition product. The clips included recordings of intimate moments inside people\u2019s homes.\n\nThis was in fall 2014, right around the time Amazon unveiled the Echo speaker featuring Alexa, its voice-activated virtual-assistant software. Amazon pitched Alexa as a miracle of artificial intelligence in its first Echo ad, in which a family asked for and received news updates, answers to trivia questions, and help with the kids\u2019 homework. But Slatis soon began to grasp the extent to which humans were behind the robotic magic she saw in the commercial. \u201cOh my God, that\u2019s what I\u2019m working on,\u201d she remembers thinking. Amazon was capturing every voice command in the cloud and relying on data associates like her to train the system. Slatis first figured she\u2019d been listening to paid testers who\u2019d volunteered their vocal patterns in exchange for a few bucks. She realized that couldn\u2019t be.\n\nThe recordings she and her co-workers were listening to were often intense, awkward, or intensely awkward. Lonely sounding people confessing intimate secrets and fears: a boy expressing a desire to rape; men hitting on Alexa like a crude version of Joaquin Phoenix in Her. And as the transcription program grew along with Alexa\u2019s popularity, so did the private information revealed in the recordings. Other contractors recall hearing kids share their home address and phone number, a man trying to order sex toys, a dinner party guest wondering aloud whether Amazon was snooping on them at that very instant. \u201cThere\u2019s no frickin\u2019 way they knew they were being listened to,\u201d Slatis says. \u201cThese people didn\u2019t agree to this.\u201d She quit in 2016.\n\nIn the five years since Slatis first felt her skin crawl, a quarter of Americans have bought \u201csmart speaker\u201d devices such as the Echo, Google Home, and Apple HomePod. (A relative few have even bought Facebook\u2019s Portal, an adjacent smart video screen.) Amazon is winning the sales battle so far, reporting that more than 100 million Alexa devices have been purchased. But now a war is playing out between the world\u2019s biggest companies to weave Alexa, Apple\u2019s Siri, Alphabet\u2019s Google Assistant, Microsoft\u2019s Cortana, and Facebook\u2019s equivalent service much deeper into people\u2019s lives. Mics are built into phones, smartwatches, TVs, fridges, SUVs, and everything in between. Consulting firm Juniper Research Ltd. estimates that by 2023 the global annual market for smart speakers will reach $11 billion, and there will be about 7.4 billion voice-controlled devices in the wild. That\u2019s about one for every person on Earth.\n\nAmazon\u2019s Echo Plus Source: Amazon\n\nThe question is, then what? These machines are not creating audio files of your every decibel\u2014tech companies say their smart speakers record audio only when users activate them\u2014but they are introducing always-on mics to kitchens and bedrooms, which could inadvertently capture sounds users never intended to share. \u201cHaving microphones that listen all the time is concerning. We\u2019ve found that users of these devices close their eyes and trust that companies are not going to do anything bad with their recorded data,\u201d says Florian Schaub, a University of Michigan professor who studies human behavior around voice-command software. \u201cThere\u2019s this creeping erosion of privacy that just keeps going and going. People don\u2019t know how to protect themselves.\u201d\n\nAmazon declined interview requests for this story. In an emailed statement, a spokeswoman wrote, \u201cPrivacy is foundational to how every team and employee designs and develops Alexa features and Echo devices. All Alexa employees are trained on customer data handling as part of our security training.\u201d The company and its competitors have said computers perform the vast majority of voice requests without human review.\n\nYet so-called smart devices inarguably depend on thousands of low-paid humans who annotate sound snippets so tech companies can upgrade their electronic ears; our faintest whispers have become one of their most valuable datasets. Earlier this year, Bloomberg News was first to report on the scope of the technology industry\u2019s use of humans to review audio collected from their users without disclosures, including at Apple, Amazon, and Facebook. Few executives and engineers who spoke with Bloomberg Businessweek for this story say they anticipated that setting up vast networks of human listeners would be problematic or intrusive. To them, it was and is simply an obvious way to improve their products.\n\nCurrent and former contractors such as Slatis make clear that the downsides of pervasive audio surveillance were obvious to those with much less financial upside at stake. \u201cIt never felt right,\u201d says a voice transcriber for an Alexa rival who, like most of the contractors, signed a nondisclosure agreement and spoke on condition of anonymity for fear of reprisals. \u201cWhat are they really selling to customers?\u201d\n\nNerds have imagined voice commands to be the future of computing for more than a half-century. (Thank Star Trek.) But for most of that time, teaching machines to identify and respond to spoken sentences required matching audio files verbatim to transcribed text, a slow and expensive process. Early pioneers bought or built massive libraries of recordings\u2014people reading newspapers or other prewritten material into mics. The Sisyphean nature of the projects eventually became an industry joke. In the 1990s, a former product manager on the speech team at Apple Inc. recalls, it offered each volunteer willing to record voice patterns at their lab a T-shirt emblazoned with the phrase \u201cI Helped Apple Wreck a Nice Beach,\u201d a computer\u2019s garble of \u201crecognize speech.\u201d\n\nFeatured in Bloomberg Businessweek, Dec. 16, 2019. Subscribe now Illustration: Scott Gelber for Bloomberg Businessweek\n\nApple, which declined to comment for this story, became the first major company to flip the model in 2011, when it shipped the iPhone 4S with Siri, acquired the year before from a Pentagon-funded research spinoff. No longer did recordings have to be scripted and amassed in labs. Apple sold more than 4 million 4S phones within days, and soon began piling up an incalculable mountain of free, natural voice data. For the first few years, the company largely trusted outside speech-software specialists to use the data to improve Siri\u2019s abilities, but Apple retook control around 2014. \u201cThe work was very tedious: After listening for 15 or 30 minutes, you\u2019d get headaches,\u201d Tao Ma, a former senior Siri speech scientist, says of transcribing user recordings. The in-house team farmed out much of this work to IT contractors in Europe, including Ireland-based GlobeTech.\n\nOver the past few years, Apple has grown more aggressive in its harvesting and analysis of people\u2019s voices, worried that Siri\u2019s comprehension and speed were falling behind those of Alexa and Google Assistant. Apple treated Siri\u2019s development like a verbal search engine that it had to prep to fulfill endless user queries and ramped up its dependence on audio analysis to feed the assistant\u2019s lexicon. Temps were expected to account for the clips\u2019 various languages, dialects, and cultural idiosyncrasies.\n\nFormer contractors describe the system as something out of the Tower of Babel or George Orwell\u2019s 1984. At a GlobeTech office near an airport in Cork, Ireland, some say, they sat in silence at MacBooks wearing headphones, tasked with transcribing 1,300 clips a day, each of which could be a single sentence or an entire conversation. (This quota was reduced from as many as 2,500 clips, others say, to improve accuracy rates.) When a contractor clicked play on a voice recording, the computer filled a text box with the words it thought Siri \u201cheard,\u201d then prompted the worker to approve or correct the translation and move on. GlobeTech didn\u2019t respond to requests for comment.\n\nA program the workers used, called CrowdCollect, included buttons to skip recordings for a variety of reasons\u2014accidental trigger, missing audio, wrong language\u2014but contractors say there was no specific mechanism to report or delete offensive or inappropriate audio, such as drunk-sounding users slurring demands into the mics or people dictating sexts. Contractors who asked managers whether they could skip overly private clips were told no clips were too private. They were expected to transcribe anything that came in. Contractors often lasted only a couple of months, and training on privacy issues was minimal. One former contractor who had no qualms about the work says listening in on real-world users was \u201cabsolutely hilarious.\u201d\n\nApple\u2019s HomePod Source: Getty Images\n\nIn 2015, the same year Apple Chief Executive Officer Tim Cook called privacy a \u201cfundamental human right,\u201d Apple\u2019s machines were processing more than a billion requests a week. By then, users could turn on a feature so they no longer had to push a button on the iPhone to activate the voice assistant; it was always listening. Deep in its user agreement legalese, Apple said voice data might be recorded and analyzed to improve Siri, but nowhere did it mention that fellow humans might listen. \u201cI felt extremely uncomfortable overhearing people,\u201d says one of the former contractors, especially given how often the recordings were of children.\n\nTen former Apple executives in the Siri division say they didn\u2019t and still don\u2019t see this system as a violation of privacy. These former executives say recordings were disassociated from Apple user IDs, and they assumed users understood the company was processing their audio clips, so what did it matter if humans helped with the processing? \u201cWe felt emotionally safe, that this was the right thing to do,\u201d says John Burkey, who worked in Siri\u2019s advanced development group until 2016. \u201cIt wasn\u2019t spying. It was, \u2018This [Siri request] doesn\u2019t work. Let\u2019s fix it.\u2019 It\u2019s the same as when an app crashes and asks if you want to send the report to Apple. This is just a voice bug.\u201d\n\nThe difference between this system and a bug on a MacBook, of course, is that MacOS clearly asks users if they\u2019d like to submit a report directly after a program crashes. It\u2019s an opt-in prompt for each malfunction, as opposed to Siri\u2019s blanket consent. Current and former contractors say most Siri requests are banal\u2014\u201cplay a Justin Bieber song,\u201d \u201cwhere\u2019s the nearest McDonald\u2019s\u201d\u2014but they also recall hearing extremely graphic messages and lengthy racist or homophobic rants. A former data analyst who worked on Siri transcriptions for several years says workers in Cork swapped horror stories during smoke breaks. A current analyst, asked to recount the most outrageous clip to come through CrowdCollect, says it was akin to a scene from Fifty Shades of Grey.\n\nApple has said less than 0.2% of Siri requests undergo human analysis, and former managers dismiss the contractors\u2019 accounts as overemphases on mere rounding errors. \u201c \u2018Oh, I heard someone having sex\u2019 or whatever. You also hear people farting and sneezing\u2014there\u2019s all kind of noise out there when you turn a microphone on,\u201d says Tom Gruber, a Siri co-founder who led its advanced development group through 2018. \u201cIt\u2019s not like the machine has an intention to record people making certain kinds of sounds. It\u2019s like a statistical fluke.\u201d\n\nBy 2019, after Apple brought Siri to products such as its wireless headphones and HomePod speaker, it was processing 15 billion voice commands a month; 0.2% of 15 billion is still 30 million potential flukes a month, or 360 million a year. The risks of inadvertent recording grew along with the use cases, says Mike Bastian, a former principal research scientist on the Siri team who left Apple earlier this year. He cites the Apple Watch\u2019s \u201craise to speak\u201d feature, which automatically activates Siri when it detects a wearer\u2019s wrist being lifted, as especially dicey. \u201cThere was a high false positive rate,\u201d he says.\n\nGlobal Smart-Speaker Shipments Data: Canalys\n\nIn the smart speaker business, Apple\u2019s HomePod is estimated to account for only 5% of the U.S. market. Amazon has an estimated 70%. In 2011 CEO and massive Star Trek fan Jeff Bezos ordered a team that showed him an early voice-controlled music app to build the software into a hardware product. They produced the Echo, with its seven microphones constantly listening for a \u201cwake word\u201d that will trigger a fresh recording. Each clip, as with Apple\u2019s, goes to the company\u2019s servers, where a portion of them are then routed to one of hundreds of data associates for review.\n\nBezos and David Limp, Amazon\u2019s senior vice president for devices, weren\u2019t blind to the creep factor. They made design choices aimed at keeping Echo users from freaking out about being recorded, says an early Alexa product manager. When a user says \u201cAlexa,\u201d a ring of light appears around the Echo, as though the assistant were coming to life. A dedicated \u201cpersonality team\u201d scripted jokey answers to hundreds of frequently asked questions. And developers created an online portal where users could play and delete their audio clips. An Amazon spokeswoman says privacy standards were built into Alexa from the start.\n\nThe fine print grants Amazon the right to retain and experiment on its voice clips far beyond what Apple does with Siri. By default, the company retains recordings indefinitely. Amazon discloses few specifics on how this data is used, except to say its human transcriptions have proved an enormous advantage in translating Alexa into new languages around the world and expanding its response capabilities.\n\nIn 2016, Amazon created the Frequent Utterance Database, or FUD, to help Alexa add answers to common requests. Former employees who worked with FUD say there was tension between product teams eager to mine the data more aggressively and the security team charged with protecting user info, such as phone numbers that could easily identify a given customer. In 2017, Amazon introduced the camera-equipped Echo Look, which was pitched as an AI stylist that could recommend outfit pairings. Its developers considered programming the camera to switch on automatically when a user asked Alexa to make a joke, say people familiar with the matter. The idea was to record a video of the user\u2019s face and assess whether she was laughing. Amazon ultimately shelved the idea, these people say. Amazon says Alexa doesn\u2019t use facial recognition technology today.\n\nThe company has set up transcription farms in cities around the world, from Bucharest to Chennai. Several times this year, it\u2019s held walk-in recruiting events for transcribers overseas. A speech technologist who\u2019s spent decades developing recognition systems for tech companies says the scale of Amazon\u2019s audio data analysis as outlined in a recent recruiting effort was terrifying. Amazon says it takes the \u201csecurity of customers and their voice recordings seriously,\u201d and that it needs a complete understanding of regional accents and colloquialisms to make Alexa global.\n\nThis August, Microsoft acknowledged that humans help review voice data generated through its speech-recognition technology\u2014in products including its Cortana assistant and Skype messaging app\u2014which businesses such as BMW, HP Inc., and Humana are integrating into their own products and services. Chinese tech companies including marketplace Alibaba, search giant Baidu, and phone maker Xiaomi are churning out millions of smart speakers each quarter. Industry analysts say Google and Facebook Inc. are likewise betting audio data will greatly enhance their mammoth ad businesses. Internet browsing tells these companies a tremendous amount about people, but audio recordings could make it much easier for AI to approximate ages, genders, emotions, and even locations and interests, says Schaub, the University of Michigan professor. \u201cPeople often don\u2019t realize what their voice commands reveal,\u201d he says. \u201cIf you\u2019re asking about football a lot, you\u2019re likely an NFL fan. If a baby is crying in the background, they can infer you have a family.\u201d\n\nSeveral big tech companies tweaked their virtual-assistant programs this year after a steady drip of news reports\n\nGoogle Assistant feeds its namesake search engine with queries from a billion devices it\u2019s available on, including Android smartphones and tablets, Nest thermostats, and Sony TVs. Google, which has hired temp workers overseas to transcribe clips to improve the system\u2019s accuracy, has promised that reviewed voice recordings aren\u2019t linked to any personal information. But this summer a Google contractor shared more than 1,000 user recordings with Belgian broadcaster VRT NWS. The outlet was able to figure out who some of the people in the recordings were based on things they said, to the shock of those identified. Roughly 10% of the leaked clips were also recorded without these users\u2019 consent, because of devices erroneously detecting the activation phrase \u201cOK, Google.\u201d\n\nA Google spokeswoman says, \u201cSince hearing concerns, we have been committed to pausing this human transcription of Assistant audio while we enhance our privacy controls.\u201d The company declined to comment on whether humans transcribe voice data collected from other Google services. A senior engineer involved with Google Assistant who recently left the company says people would overlook concerns about snooping if voice assistants, including Google\u2019s, were more useful.\n\nFacebook\u2019s Portal+ Source: Facebook\n\nFacebook, where data privacy scandals have become routine, drew scoffs when it introduced Portal, a combination smart speaker and videophone, in November 2018. The company had wanted to hold off on releasing Portal until the heat from its Cambridge Analytica debacle had died down, but it wound up unveiling the device, which includes a built-in microphone and camera, soon after a different shocking data leak. Incredibly, Facebook billed the Portal as a privacy-centric project, promising that any stored mic or camera data would be kept on the device and off the cloud. Who wouldn\u2019t want a Facebook camera tracking them around the living room as they walk and talk? Besides CEO Mark Zuckerberg, who keeps his laptop\u2019s mic and camera covered and nonfunctional.\n\nAt one point or another, pretty much every Facebook user has heard the rumor that the company sharpens its ad targeting by secretly listening to people through the mics in their phones or other devices. When Congress called him to testify last year, Zuckerberg labeled that concern a \u201cconspiracy theory.\u201d Yet Facebook, too, has been relying on transcribed recordings to train its AI, and not just with audio from its users. In one instance, a contractor hired through Accenture Plc was instructed to use her personal Facebook account to call friends and family to create new audio, without telling them why. (She says this caused her anxiety.) A source within Facebook confirms the commands were recorded, but the company says it never instructed the actual calls to be captured, saying it\u2019s \u201cnot something we would ever direct to be done.\u201d Accenture referred a request for comment to Facebook.\n\nFacebook has also relied on human transcribers for its chat app Messenger, which allows users to exchange audio clips instead of texting. The company prompted users with an option to have its AI auto-transcribe these voice messages but didn\u2019t tell them these clips also went to contractor TaskUs Inc. for manual review. Facebook didn\u2019t inform the TaskUs workers where the audio clips came from, so they assumed Facebook was using exactly the kind of surveillance dragnet Zuckerberg had told Congress didn\u2019t exist. It didn\u2019t help that TaskUs referred to its Facebook contract internally as \u201cPrism,\u201d the same code name used for a National Security Agency spying program revealed in 2013 by whistleblower Edward Snowden.\n\nAlong with separating voice files from user IDs the way Apple does, Facebook\u2019s software slightly alters each person\u2019s vocal pitch before relaying the files to contractors, says Andrew Bosworth, the vice president who oversees Facebook\u2019s hardware division. He acknowledges that using voice command and video chat tools should require \u201ca lot of faith in the technology distributors behind those tools\u201d but says he trusts Google and Amazon, as well as his own company, to use voice data to improve their services rather than take advantage of sensitive information in the clips. His home in San Mateo, Calif., is sprinkled with three Portals and four other devices that use either Alexa or Google Assistant, including in his kitchen and his kids\u2019 playroom.\n\nGoogle Home Source: Google\n\nSeveral of the big tech companies tweaked their virtual-assistant programs this year after a steady drip of news reports. While Google has paused human transcriptions of Assistant audio, Apple has begun letting users delete their Siri history and opt out of sharing more, made sharing recordings optional, and hired many former contractors directly to increase its control over human listening. Facebook and Microsoft have added clearer disclaimers to their privacy policies. And Amazon has introduced a similar disclosure and started letting Alexa users opt out of manual reviews. \u201cIt\u2019s a well-known thing in the industry,\u201d Amazon\u2019s Limp recently said about human transcription teams. \u201cWhether it was well known among press or customers, it\u2019s pretty clear we weren\u2019t good enough there.\u201d\n\nIt\u2019s easy to fathom how an authoritarian government or unscrupulous three-letter agency could take advantage of these ubiquitous surveillance networks. The U.S. House of Representatives is considering legislation to curb automated eavesdropping by digital assistants, and a bipartisan group of senators has called for the Federal Trade Commission to investigate Amazon\u2019s recordings of children, but all the relevant authorities are moving slowly. \u201cAre users aware this processing is happening? If not, they need to be,\u201d says Dale Sunderland, deputy commissioner of Ireland\u2019s Data Protection Commission, which supervises tech companies\u2019 compliance with European Union privacy rules and is reviewing the industry\u2019s audio collection practices. \u201cWe want these companies to demonstrate to us how they\u2019ve built in necessary safeguards.\u201d A June Pew Research Center survey estimated that most Americans are concerned about the data collection practices of smart speakers and similar listening devices. Still, adoption rates keep rising.\n\nSome researchers say advances in smartphone processing power and a form of computer modeling called federated learning may eventually render this kind of eavesdropping obsolete\u2014that the machines will get smart enough to figure out things without help from the contractors. For now, absent tougher laws or consumer backlash, the ranks of human audio reviewers will almost certainly continue growing to keep pace as listening devices proliferate.\n\nMany former contractors say they\u2019ve stopped using virtual assistants and unplugged their listening devices. The audio sexts were awkward and all, but some are more haunted by the idea that people are listening even to the most quotidian of conversations, like a father chatting with his son after school, or a husband and wife talking in the kitchen after work. \u201cIn my head, I would say, I shouldn\u2019t be listening to this, \u201d says a former contractor who spent months working on Siri transcriptions. \u201cThis is none of my business.\u201d \u2014With Mark Bergen, Gerrit De Vynck, Natalia Drozdiak, and Giles Turner\n\n\n\nRead more: I Tried Hiding From Silicon Valley in a Pile of Privacy Gadgets",
    "source_url": "www.bloomberg.com",
    "bias_text": "center",
    "ID": "8dIGPcz0iZmi49GQ"
}