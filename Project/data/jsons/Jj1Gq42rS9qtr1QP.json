{
    "topic": "media_bias",
    "source": "The Guardian",
    "bias": 0,
    "url": "https://www.theguardian.com/technology/2016/may/12/facebook-trending-news-leaked-documents-editor-guidelines",
    "title": "Facebook news selection is in hands of editors not algorithms, documents show",
    "date": "2016-05-12",
    "authors": "Sam Thielman, Alex Hern, Trevor Timm",
    "content": "Leaked documents show how Facebook , now the biggest news distributor on the planet , relies on old-fashioned news values on top of its algorithms to determine what the hottest stories will be for the 1 billion people who visit the social network every day .\nThe documents , given to \u2588\u2588\u2588 , come amid growing concerns over how Facebook decides what is news for its users . This week the company was accused of an editorial bias against conservative news organizations , prompting calls for a congressional inquiry from the US Senate commerce committee chair , John Thune .\nThe boilerplate about its news operations provided to customers by the company suggests that much of its news gathering is determined by machines : \u201c The topics you see are based on a number of factors including engagement , timeliness , Pages you \u2019 ve liked and your location , \u201d says a page devoted to the question \u201c How does Facebook determine what topics are trending ? \u201d\nThe inside story of Facebook \u2019 s biggest setback | Rahul Bhatia Read more\nBut the documents show that the company relies heavily on the intervention of a small editorial team to determine what makes its \u201c trending module \u201d headlines \u2013 the list of news topics that shows up on the side of the browser window on Facebook \u2019 s desktop version . The company backed away from a pure-algorithm approach in 2014 after criticism that it had not included enough coverage of unrest in Ferguson , Missouri , in users \u2019 feeds .\nThe guidelines show human intervention \u2013 and therefore editorial decisions \u2013 at almost every stage of Facebook \u2019 s trending news operation , a team that at one time was as few as 12 people :\nA team of news editors working in shifts around the clock was instructed on how to \u201c inject \u201d stories into the trending topics module , and how to \u201c blacklist \u201d topics for removal for up to a day over reasons including \u201c doesn \u2019 t represent a real-world event \u201d , left to the discretion of the editors .\nThe company wrote that \u201c the editorial team CAN [ sic ] inject a newsworthy topic \u201d as well if users create something that attracts a lot of attention , for example # BlackLivesMatter .\nFacebook relies heavily on just 10 news sources to determine whether a trending news story has editorial authority . \u201c You should mark a topic as \u2018 National Story \u2019 importance if it is among the 1-3 top stories of the day , \u201d reads the trending review guidelines for the US . \u201c We measure this by checking if it is leading at least 5 of the following 10 news websites : BBC News , CNN , Fox News , \u2588\u2588\u2588 , NBC News , The New York Times , USA Today , The Wall Street Journal , Washington Post , Yahoo News or Yahoo . \u201d\nStrict guidelines are enforced around Facebook \u2019 s \u201c involved in this story \u201d feature , which pulls information from Facebook pages of newsmakers \u2013 say , a sports star or a famous author . The guidelines give editors ways to determine which users \u2019 pages are appropriate to cite , and how prominently .\nThe company \u2019 s guidelines are very similar to a traditional news organization \u2019 s , with a style guide reminiscent of the Associated Press guide , a list of trusted sources and instructions for determining newsworthiness . ( \u2588\u2588\u2588 also obtained the guidelines for moderating the \u201c in the story \u201d feature , now called \u201c involved in this story \u201d ; the guidelines for the company \u2019 s Facebook Paper app ; and a broader editorial guide for the app . )\nThe guidelines are sure to bolster arguments that Facebook has made discriminatory editorial decisions against rightwing media . Conservatives would label the majority of Facebook \u2019 s primary sources as liberal .\nThey also appear to undermine claims this week from Facebook \u2019 s vice-president of search , Tom Stocky , who posted a statement addressing the controversy on 9 May . \u201c We do not insert stories artificially into trending topics , and do not instruct our reviewers to do so , \u201d he wrote .\nStocky \u2019 s statement may depend on the definition of the word \u201c artificially \u201d . In interviews with \u2588\u2588\u2588 , three former editors said they had indeed inserted stories that were not visible to users into the trending feed in order to make the experience more topical . All denied personal bias , but all said the human element was vital .\nA second list , of 1,000 trusted sources , was provided to \u2588\u2588\u2588 by Facebook . It includes prominent conservative news outlets such as Redstate , Breitbart , the Drudge Report and the Daily Caller .\nFormer employees who worked in Facebook \u2019 s news organization said that they did not agree with the Gizmodo report on Monday alleging partisan misconduct on the part of the social network . They did admit the presence of human judgment in part because the company \u2019 s algorithm did not always create the best possible mix of news .\nSpecifically , complaints about the absence from trending feeds of news reports about clashes between protesters and police in Ferguson in 2014 were evidence to Facebook that \u2013 in the specific case of the trending module \u2013 humans had better news judgment than the company \u2019 s algorithm . Multiple news stories criticized Facebook for apparently prioritizing Ice Bucket Challenge videos over the riots . Many said the incident proved that Twitter was the place for hard news , and Facebook was a destination for fluff .\n\u201c The guidelines demonstrate that we have a series of checks and balances in place to help surface the most important popular stories , regardless of where they fall on the ideological spectrum , \u201d said Justin Osofsky , Facebook \u2019 s vice-president of global operations . \u201c Facebook does not allow or advise our reviewers to systematically discriminate against sources of any political origin , period . What these guidelines show is that we \u2019 ve approached this responsibly and with the goal of creating a high-quality product \u2013 in the hopes of delivering a meaningful experience for the people who use our service .\n\u201c Trending Topics uses a variety of mechanisms to help surface events and topics that are happening in the real world . In our guidelines , we rely on more than a thousand sources of news \u2013 from around the world , and of all sizes and viewpoints \u2013 to help verify and characterize world events and what people are talking about . The intent of verifying against news outlets is to surface topics that are meaningful to people and newsworthy . We have at no time sought to weight any one viewpoint over another , and in fact our guidelines are designed with the intent to make sure we do not do so . \u201d",
    "content_original": "Leaked documents show how Facebook, now the biggest news distributor on the planet, relies on old-fashioned news values on top of its algorithms to determine what the hottest stories will be for the 1 billion people who visit the social network every day.\n\nThe documents, given to the Guardian, come amid growing concerns over how Facebook decides what is news for its users. This week the company was accused of an editorial bias against conservative news organizations, prompting calls for a congressional inquiry from the US Senate commerce committee chair, John Thune.\n\n\n\nThe boilerplate about its news operations provided to customers by the company suggests that much of its news gathering is determined by machines: \u201cThe topics you see are based on a number of factors including engagement, timeliness, Pages you\u2019ve liked and your location,\u201d says a page devoted to the question \u201cHow does Facebook determine what topics are trending?\u201d\n\n\n\nThe inside story of Facebook\u2019s biggest setback | Rahul Bhatia Read more\n\nBut the documents show that the company relies heavily on the intervention of a small editorial team to determine what makes its \u201ctrending module\u201d headlines \u2013 the list of news topics that shows up on the side of the browser window on Facebook\u2019s desktop version. The company backed away from a pure-algorithm approach in 2014 after criticism that it had not included enough coverage of unrest in Ferguson, Missouri, in users\u2019 feeds.\n\nThe guidelines show human intervention \u2013 and therefore editorial decisions \u2013 at almost every stage of Facebook\u2019s trending news operation, a team that at one time was as few as 12 people:\n\n\n\nA team of news editors working in shifts around the clock was instructed on how to \u201cinject\u201d stories into the trending topics module, and how to \u201cblacklist\u201d topics for removal for up to a day over reasons including \u201cdoesn\u2019t represent a real-world event\u201d, left to the discretion of the editors.\n\nThe company wrote that \u201cthe editorial team CAN [sic] inject a newsworthy topic\u201d as well if users create something that attracts a lot of attention, for example #BlackLivesMatter.\n\nFacebook relies heavily on just 10 news sources to determine whether a trending news story has editorial authority. \u201cYou should mark a topic as \u2018National Story\u2019 importance if it is among the 1-3 top stories of the day,\u201d reads the trending review guidelines for the US. \u201cWe measure this by checking if it is leading at least 5 of the following 10 news websites: BBC News, CNN, Fox News, The Guardian, NBC News, The New York Times, USA Today, The Wall Street Journal, Washington Post, Yahoo News or Yahoo.\u201d\n\nStrict guidelines are enforced around Facebook\u2019s \u201cinvolved in this story\u201d feature, which pulls information from Facebook pages of newsmakers \u2013 say, a sports star or a famous author. The guidelines give editors ways to determine which users\u2019 pages are appropriate to cite, and how prominently.\n\nThe company\u2019s guidelines are very similar to a traditional news organization\u2019s, with a style guide reminiscent of the Associated Press guide, a list of trusted sources and instructions for determining newsworthiness. (The Guardian also obtained the guidelines for moderating the \u201cin the story\u201d feature, now called \u201cinvolved in this story\u201d; the guidelines for the company\u2019s Facebook Paper app; and a broader editorial guide for the app.)\n\nThe guidelines are sure to bolster arguments that Facebook has made discriminatory editorial decisions against rightwing media. Conservatives would label the majority of Facebook\u2019s primary sources as liberal.\n\nThey also appear to undermine claims this week from Facebook\u2019s vice-president of search, Tom Stocky, who posted a statement addressing the controversy on 9 May. \u201cWe do not insert stories artificially into trending topics, and do not instruct our reviewers to do so,\u201d he wrote.\n\n\n\nStocky\u2019s statement may depend on the definition of the word \u201cartificially\u201d. In interviews with the Guardian, three former editors said they had indeed inserted stories that were not visible to users into the trending feed in order to make the experience more topical. All denied personal bias, but all said the human element was vital.\n\n\n\nA second list, of 1,000 trusted sources, was provided to the Guardian by Facebook. It includes prominent conservative news outlets such as Redstate, Breitbart, the Drudge Report and the Daily Caller.\n\nFormer employees who worked in Facebook\u2019s news organization said that they did not agree with the Gizmodo report on Monday alleging partisan misconduct on the part of the social network. They did admit the presence of human judgment in part because the company\u2019s algorithm did not always create the best possible mix of news.\n\n\n\nSpecifically, complaints about the absence from trending feeds of news reports about clashes between protesters and police in Ferguson in 2014 were evidence to Facebook that \u2013 in the specific case of the trending module \u2013 humans had better news judgment than the company\u2019s algorithm. Multiple news stories criticized Facebook for apparently prioritizing Ice Bucket Challenge videos over the riots. Many said the incident proved that Twitter was the place for hard news, and Facebook was a destination for fluff.\n\n\u201cThe guidelines demonstrate that we have a series of checks and balances in place to help surface the most important popular stories, regardless of where they fall on the ideological spectrum,\u201d said Justin Osofsky, Facebook\u2019s vice-president of global operations. \u201cFacebook does not allow or advise our reviewers to systematically discriminate against sources of any political origin, period. What these guidelines show is that we\u2019ve approached this responsibly and with the goal of creating a high-quality product \u2013 in the hopes of delivering a meaningful experience for the people who use our service.\n\n\u201cTrending Topics uses a variety of mechanisms to help surface events and topics that are happening in the real world. In our guidelines, we rely on more than a thousand sources of news \u2013 from around the world, and of all sizes and viewpoints \u2013 to help verify and characterize world events and what people are talking about. The intent of verifying against news outlets is to surface topics that are meaningful to people and newsworthy. We have at no time sought to weight any one viewpoint over another, and in fact our guidelines are designed with the intent to make sure we do not do so.\u201d",
    "source_url": "www.theguardian.com",
    "bias_text": "left",
    "ID": "Jj1Gq42rS9qtr1QP"
}