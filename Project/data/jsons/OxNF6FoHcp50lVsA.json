{
    "topic": "race_and_racism",
    "source": "The Guardian",
    "bias": 0,
    "url": "https://www.theguardian.com/technology/2020/jun/10/amazon-rekognition-software-police-black-lives-matter",
    "title": "Amazon to ban police use of facial recognition software for a year",
    "date": "2020-06-10",
    "authors": "Kari Paul",
    "content": "Amazon is implementing a one-year moratorium on police use of its artificial intelligence software Rekognition amid a growing backlash over the tech company \u2019 s ties to law enforcement .\nThe company has recently stated its support for the Black Lives Matter movement , which advocates for police reform \u2013 using Twitter to call for an end to \u201c the inequitable and brutal treatment of black people \u201d in the US and has putting a \u201c Black lives matter \u201d banner at the top of its home page . But the company has been criticized as hypocritical because it sells its facial recognition software to police forces .\nAmazon has not said how many police forces use the technology , or how it is used , but marketing materials have promoted Rekognition being used in conjunction with police body cameras in real time .\nWhen it was first released , Amazon \u2019 s Rekognition software was criticized by human rights groups as \u201c a powerful surveillance system \u201d that is available to \u201c violate rights and target communities of color \u201d . Advocacy groups also said the technology could have a disproportionately negative effect on non-white people . Congresswoman Alexandria Ocasio-Cortez echoed this complaint in a tweet on Wednesday , saying the technology \u201c shouldn \u2019 t be anywhere near law enforcement \u201d .\n\u201c Facial recognition is a horrifying , inaccurate tool that fuels racial profiling and mass surveillance , \u201d she said . \u201c It regularly falsely [ identifies ] Black and Brown people as criminal \u201d .\nAn experiment run by the ACLU in 2018 showed Rekognition incorrectly matched 28 members of Congress to photos of people arrested for a crime . It overwhelmingly misidentified Congress members who are not white . Facial recognition software , like many forms of artificial intelligence , has a long history of racial bias . The field of artificial intelligence , which is overwhelmingly white and male , is frequently criticized for its lack of diversity .\nIn a statement on its blog Wednesday , Amazon said it will pull the use of its technology from police forces until there is stronger regulation around it . The move follows IBM putting a permanent end to its development of facial recognition technology .\n\u201c We \u2019 ve advocated that governments should put in place stronger regulations to govern the ethical use of facial recognition technology , and in recent days , Congress appears ready to take on this challenge , \u201d Amazon said . \u201c We hope this one-year moratorium might give Congress enough time to implement appropriate rules , and we stand ready to help if requested . \u201d\nWhile some privacy advocates say the move represents a step in the right direction , Evan Greer , of digital rights group Fight for the Future , said this is \u201c nothing more than a public relations stunt from Amazon \u201d .\nShe said Amazon could spend the year moratorium improving the technology and lobbying Congress to make industry-friendly regulation so the technology can be implemented in the future . Amazon spent $ 16.8m on lobbying in 2019 .\n\u201c The reality is that facial recognition technology is too dangerous to be used at all , \u201d Greer said . \u201c Like nuclear or biological weapons , it poses such a profound threat to the future of humanity that it should be banned outright . \u201d\nNicole Ozer , the technology and civil liberties director with the American Civil Liberties Union of northern California , also called on Amazon to make more meaningful commitments . \u201c This surveillance technology \u2019 s threat to our civil rights and civil liberties will not disappear in a year , \u201d Ozer said . \u201c Amazon must fully commit to a blanket moratorium on law enforcement use of face recognition until the dangers can be fully addressed , and it must press Congress and legislatures across the country to do the same . They should also commit to stop selling surveillance systems like Ring that fuel the over-policing of communities of color .\nThe Washington county sheriff \u2019 s office in Oregon , the first law enforcement agency in the country to contract with Amazon to use the technology , confirmed on Wednesday it would suspend its use of the product in light of the announcement .\nSuspension of this particular program does not mean all partnerships with law enforcement will be halted . Amazon noted in its announcement that the International Center for Missing and Exploited Children , as well as technology companies Thorn and Marinus Analytics , will still have access to Rekognition for human trafficking cases .\nAmazon also has not made changes to Ring , its camera-connected smart doorbell company , which has also been criticized for increasing the policing of non-white Americans . A report from Motherboard in 2019 revealed black and brown people are more likely to be surveilled by the Neighbors app , where Ring users can post videos and photos of \u201c suspicious \u201d people caught on camera .\nThe doorbell app now partners with more than 1,300 police forces across the US \u2013 a 300 % increase from just 400 police forces in August 2019 . The ACLU has called on Amazon to \u201c stop selling surveillance systems like Ring that fuel the over-policing of communities of color \u201d . It also called on other companies that power facial recognition , including Microsoft , to halt the technology .\n\u201c Face recognition technology gives governments the unprecedented power to spy on us wherever we go , \u201d said Ozer . \u201c It fuels police abuse . This surveillance technology must be stopped . \u201d",
    "content_original": "Amazon is implementing a one-year moratorium on police use of its artificial intelligence software Rekognition amid a growing backlash over the tech company\u2019s ties to law enforcement.\n\nThe company has recently stated its support for the Black Lives Matter movement, which advocates for police reform \u2013 using Twitter to call for an end to \u201cthe inequitable and brutal treatment of black people\u201d in the US and has putting a \u201cBlack lives matter\u201d banner at the top of its home page. But the company has been criticized as hypocritical because it sells its facial recognition software to police forces.\n\nAmazon has not said how many police forces use the technology, or how it is used, but marketing materials have promoted Rekognition being used in conjunction with police body cameras in real time.\n\nWhen it was first released, Amazon\u2019s Rekognition software was criticized by human rights groups as \u201ca powerful surveillance system\u201d that is available to \u201cviolate rights and target communities of color\u201d. Advocacy groups also said the technology could have a disproportionately negative effect on non-white people. Congresswoman Alexandria Ocasio-Cortez echoed this complaint in a tweet on Wednesday, saying the technology \u201cshouldn\u2019t be anywhere near law enforcement\u201d.\n\n\u201cFacial recognition is a horrifying, inaccurate tool that fuels racial profiling and mass surveillance,\u201d she said. \u201cIt regularly falsely [identifies] Black and Brown people as criminal\u201d.\n\nAn experiment run by the ACLU in 2018 showed Rekognition incorrectly matched 28 members of Congress to photos of people arrested for a crime. It overwhelmingly misidentified Congress members who are not white. Facial recognition software, like many forms of artificial intelligence, has a long history of racial bias. The field of artificial intelligence, which is overwhelmingly white and male, is frequently criticized for its lack of diversity.\n\nIn a statement on its blog Wednesday, Amazon said it will pull the use of its technology from police forces until there is stronger regulation around it. The move follows IBM putting a permanent end to its development of facial recognition technology.\n\n\u201cWe\u2019ve advocated that governments should put in place stronger regulations to govern the ethical use of facial recognition technology, and in recent days, Congress appears ready to take on this challenge,\u201d Amazon said. \u201cWe hope this one-year moratorium might give Congress enough time to implement appropriate rules, and we stand ready to help if requested.\u201d\n\nWhile some privacy advocates say the move represents a step in the right direction, Evan Greer, of digital rights group Fight for the Future, said this is \u201cnothing more than a public relations stunt from Amazon\u201d.\n\nShe said Amazon could spend the year moratorium improving the technology and lobbying Congress to make industry-friendly regulation so the technology can be implemented in the future. Amazon spent $16.8m on lobbying in 2019.\n\n\u201cThe reality is that facial recognition technology is too dangerous to be used at all,\u201d Greer said. \u201cLike nuclear or biological weapons, it poses such a profound threat to the future of humanity that it should be banned outright.\u201d\n\nNicole Ozer, the technology and civil liberties director with the American Civil Liberties Union of northern California, also called on Amazon to make more meaningful commitments. \u201cThis surveillance technology\u2019s threat to our civil rights and civil liberties will not disappear in a year,\u201d Ozer said. \u201cAmazon must fully commit to a blanket moratorium on law enforcement use of face recognition until the dangers can be fully addressed, and it must press Congress and legislatures across the country to do the same. They should also commit to stop selling surveillance systems like Ring that fuel the over-policing of communities of color.\n\nThe Washington county sheriff\u2019s office in Oregon, the first law enforcement agency in the country to contract with Amazon to use the technology, confirmed on Wednesday it would suspend its use of the product in light of the announcement.\n\nSuspension of this particular program does not mean all partnerships with law enforcement will be halted. Amazon noted in its announcement that the International Center for Missing and Exploited Children, as well as technology companies Thorn and Marinus Analytics, will still have access to Rekognition for human trafficking cases.\n\nAmazon also has not made changes to Ring, its camera-connected smart doorbell company, which has also been criticized for increasing the policing of non-white Americans. A report from Motherboard in 2019 revealed black and brown people are more likely to be surveilled by the Neighbors app, where Ring users can post videos and photos of \u201csuspicious\u201d people caught on camera.\n\nThe doorbell app now partners with more than 1,300 police forces across the US \u2013 a 300% increase from just 400 police forces in August 2019. The ACLU has called on Amazon to \u201cstop selling surveillance systems like Ring that fuel the over-policing of communities of color\u201d. It also called on other companies that power facial recognition, including Microsoft, to halt the technology.\n\n\u201cFace recognition technology gives governments the unprecedented power to spy on us wherever we go,\u201d said Ozer. \u201cIt fuels police abuse. This surveillance technology must be stopped.\u201d",
    "source_url": "www.theguardian.com",
    "bias_text": "left",
    "ID": "OxNF6FoHcp50lVsA"
}