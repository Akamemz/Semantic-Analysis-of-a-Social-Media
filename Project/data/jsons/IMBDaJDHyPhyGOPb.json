{
    "topic": "civil_rights",
    "source": "Vox",
    "bias": 0,
    "url": "https://www.vox.com/recode/2020/7/9/21318896/facebook-civil-rights-audit-hate-speech-failed-zuckerberg-white-nationalism-sheryl-sandberg",
    "title": "Why Facebook failed its civil rights audit",
    "date": "2020-07-09",
    "authors": "Rebecca Heilweil, Shirin Ghaffary, Dylan Scott, German Lopez, Theodore Schleifer, Anna North, Fabiola Cineas, Brian Resnick, Ella Nilsen",
    "content": "On Wednesday , after two years of work , the social media giant finally released the results of its independent audit , a wide-ranging report on the state of civil rights on Facebook , from hate speech to advertising to algorithmic bias . The auditors found that the company simply hasn \u2019 t done enough to combat hate and abuse on its platform .\nFollowing up on two previous updates in December 2018 and June 2019 , the audit concludes that the company \u2019 s handling of civil rights issues is \u201c too reactive and piecemeal , \u201d and ultimately raises doubts about whether Facebook is actually committed to addressing its myriad problems .\nThat \u2019 s especially concerning given that the November 2020 election is just months away .\nFormer ACLU director Laura W. Murphy , who led the report along with civil rights attorney Megan Cacace , compared Facebook \u2019 s work to climbing Mount Everest . She noted that though the social media company had made some progress , Facebook still hadn \u2019 t invested enough resources or moved quickly enough to address its many civil rights challenges , creating \u201c legitimate questions about Facebook \u2019 s full-throated commitment to reaching the summit . \u201d\nThe audit , which was commissioned by Facebook at the urging of civil rights leaders and politicians , comes amid a growing advertiser boycott of the platform called Stop Hate for Profit , which is led by civil rights groups including the NAACP , the Anti-Defamation League , and Color of Change , none of which seem to have any plans to halt their campaign . More than 1,000 companies have now signed on , despite CEO Mark Zuckerberg dismissing its impact .\nFor these leaders of the boycott , who have long tried to work alongside Facebook , the findings of the audit confirm much of what they \u2019 ve previously said about the company : that it isn \u2019 t taking issues around hate speech , bias , polarization , and diversity seriously enough .\n\u201c Ridding the platform of hate and misinformation against Black people only became a priority when there was a PR crisis to endure , \u201d said Rashad Robinson , the president of Color of Change , who hinted that Congress may have a role in protecting civil rights on the ever-embattled platform .\nThe report is an important one for Facebook \u2019 s reputation , but it isn \u2019 t binding . Facebook can choose to implement the recommendations in the report or to dismiss them \u2014 which is what some advocates like Robinson fear . In a blog post announcing the report \u2019 s release on Wednesday , Facebook COO Sheryl Sandberg said that the company \u201c won \u2019 t make every change they [ auditors ] call for , \u201d but that it \u201c will put more of their proposals into practice . \u201d\nRegardless of what the company ends up doing , the audit serves as a thorough examination of Facebook \u2019 s longstanding struggle to reconcile its stated values around free speech with the history of harm caused by unchecked vitriol and discrimination on its platform . With that overarching theme in mind , here are five key takeaways about Facebook and civil rights from the 89-page report .\n1 ) Holding Trump to a different standard sets a troubling precedent\nFacebook has failed to penalize Trump for violating its community guidelines , the auditors say , which stands \u201c to gut policies \u201d that had represented progress for civil rights on the platform . The report specifically highlights a group of Trump \u2019 s posts that made misleading claims about voting and the president \u2019 s infamous \u201c looting \u2026 shooting \u201d post about protesters . Echoing previous concerns from civil rights groups , the auditors say these posts clearly violate Facebook \u2019 s community guidelines and that not removing them establishes a concerning precedent for Trump and other politicians .\nThe voting-related posts by Trump referenced in the report include false claims about mail-in ballots in California , Michigan , and Nevada . Facebook ultimately decided that these posts did not violate its guidelines , arguing in the case of Michigan and Nevada that the language in the posts was merely \u201c challenging the legality of officials. \u201d The auditors explain that they \u201c vehemently expressed \u201d their view that the posts violated policy but were \u201c not afforded an opportunity to speak directly to decision-makers \u201d until after the final decision was made .\nFacebook \u2019 s decisions , they said , constitute a \u201c tremendous setback for all of the policies that attempt to ban voter suppression on Facebook . \u201d\nTrump \u2019 s \u201c looting ... shooting \u201d post represents a similar pattern of self-justified inaction . In that post , the president appeared to threaten violence against Black Lives Matter protesters , using language that echoed civil rights-era white segregationists . Though Facebook executives called the White House requesting that Trump change or delete the post , the company ultimately did nothing about it . By contrast , Twitter chose to label an identical post by President Trump on its platform for violating its rules about glorifying violence .\nFacebook defended its decision by arguing that threats of state action are allowed on the platform . The auditors say that logic ignored \u201c how such statements , especially when made by those in power and targeted toward an identifiable , minority community , condone vigilantism and legitimize violence against that community. \u201c They added , \u201c Random shooting is not a legitimate state use of force. \u201d Again , the auditors say they were not included in the decision-making process in time . Facebook \u2019 s decision about the \u201c looting \u2026 shooting \u201d post , which Mark Zuckerberg later defended on a call with employees , prompted criticism from company executives and a virtual employee walkout . It was one of the incidents that inspired the Stop Hate for Profit boycott .\nIn June , Facebook announced it will label posts that violate its community guidelines but are left up because they \u2019 re deemed newsworthy ( and if their public interest value eclipses the harm they cause ) , but that doesn \u2019 t seem to happen very often . The audit revealed that over the past year , the company only applied the newsworthy exception to politicians 15 times , and only once in the United States , and it was not immediately clear what those instances were .\nMeanwhile , the company still hasn \u2019 t taken any action against Trump \u2019 s past posts , and the auditors concluded that for many civil rights advocates , \u201c the damage has already been done. \u201d Even if Facebook has policies supporting civil rights , the auditors concluded , the refusal to enforce them against Trump has eroded trust in the company and leaves room for other politicians to follow in Trump \u2019 s footsteps .\nWhile Facebook \u2019 s leadership has repeatedly emphasized the company \u2019 s commitment to free expression , the auditors found that this comes at a cost . Facebook systematically chooses to prioritize the speech of politicians over clamping down on harmful and hateful rhetoric , which hurts its users overall . Several times in the report , the auditors cite Zuckerberg \u2019 s 2019 speech at Georgetown as a \u201c turning point , \u201d where Facebook reiterated its commitment to free expression as \u201c a governing principle of the platform . \u201d\nFacebook \u2019 s choice not to fact-check politicians \u2014 and to allow them to sometimes break Facebook \u2019 s own rules against posting harmful content because what politicians say is inherently newsworthy \u2014 represents another problem . Both steps have significantly hurt the company \u2019 s civil rights efforts , the auditors said . Allowing politicians to spread misinformation about voting , which Zuckerberg in his Georgetown speech argued was a form of free expression , particularly undermines Facebook \u2019 s commitment to its values . The auditors said they found Facebook \u2019 s prioritization of free speech over other values , like nondiscrimination and equality , \u201c deeply troubling . \u201d\nThe auditors said they found Facebook \u2019 s prioritization of free speech over other values , like nondiscrimination and equality , \u201c deeply troubling \u201d\nBy forming exemptions for politicians \u2019 content , they argue , a \u201c hierarchy of speech is created that privileges certain voices over less powerful voices . \u201d\nThe report , however , acknowledges that Facebook is failing to address the tension between its civil rights promises and its monolithic commitment to free expression . Instead , the company should work to develop a more comprehensive understanding of free speech that acknowledges how typical users actually experience the platform .\n\u201c For a 21st century American corporation , and for Facebook , a social media company that has so much influence over our daily lives , the lack of clarity about the relationship between those two values is devastating , \u201d lead auditor Laura W. Murphy wrote in the report \u2019 s introduction . \u201c It will require hard balancing , but that kind of balancing of rights and interests has been part of the American dialogue since its founding and there is no reason that Facebook can not harmonize those values , if it really wants to do so . \u201d\n3 ) Hate speech is still a problem for Facebook , and we don \u2019 t know how bad it really is\nFacebook has long struggled with hateful and violent speech on its platform , including from white nationalists streaming talk shows on Facebook Watch and members of the \u201c boogaloo movement \u201d that promote anti-government ideology and has instigated violence at recent racial justice protests .\nFacebook \u2019 s audit highlights that the company has a long way to go in combating hate speech , particularly around white nationalism . Facebook has made some progress : It says it \u2019 s gotten better at identifying hate speech , and it now has a team of 350 people who work exclusively on combating dangerous groups on Facebook . But the auditors say hateful content often stays on the platform for longer than it should or doesn \u2019 t get removed in the first place . This is an \u201c especially acute \u201d problem with content targeting African Americans , Jews , and Muslims , according to the audit .\nFor example , the auditors asked Facebook to ban all content that promotes white nationalist or white separatist ideology , something it has so far failed to do . The company has explicitly banned phrases like \u201c white nationalism \u201d or \u201c white separatism , \u201d but that simplistic approach still allows racist content to continue to spread on the platform , the auditors said .\nThe audit also criticized Facebook for not taking down hateful events fast enough . The report highlights how in 2019 , it took Facebook more than 24 hours to remove an event intended to physically intimidate attendees at the Islamic Society of North America \u2019 s annual meeting in Houston , Texas . Facebook has acknowledged its misstep with that incident , but auditors called for the company to fundamentally revise its review process to expedite the removal of such events . Properly moderating events , the report says , is essential \u201c to ensure that people can not use Facebook to organize calls to arms to harm or intimidate specific groups \u201d during the current nationwide protests .\nOne thing complicating Facebook \u2019 s hate speech problem is the fact that there \u2019 s not enough hard data to know how bad it is or how it impacts different groups . The report says \u201c the absence of data for analysis and study seems to undercut efforts to document and define the problem , identify its source , and explore potential mitigation . \u201d\nWhile the audit focused on issues of hate speech , it also touched on a related and even more complex issue that has dogged Facebook for years : whether its platform politically polarizes its users and how this might be connected to the hate speech that spreads on Facebook . A recent Wall Street Journal report found that Facebook \u2019 s leadership shut down efforts to make the site less divisive by shelving internal research on whether social media increases polarization . Facebook , and Zuckerberg in particular , has denied these claims and criticized the Journal \u2019 s reporting .\nZuckerberg has vehemently disputed the notion that Facebook is polarizing its users , arguing that on the whole the platform brings people together . The auditors questioned that conclusion , saying they \u201c do not believe that Facebook is sufficiently attuned to the depth of concern on the issue of polarization and the way that the algorithms used by Facebook inadvertently fuel extreme and polarizing content . \u201d\nUnder public pressure after the 2016 election , Facebook adjusted its News Feed \u2019 s algorithm so that it promotes posts from friends and family over news articles . Still , the auditors believe this wasn \u2019 t sufficient action and that \u201c Facebook should do everything in its power to prevent its tools and algorithms from driving people toward self-reinforcing echo chambers of extremism , and that the company must recognize that failure to do so can have dangerous ( and life-threatening ) real-world consequences . \u201d\nFacebook can do this , the auditors say , not just by removing hateful content but also by redirecting users \u201c away from ( rather than toward ) extremist organizations \u201d in the types of recommendations it makes .\n4 ) Covid-19 showed Facebook can effectively police harmful content when it wants to\nThe Covid-19 pandemic raised the stakes for how the company handles harmful content . Notably , in response to the pandemic , Facebook began to aggressively take down misinformation related to Covid-19 , removing hundreds of thousands of false posts that Facebook identified as having the potential to cause imminent physical harm .\nThis new approach contrasts starkly with how the company combats other types of misinformation , which Facebook has historically chosen not to act on . The report says that \u201c Facebook has no qualms about reining in speech by the proponents of the anti-vaccination movement , or limiting misinformation about COVID-19 , but when it comes to voting , Facebook has been far too reluctant to adopt strong rules to limit misinformation and voter suppression . \u201d\nModerating pandemic-related content is also getting more complicated for the platform : As Recode \u2019 s Peter Kafka explained in late May , the discussion around Covid-19 has evolved from a public health concern into a rancorous and partisan political debate that encompasses voting rights , state reopening plans , and the politics of wearing ( or not wearing ) masks . The report notes the majority of the 100,000 pieces of content between March and May taken down for violating its voter inference policies were related to Covid-19 .\n5 ) The person Facebook hires to be its new civil rights executive needs real decision-making power\nFor years , civil rights leaders have pressured Facebook to create a role that would ensure that the company is thinking about whether its products and policies are treating people fairly . With the publication of this report , Facebook announced that it is creating a senior vice president on civil rights leadership role . But auditors say that isn \u2019 t enough . They want Facebook to create a \u201c civil rights infrastructure . \u201d\nThe audit recommends that the new vice president of civil rights should manage a team rather than work in a standalone position ; they should have a mandatory say in key \u201c decisions with civil rights implications , \u201d such as whether or not to remove controversial posts from a politician . The auditors specifically said the new vice president of civil rights \u201c must be \u2018 in the room \u2019 ( meaning in direct dialogue with decision-makers ) when decisions are being made and have direct conversations with leadership . \u201d\nFewer than 10 people weighed in on Zuckerberg \u2019 s controversial final decision not to take down Trump \u2019 s post referencing \u201c shooting \u201d at protests , according to a transcript of an internal Facebook all-hands meeting Recode reported on in June . Of the people Zuckerberg cited in the meeting , only one was Black , and none had roles dedicated exclusively to civil rights .\nIn a statement to Recode , Rashad Robinson , the president of Color of Change , said the newly announced position was \u201c an important step \u201d but added that \u201c their office needs to be provided with full resources to be effective . \u201d\n\u201c Without this , there is no reason to believe that Facebook will prioritize civil rights protections moving forward , \u201d Robinson said . \u201c All we can count on is Zuckerberg pontificating about free expression , while giving a free pass to politicians to lie , sow discord , and thrive off of hate and political chaos . \u201d\nFor civil rights leaders who have been waiting on the results of this report for two years , the big question is what comes next . Will Facebook enact the many changes in this audit it has said it \u2019 s \u201c considering \u201d or \u201c piloting \u201d ?\nFacebook COO Sheryl Sandberg , in her blog post announcing the audit \u2019 s release on Wednesday , called it the \u201c beginning of the journey \u2014 not the end \u201d for Facebook \u2019 s handling of hate speech and related issues . But some civil rights organizations are losing patience , and according to the audit , some are considering stopping their work with Facebook altogether . This is an alarming sign , considering how close the November election is .\n\u201c I \u2019 m not looking only for what the audit recommends , but what Facebook is going to do about it , \u201d Jessica Gonz\u00e1lez , president of the civil rights organization Free Press , which has been one of the organizations leading an advertising boycott of Facebook , told Recode .\n\u201c I know that we can \u2019 t snap our fingers and transform a social media network in a day , but [ Facebook has ] been way too lethargic about this \u201d\nAdvertisers are continuing to sign on to the boycott , with around 125 new ones signing up so far this week alone , Gonz\u00e1lez told Recode on Wednesday . Congress is also likely to press Facebook on these issues at an upcoming congressional hearing on antitrust issues in July , during which Zuckerberg and other major tech executives are set to testify .\n\u201c I know that we can \u2019 t snap our fingers and transform a social media network in a day , but [ Facebook has ] been way too lethargic about this , \u201d said Gonz\u00e1lez . \u201c The actions don \u2019 t meet the words . \u201d\nEvery day at \u2588\u2588\u2588 , we aim to answer your most important questions and provide you , and our audience around the world , with information that has the power to save lives . Our mission has never been more vital than it is in this moment : to empower you through understanding . \u2588\u2588\u2588 \u2019 s work is reaching more people than ever , but our distinctive brand of explanatory journalism takes resources \u2014 particularly during a pandemic and an economic downturn . Your financial contribution will not constitute a donation , but it will enable our staff to continue to offer free articles , videos , and podcasts at the quality and volume that this moment requires . Please consider making a contribution to \u2588\u2588\u2588 today .",
    "content_original": "Facebook has failed on civil rights.\n\nOn Wednesday, after two years of work, the social media giant finally released the results of its independent audit, a wide-ranging report on the state of civil rights on Facebook, from hate speech to advertising to algorithmic bias. The auditors found that the company simply hasn\u2019t done enough to combat hate and abuse on its platform.\n\nFollowing up on two previous updates in December 2018 and June 2019, the audit concludes that the company\u2019s handling of civil rights issues is \u201ctoo reactive and piecemeal,\u201d and ultimately raises doubts about whether Facebook is actually committed to addressing its myriad problems.\n\nThat\u2019s especially concerning given that the November 2020 election is just months away.\n\nFormer ACLU director Laura W. Murphy, who led the report along with civil rights attorney Megan Cacace, compared Facebook\u2019s work to climbing Mount Everest. She noted that though the social media company had made some progress, Facebook still hadn\u2019t invested enough resources or moved quickly enough to address its many civil rights challenges, creating \u201clegitimate questions about Facebook\u2019s full-throated commitment to reaching the summit.\u201d\n\nThe audit, which was commissioned by Facebook at the urging of civil rights leaders and politicians, comes amid a growing advertiser boycott of the platform called Stop Hate for Profit, which is led by civil rights groups including the NAACP, the Anti-Defamation League, and Color of Change, none of which seem to have any plans to halt their campaign. More than 1,000 companies have now signed on, despite CEO Mark Zuckerberg dismissing its impact.\n\nFor these leaders of the boycott, who have long tried to work alongside Facebook, the findings of the audit confirm much of what they\u2019ve previously said about the company: that it isn\u2019t taking issues around hate speech, bias, polarization, and diversity seriously enough.\n\n\u201cRidding the platform of hate and misinformation against Black people only became a priority when there was a PR crisis to endure,\u201d said Rashad Robinson, the president of Color of Change, who hinted that Congress may have a role in protecting civil rights on the ever-embattled platform.\n\nThe report is an important one for Facebook\u2019s reputation, but it isn\u2019t binding. Facebook can choose to implement the recommendations in the report or to dismiss them \u2014 which is what some advocates like Robinson fear. In a blog post announcing the report\u2019s release on Wednesday, Facebook COO Sheryl Sandberg said that the company \u201cwon\u2019t make every change they [auditors] call for,\u201d but that it \u201cwill put more of their proposals into practice.\u201d\n\nRegardless of what the company ends up doing, the audit serves as a thorough examination of Facebook\u2019s longstanding struggle to reconcile its stated values around free speech with the history of harm caused by unchecked vitriol and discrimination on its platform. With that overarching theme in mind, here are five key takeaways about Facebook and civil rights from the 89-page report.\n\n1) Holding Trump to a different standard sets a troubling precedent\n\nFacebook has failed to penalize Trump for violating its community guidelines, the auditors say, which stands \u201cto gut policies\u201d that had represented progress for civil rights on the platform. The report specifically highlights a group of Trump\u2019s posts that made misleading claims about voting and the president\u2019s infamous \u201clooting \u2026 shooting\u201d post about protesters. Echoing previous concerns from civil rights groups, the auditors say these posts clearly violate Facebook\u2019s community guidelines and that not removing them establishes a concerning precedent for Trump and other politicians.\n\nThe voting-related posts by Trump referenced in the report include false claims about mail-in ballots in California, Michigan, and Nevada. Facebook ultimately decided that these posts did not violate its guidelines, arguing in the case of Michigan and Nevada that the language in the posts was merely \u201cchallenging the legality of officials.\u201d The auditors explain that they \u201cvehemently expressed\u201d their view that the posts violated policy but were \u201cnot afforded an opportunity to speak directly to decision-makers\u201d until after the final decision was made.\n\nFacebook\u2019s decisions, they said, constitute a \u201ctremendous setback for all of the policies that attempt to ban voter suppression on Facebook.\u201d\n\nTrump\u2019s \u201clooting ... shooting\u201d post represents a similar pattern of self-justified inaction. In that post, the president appeared to threaten violence against Black Lives Matter protesters, using language that echoed civil rights-era white segregationists. Though Facebook executives called the White House requesting that Trump change or delete the post, the company ultimately did nothing about it. By contrast, Twitter chose to label an identical post by President Trump on its platform for violating its rules about glorifying violence.\n\nFacebook defended its decision by arguing that threats of state action are allowed on the platform. The auditors say that logic ignored \u201chow such statements, especially when made by those in power and targeted toward an identifiable, minority community, condone vigilantism and legitimize violence against that community.\u201c They added, \u201cRandom shooting is not a legitimate state use of force.\u201d Again, the auditors say they were not included in the decision-making process in time. Facebook\u2019s decision about the \u201clooting \u2026 shooting\u201d post, which Mark Zuckerberg later defended on a call with employees, prompted criticism from company executives and a virtual employee walkout. It was one of the incidents that inspired the Stop Hate for Profit boycott.\n\nIn June, Facebook announced it will label posts that violate its community guidelines but are left up because they\u2019re deemed newsworthy (and if their public interest value eclipses the harm they cause), but that doesn\u2019t seem to happen very often. The audit revealed that over the past year, the company only applied the newsworthy exception to politicians 15 times, and only once in the United States, and it was not immediately clear what those instances were.\n\nMeanwhile, the company still hasn\u2019t taken any action against Trump\u2019s past posts, and the auditors concluded that for many civil rights advocates, \u201cthe damage has already been done.\u201d Even if Facebook has policies supporting civil rights, the auditors concluded, the refusal to enforce them against Trump has eroded trust in the company and leaves room for other politicians to follow in Trump\u2019s footsteps.\n\n2) Valuing free speech above all else creates problems\n\nWhile Facebook\u2019s leadership has repeatedly emphasized the company\u2019s commitment to free expression, the auditors found that this comes at a cost. Facebook systematically chooses to prioritize the speech of politicians over clamping down on harmful and hateful rhetoric, which hurts its users overall. Several times in the report, the auditors cite Zuckerberg\u2019s 2019 speech at Georgetown as a \u201cturning point,\u201d where Facebook reiterated its commitment to free expression as \u201ca governing principle of the platform.\u201d\n\nFacebook\u2019s choice not to fact-check politicians \u2014 and to allow them to sometimes break Facebook\u2019s own rules against posting harmful content because what politicians say is inherently newsworthy \u2014 represents another problem. Both steps have significantly hurt the company\u2019s civil rights efforts, the auditors said. Allowing politicians to spread misinformation about voting, which Zuckerberg in his Georgetown speech argued was a form of free expression, particularly undermines Facebook\u2019s commitment to its values. The auditors said they found Facebook\u2019s prioritization of free speech over other values, like nondiscrimination and equality, \u201cdeeply troubling.\u201d\n\nThe auditors said they found Facebook\u2019s prioritization of free speech over other values, like nondiscrimination and equality, \u201cdeeply troubling\u201d\n\nBy forming exemptions for politicians\u2019 content, they argue, a \u201chierarchy of speech is created that privileges certain voices over less powerful voices.\u201d\n\nThe report, however, acknowledges that Facebook is failing to address the tension between its civil rights promises and its monolithic commitment to free expression. Instead, the company should work to develop a more comprehensive understanding of free speech that acknowledges how typical users actually experience the platform.\n\n\u201cFor a 21st century American corporation, and for Facebook, a social media company that has so much influence over our daily lives, the lack of clarity about the relationship between those two values is devastating,\u201d lead auditor Laura W. Murphy wrote in the report\u2019s introduction. \u201cIt will require hard balancing, but that kind of balancing of rights and interests has been part of the American dialogue since its founding and there is no reason that Facebook cannot harmonize those values, if it really wants to do so.\u201d\n\n3) Hate speech is still a problem for Facebook, and we don\u2019t know how bad it really is\n\nFacebook has long struggled with hateful and violent speech on its platform, including from white nationalists streaming talk shows on Facebook Watch and members of the \u201cboogaloo movement\u201d that promote anti-government ideology and has instigated violence at recent racial justice protests.\n\nFacebook\u2019s audit highlights that the company has a long way to go in combating hate speech, particularly around white nationalism. Facebook has made some progress: It says it\u2019s gotten better at identifying hate speech, and it now has a team of 350 people who work exclusively on combating dangerous groups on Facebook. But the auditors say hateful content often stays on the platform for longer than it should or doesn\u2019t get removed in the first place. This is an \u201cespecially acute\u201d problem with content targeting African Americans, Jews, and Muslims, according to the audit.\n\nFor example, the auditors asked Facebook to ban all content that promotes white nationalist or white separatist ideology, something it has so far failed to do. The company has explicitly banned phrases like \u201cwhite nationalism\u201d or \u201cwhite separatism,\u201d but that simplistic approach still allows racist content to continue to spread on the platform, the auditors said.\n\nThe audit also criticized Facebook for not taking down hateful events fast enough. The report highlights how in 2019, it took Facebook more than 24 hours to remove an event intended to physically intimidate attendees at the Islamic Society of North America\u2019s annual meeting in Houston, Texas. Facebook has acknowledged its misstep with that incident, but auditors called for the company to fundamentally revise its review process to expedite the removal of such events. Properly moderating events, the report says, is essential \u201cto ensure that people cannot use Facebook to organize calls to arms to harm or intimidate specific groups\u201d during the current nationwide protests.\n\nOne thing complicating Facebook\u2019s hate speech problem is the fact that there\u2019s not enough hard data to know how bad it is or how it impacts different groups. The report says \u201cthe absence of data for analysis and study seems to undercut efforts to document and define the problem, identify its source, and explore potential mitigation.\u201d\n\nWhile the audit focused on issues of hate speech, it also touched on a related and even more complex issue that has dogged Facebook for years: whether its platform politically polarizes its users and how this might be connected to the hate speech that spreads on Facebook. A recent Wall Street Journal report found that Facebook\u2019s leadership shut down efforts to make the site less divisive by shelving internal research on whether social media increases polarization. Facebook, and Zuckerberg in particular, has denied these claims and criticized the Journal\u2019s reporting.\n\nZuckerberg has vehemently disputed the notion that Facebook is polarizing its users, arguing that on the whole the platform brings people together. The auditors questioned that conclusion, saying they \u201cdo not believe that Facebook is sufficiently attuned to the depth of concern on the issue of polarization and the way that the algorithms used by Facebook inadvertently fuel extreme and polarizing content.\u201d\n\nUnder public pressure after the 2016 election, Facebook adjusted its News Feed\u2019s algorithm so that it promotes posts from friends and family over news articles. Still, the auditors believe this wasn\u2019t sufficient action and that \u201cFacebook should do everything in its power to prevent its tools and algorithms from driving people toward self-reinforcing echo chambers of extremism, and that the company must recognize that failure to do so can have dangerous (and life-threatening) real-world consequences.\u201d\n\nFacebook can do this, the auditors say, not just by removing hateful content but also by redirecting users \u201caway from (rather than toward) extremist organizations\u201d in the types of recommendations it makes.\n\n4) Covid-19 showed Facebook can effectively police harmful content when it wants to\n\nThe Covid-19 pandemic raised the stakes for how the company handles harmful content. Notably, in response to the pandemic, Facebook began to aggressively take down misinformation related to Covid-19, removing hundreds of thousands of false posts that Facebook identified as having the potential to cause imminent physical harm.\n\nThis new approach contrasts starkly with how the company combats other types of misinformation, which Facebook has historically chosen not to act on. The report says that \u201cFacebook has no qualms about reining in speech by the proponents of the anti-vaccination movement, or limiting misinformation about COVID-19, but when it comes to voting, Facebook has been far too reluctant to adopt strong rules to limit misinformation and voter suppression.\u201d\n\nModerating pandemic-related content is also getting more complicated for the platform: As Recode\u2019s Peter Kafka explained in late May, the discussion around Covid-19 has evolved from a public health concern into a rancorous and partisan political debate that encompasses voting rights, state reopening plans, and the politics of wearing (or not wearing) masks. The report notes the majority of the 100,000 pieces of content between March and May taken down for violating its voter inference policies were related to Covid-19.\n\n5) The person Facebook hires to be its new civil rights executive needs real decision-making power\n\nFor years, civil rights leaders have pressured Facebook to create a role that would ensure that the company is thinking about whether its products and policies are treating people fairly. With the publication of this report, Facebook announced that it is creating a senior vice president on civil rights leadership role. But auditors say that isn\u2019t enough. They want Facebook to create a \u201ccivil rights infrastructure.\u201d\n\nThe audit recommends that the new vice president of civil rights should manage a team rather than work in a standalone position; they should have a mandatory say in key \u201cdecisions with civil rights implications,\u201d such as whether or not to remove controversial posts from a politician. The auditors specifically said the new vice president of civil rights \u201cmust be \u2018in the room\u2019 (meaning in direct dialogue with decision-makers) when decisions are being made and have direct conversations with leadership.\u201d\n\nFewer than 10 people weighed in on Zuckerberg\u2019s controversial final decision not to take down Trump\u2019s post referencing \u201cshooting\u201d at protests, according to a transcript of an internal Facebook all-hands meeting Recode reported on in June. Of the people Zuckerberg cited in the meeting, only one was Black, and none had roles dedicated exclusively to civil rights.\n\nIn a statement to Recode, Rashad Robinson, the president of Color of Change, said the newly announced position was \u201can important step\u201d but added that \u201ctheir office needs to be provided with full resources to be effective.\u201d\n\n\u201cWithout this, there is no reason to believe that Facebook will prioritize civil rights protections moving forward,\u201d Robinson said. \u201cAll we can count on is Zuckerberg pontificating about free expression, while giving a free pass to politicians to lie, sow discord, and thrive off of hate and political chaos.\u201d\n\nWhat\u2019s next\n\nFor civil rights leaders who have been waiting on the results of this report for two years, the big question is what comes next. Will Facebook enact the many changes in this audit it has said it\u2019s \u201cconsidering\u201d or \u201cpiloting\u201d?\n\nFacebook COO Sheryl Sandberg, in her blog post announcing the audit\u2019s release on Wednesday, called it the \u201cbeginning of the journey \u2014 not the end\u201d for Facebook\u2019s handling of hate speech and related issues. But some civil rights organizations are losing patience, and according to the audit, some are considering stopping their work with Facebook altogether. This is an alarming sign, considering how close the November election is.\n\n\u201cI\u2019m not looking only for what the audit recommends, but what Facebook is going to do about it,\u201d Jessica Gonz\u00e1lez, president of the civil rights organization Free Press, which has been one of the organizations leading an advertising boycott of Facebook, told Recode.\n\n\u201cI know that we can\u2019t snap our fingers and transform a social media network in a day, but [Facebook has] been way too lethargic about this\u201d\n\nAdvertisers are continuing to sign on to the boycott, with around 125 new ones signing up so far this week alone, Gonz\u00e1lez told Recode on Wednesday. Congress is also likely to press Facebook on these issues at an upcoming congressional hearing on antitrust issues in July, during which Zuckerberg and other major tech executives are set to testify.\n\n\u201cI know that we can\u2019t snap our fingers and transform a social media network in a day, but [Facebook has] been way too lethargic about this,\u201d said Gonz\u00e1lez. \u201cThe actions don\u2019t meet the words.\u201d\n\nSupport Vox\u2019s explanatory journalism\n\nEvery day at Vox, we aim to answer your most important questions and provide you, and our audience around the world, with information that has the power to save lives. Our mission has never been more vital than it is in this moment: to empower you through understanding. Vox\u2019s work is reaching more people than ever, but our distinctive brand of explanatory journalism takes resources \u2014 particularly during a pandemic and an economic downturn. Your financial contribution will not constitute a donation, but it will enable our staff to continue to offer free articles, videos, and podcasts at the quality and volume that this moment requires. Please consider making a contribution to Vox today.",
    "source_url": "www.vox.com",
    "bias_text": "left",
    "ID": "IMBDaJDHyPhyGOPb"
}