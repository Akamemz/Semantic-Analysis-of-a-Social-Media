{
    "topic": "fake_news",
    "source": "Christian Science Monitor",
    "bias": 1,
    "url": "https://www.csmonitor.com/Business/2017/1006/Combating-fake-news-may-force-big-changes-at-Facebook-Twitter",
    "title": "Combating fake news may force big changes at Facebook, Twitter",
    "date": "2017-10-06",
    "authors": "Laurent Belsie",
    "content": "The day after the 2016 presidential election , Facebook CEO Mark Zuckerberg was asked whether social media had contributed to Donald Trump \u2019 s win .\n\u201c A pretty crazy idea , \u201d he responded at the time . But after months of internal sleuthing by media organizations , congressional investigations , and Facebook itself , the idea doesn \u2019 t look so far-fetched .\n\u201c Calling that crazy was dismissive and I regret it , \u201d Mr. Zuckerberg wrote in a Facebook post last week . \u201c We will do our part to defend against nation states attempting to spread misinformation and subvert elections . We 'll keep working to ensure the integrity of free and fair elections around the world , and to ensure our community is a platform for all ideas and force for good in democracy . \u201d\nIt is a startling turnabout . After years of defending themselves as communications networks , whose sole aim is to foster dialogue , social media companies like Facebook and Twitter are under increasing pressure to take responsibility for the content they carry . Search-engine giant Google is under similar pressure to reform after it , too , has promoted fake news stories , including extreme right-wing posts misidentifying the Las Vegas shooter and calling him a left-winger .\nPhoto Illustration/Dado Ruvic/Reuters/File Google is facing pressure to reform after promoting fake news stories .\nThe proliferation of fake news is forcing these companies to rethink their role in society , their reliance on cheap algorithms rather than expensive employees , and their engineer-driven , data-dependent culture in an era when they are increasingly curating and delivering news .\n\u201c This is definitely a crisis moment for them , \u201d says Cliff Lampe , a professor and social media expert in the School of Information at the University of Michigan in Ann Arbor . \u201c They \u2019 re just trying to do their business . What they don \u2019 t understand is that in the huge panoply of humankind , people are going to try to manipulate that business for their own ends . \u201d\nIt \u2019 s clear that Facebook was aware that something was afoot with fake campaign stories as early as June 2016 , when it detected a Russian espionage operation on its network and alerted the FBI , according to a Washington Post report . More hints of Russian activity popped up in the following weeks . Facebook 's lengthy internal investigations have hit some paydirt , after the firm decided to narrow its search rather than try to be comprehensive .\nThis week , Facebook handed over to congressional investigators more than 3,000 ads that ran between 2015 and 2017 linked to the Internet Research Agency , a Russian social media trolling group .\nSome of the ads are drawing particular interest because they targeted pivotal voting groups in Michigan and Wisconsin , where Mr. Trump won narrowly . Investigators will probe to see if the Trump campaign played any role in helping the Russians target those ads .\nBut experts suspect the company has only scratched the surface . And the problem stretches beyond Facebook .\nDuring the Republican primaries , Ron Nehring noticed something odd about his Twitter feed . The campaign spokesman for presidential hopeful Sen. Ted Cruz could go on cable television and bash any of Mr. Cruz \u2019 s rivals without any social media blowback . But when he criticized Trump , his Twitter account would be deluged by a torrent of negative and \u201c extremely hysterical \u201d tweets .\n\u201c The tone was always extremely hysterical , not something that I would see from typical conservative activists , \u201d he said at a Heritage Foundation event this week .\nIt is tempting to say that Russia simply manipulated right-wing social media to support Trump \u2019 s candidacy . The reality is stranger than that . While a preponderance of the fake posts promoted Trump or criticized his Democratic opponent , Hillary Clinton , on websites crafted to attract right-wing voters , some of them also appeared on sites catering to left-wing causes , such as Black Lives Matter , and religious ones , such as United Muslims of America .\n\u201c The U.S. left ( liberal ) vs. right ( conservative ) political spectrum was not appropriate for much of this content , \u201d Kate Starbird , a University of Washington professor and researcher of Twitter fake news , wrote in a blog this spring . \u201c Instead , the major political orientation was towards anti-globalism . \u201d\nDifferent groups defined globalism differently , but it attracted extremists on both sides of the political spectrum .\nAnd beyond the outcome of any specific election , Russia \u2019 s aim may be to sow divisions among Americans ( and indeed citizens in other countries , especially in Eastern and Central Europe ) , Professor Starbird says .\nIn one sense , none of this is terribly new . Americans have at times been virulently divided , for example , during the American Revolution , the Civil War , and the Vietnam War . And fake news has been around since before ancient Rome . Not all of the fake material has an obvious Russian connection .\nAnd some say the Kremlin has meddled in other nations ' elections in an attempt to foster distrust in their institutions .\n\u201c Since at least 2008 , Kremlin military and intelligence thinkers have been talking about information not in the familiar terms of 'persuasion , ' 'public diplomacy ' or even 'propaganda , ' but in weaponized terms , as a tool to confuse , blackmail , demoralize , subvert and paralyze , \u201d the Institute of Modern Russia , a nonprofit think tank in New York , concluded in a 2014 report . \u201c The aim of this new propaganda is not to convince or persuade , but to keep the viewer hooked and distracted , passive and paranoid , rather than agitated to action . \u201d\nWhat is new is the scale of Russian meddling and the dramatic shift of political dialogue to social networks , which until very recently clung to the idea that enabling unfettered communication by everyone was an unqualified good , even if it meant giving voice to conspiracy theorists , racists , anti-Semites , and Russian provocateurs .\nThe reach and speed of these networks make it easy for these ideas to spread before they can be debunked . Facebook claims to have 2 billion users , or nearly a third of humanity . During the last three months of the presidential election , the top 20 fake election news stories on Facebook generated more shares , reactions , and comments on Facebook than the top 20 pieces from major news outlets , such as The New York Times , The Washington Post , and others , according to a BuzzFeed News analysis .\nAmong the most popular fake news stories , one said Ms. Clinton sold weapons to the so-called Islamic State and another one claimed the pope endorsed Trump .\nAnd the meddling continues . Sen. James Lankford ( R ) of Oklahoma , a member of the Senate Intelligence Committee , said Russian internet trolls last weekend sought to use a recent furor over NFL players and the anthem to further divide Americans .\nPart of the challenge lies in these digital giants \u2019 reliance on algorithms to make complex news decisions . Computer programs are cheaper than real-life editors . They also offer political cover .\nFacebook has used human editors in the past . But after Gizmodo reported that former employees routinely suppressed conservative news stories from users \u2019 trending topics , Zuckerberg met with conservative editors and moved back to algorithms .\nBut the algorithms are far from neutral . Until exposed by reporters , they allowed advertisers to exclude minorities from seeing ads and , until last month , target \u201c Jew-haters. \u201d A more subtle and endemic problem is that the algorithms are geared to support social media \u2019 s business model , which is to generate traffic and engagement .\nIn 2014 , after protests broke out in Ferguson , Mo. , over the police shooting of a black teenager , social media researcher Zeynep Tufekci , at the University of North Carolina , noticed that her unfiltered Twitter feed was full of stories about the incident . But they were nowhere on her Facebook feed . When she disabled Facebook \u2019 s algorithm , she discovered her friends were indeed talking about the issue , but the topic was not algorithm friendly .\n\u201c It \u2019 s not likable , \u201d she told a TedSummit audience last year . \u201c Who \u2019 s going to click on \u2018 Like \u2019 ? It \u2019 s not even easy to comment on. \u201d Instead of the Ferguson protests , a dominant theme in regular news coverage that week , Facebook highlighted the ALS Ice Bucket Challenge , which was far more likely to be shared , she said .\nAnother challenge is that even as social networks become mainstream purveyors of news , they \u2019 re still largely run by engineers who rely on data rather than editorial judgment to choose newsworthy content . That data-first mentality powers profits because it gives customers exactly what they want . But if they want fake news that supports their worldview , is it ethical to give it to them ?\n\u201c There is nothing unethical about companies delivering a product or service consumers demand , \u201d Daniel Castro , vice president at the Information Technology and Innovation Foundation , writes in an email . Major social networks have policies about hate speech and already limit some adult content . \u201c But that does not mean that we can not instill more ethics in how users share content , teach people to be more critical media consumers , or create digital spaces where substantiated facts have more authority than unsubstantiated opinions . \u201d\nAlready , Facebook has developed a specialized data-mining tool that it deployed during the French elections this past spring , helping the company identify and disable 30,000 fake accounts . The tool was used again in last month \u2019 s German elections to help identify tens of thousands of fake profiles , which were deleted .\nGet the Monitor Stories you care about delivered to your inbox . By signing up , you agree to our Privacy Policy\nLast month , Zuckerberg pledged to \u201c make political advertising more transparent \u201d on Facebook , including identifying who pays for each political ad ( as TV and newspapers already do ) and ending the practice of excluding certain groups from seeing ads .\nGovernment has a role to play , too , says Mr. Castro . \u201c Foreign interference in elections , that 's the kind of thing we should look closely at ... and prohibit . \u201d",
    "content_original": "The day after the 2016 presidential election, Facebook CEO Mark Zuckerberg was asked whether social media had contributed to Donald Trump\u2019s win.\n\n\u201cA pretty crazy idea,\u201d he responded at the time. But after months of internal sleuthing by media organizations, congressional investigations, and Facebook itself, the idea doesn\u2019t look so far-fetched.\n\n\u201cCalling that crazy was dismissive and I regret it,\u201d Mr. Zuckerberg wrote in a Facebook post last week. \u201cWe will do our part to defend against nation states attempting to spread misinformation and subvert elections. We'll keep working to ensure the integrity of free and fair elections around the world, and to ensure our community is a platform for all ideas and force for good in democracy.\u201d\n\nIt is a startling turnabout. After years of defending themselves as communications networks, whose sole aim is to foster dialogue, social media companies like Facebook and Twitter are under increasing pressure to take responsibility for the content they carry. Search-engine giant Google is under similar pressure to reform after it, too, has promoted fake news stories, including extreme right-wing posts misidentifying the Las Vegas shooter and calling him a left-winger.\n\nPhoto Illustration/Dado Ruvic/Reuters/File Google is facing pressure to reform after promoting fake news stories.\n\nThe proliferation of fake news is forcing these companies to rethink their role in society, their reliance on cheap algorithms rather than expensive employees, and their engineer-driven, data-dependent culture in an era when they are increasingly curating and delivering news.\n\n\u201cThis is definitely a crisis moment for them,\u201d says Cliff Lampe, a professor and social media expert in the School of Information at the University of Michigan in Ann Arbor. \u201cThey\u2019re just trying to do their business. What they don\u2019t understand is that in the huge panoply of humankind, people are going to try to manipulate that business for their own ends.\u201d\n\nAds linked to Russian group\n\nIt\u2019s clear that Facebook was aware that something was afoot with fake campaign stories as early as June 2016, when it detected a Russian espionage operation on its network and alerted the FBI, according to a Washington Post report. More hints of Russian activity popped up in the following weeks. Facebook's lengthy internal investigations have hit some paydirt, after the firm decided to narrow its search rather than try to be comprehensive.\n\nThis week, Facebook handed over to congressional investigators more than 3,000 ads that ran between 2015 and 2017 linked to the Internet Research Agency, a Russian social media trolling group.\n\nSome of the ads are drawing particular interest because they targeted pivotal voting groups in Michigan and Wisconsin, where Mr. Trump won narrowly. Investigators will probe to see if the Trump campaign played any role in helping the Russians target those ads.\n\nBut experts suspect the company has only scratched the surface. And the problem stretches beyond Facebook.\n\nAn unusual Twitter torrent\n\nDuring the Republican primaries, Ron Nehring noticed something odd about his Twitter feed. The campaign spokesman for presidential hopeful Sen. Ted Cruz could go on cable television and bash any of Mr. Cruz\u2019s rivals without any social media blowback. But when he criticized Trump, his Twitter account would be deluged by a torrent of negative and \u201cextremely hysterical\u201d tweets.\n\n\u201cThe tone was always extremely hysterical, not something that I would see from typical conservative activists,\u201d he said at a Heritage Foundation event this week.\n\nIt is tempting to say that Russia simply manipulated right-wing social media to support Trump\u2019s candidacy. The reality is stranger than that. While a preponderance of the fake posts promoted Trump or criticized his Democratic opponent, Hillary Clinton, on websites crafted to attract right-wing voters, some of them also appeared on sites catering to left-wing causes, such as Black Lives Matter, and religious ones, such as United Muslims of America.\n\n\u201cThe U.S. left (liberal) vs. right (conservative) political spectrum was not appropriate for much of this content,\u201d Kate Starbird, a University of Washington professor and researcher of Twitter fake news, wrote in a blog this spring. \u201cInstead, the major political orientation was towards anti-globalism.\u201d\n\nDifferent groups defined globalism differently, but it attracted extremists on both sides of the political spectrum.\n\nAn overt attack on trust itself?\n\nAnd beyond the outcome of any specific election, Russia\u2019s aim may be to sow divisions among Americans (and indeed citizens in other countries, especially in Eastern and Central Europe), Professor Starbird says.\n\nIn one sense, none of this is terribly new. Americans have at times been virulently divided, for example, during the American Revolution, the Civil War, and the Vietnam War. And fake news has been around since before ancient Rome. Not all of the fake material has an obvious Russian connection.\n\nAnd some say the Kremlin has meddled in other nations' elections in an attempt to foster distrust in their institutions.\n\n\u201cSince at least 2008, Kremlin military and intelligence thinkers have been talking about information not in the familiar terms of 'persuasion,' 'public diplomacy' or even 'propaganda,' but in weaponized terms, as a tool to confuse, blackmail, demoralize, subvert and paralyze,\u201d the Institute of Modern Russia, a nonprofit think tank in New York, concluded in a 2014 report. \u201cThe aim of this new propaganda is not to convince or persuade, but to keep the viewer hooked and distracted, passive and paranoid, rather than agitated to action.\u201d\n\nThe social multiplier\n\nWhat is new is the scale of Russian meddling and the dramatic shift of political dialogue to social networks, which until very recently clung to the idea that enabling unfettered communication by everyone was an unqualified good, even if it meant giving voice to conspiracy theorists, racists, anti-Semites, and Russian provocateurs.\n\nThe reach and speed of these networks make it easy for these ideas to spread before they can be debunked. Facebook claims to have 2 billion users, or nearly a third of humanity. During the last three months of the presidential election, the top 20 fake election news stories on Facebook generated more shares, reactions, and comments on Facebook than the top 20 pieces from major news outlets, such as The New York Times, The Washington Post, and others, according to a BuzzFeed News analysis.\n\nAmong the most popular fake news stories, one said Ms. Clinton sold weapons to the so-called Islamic State and another one claimed the pope endorsed Trump.\n\nAnd the meddling continues. Sen. James Lankford (R) of Oklahoma, a member of the Senate Intelligence Committee, said Russian internet trolls last weekend sought to use a recent furor over NFL players and the anthem to further divide Americans.\n\nPart of the challenge lies in these digital giants\u2019 reliance on algorithms to make complex news decisions. Computer programs are cheaper than real-life editors. They also offer political cover.\n\nFacebook has used human editors in the past. But after Gizmodo reported that former employees routinely suppressed conservative news stories from users\u2019 trending topics, Zuckerberg met with conservative editors and moved back to algorithms.\n\nBut the algorithms are far from neutral. Until exposed by reporters, they allowed advertisers to exclude minorities from seeing ads and, until last month, target \u201cJew-haters.\u201d A more subtle and endemic problem is that the algorithms are geared to support social media\u2019s business model, which is to generate traffic and engagement.\n\nIn 2014, after protests broke out in Ferguson, Mo., over the police shooting of a black teenager, social media researcher Zeynep Tufekci, at the University of North Carolina, noticed that her unfiltered Twitter feed was full of stories about the incident. But they were nowhere on her Facebook feed. When she disabled Facebook\u2019s algorithm, she discovered her friends were indeed talking about the issue, but the topic was not algorithm friendly.\n\n\u201cIt\u2019s not likable,\u201d she told a TedSummit audience last year. \u201cWho\u2019s going to click on \u2018Like\u2019? It\u2019s not even easy to comment on.\u201d Instead of the Ferguson protests, a dominant theme in regular news coverage that week, Facebook highlighted the ALS Ice Bucket Challenge, which was far more likely to be shared, she said.\n\nSeeking a balance on oversight\n\nAnother challenge is that even as social networks become mainstream purveyors of news, they\u2019re still largely run by engineers who rely on data rather than editorial judgment to choose newsworthy content. That data-first mentality powers profits because it gives customers exactly what they want. But if they want fake news that supports their worldview, is it ethical to give it to them?\n\n\u201cThere is nothing unethical about companies delivering a product or service consumers demand,\u201d Daniel Castro, vice president at the Information Technology and Innovation Foundation, writes in an email. Major social networks have policies about hate speech and already limit some adult content. \u201cBut that does not mean that we cannot instill more ethics in how users share content, teach people to be more critical media consumers, or create digital spaces where substantiated facts have more authority than unsubstantiated opinions.\u201d\n\nAlready, Facebook has developed a specialized data-mining tool that it deployed during the French elections this past spring, helping the company identify and disable 30,000 fake accounts. The tool was used again in last month\u2019s German elections to help identify tens of thousands of fake profiles, which were deleted.\n\nGet the Monitor Stories you care about delivered to your inbox. By signing up, you agree to our Privacy Policy\n\nLast month, Zuckerberg pledged to \u201cmake political advertising more transparent\u201d on Facebook, including identifying who pays for each political ad (as TV and newspapers already do) and ending the practice of excluding certain groups from seeing ads.\n\nGovernment has a role to play, too, says Mr. Castro. \u201cForeign interference in elections, that's the kind of thing we should look closely at ... and prohibit.\u201d",
    "source_url": "www.csmonitor.com",
    "bias_text": "center",
    "ID": "xV7iAqaeR5Fv8kIE"
}