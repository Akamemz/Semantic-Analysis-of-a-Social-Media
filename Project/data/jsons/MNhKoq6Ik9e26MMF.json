{
    "topic": "media_bias",
    "source": "Slate",
    "bias": 0,
    "url": "http://www.slate.com/articles/technology/technology/2016/11/the_problem_with_facebook_runs_much_deeper_than_fake_news.html",
    "title": "The Real Problem Behind the Fake News",
    "date": "2016-11-15",
    "authors": "Will Oremus",
    "content": "Facebook CEO Mark Zuckerberg during a town hall at Facebook \u2019 s headquarters in Menlo Park , California , in 2015 . Stephen Lam/Reuters\nIn the wake of Donald Trump \u2019 s election as president , Facebook has taken justifiable heat for its role in spreading misinformation and propaganda about the candidates . In particular , its news feed algorithm fueled a cottage industry of fake and intentionally misleading \u201c news \u201d that skewed heavily anti\u2013Hillary Clinton and pro-Trump , according to a BuzzFeed analysis . These falsehoods attracted far more user engagement , on average , than true stories from the same outlets and drowned out earnest attempts by dedicated fact-checking sites such as Snopes to debunk them .\nThis should not surprise anyone who understands how Facebook works . People tend to read , like , and share stories that appeal to their emotions and play to their existing beliefs . Without robust countervailing forces favoring credibility and accuracy , Facebook \u2019 s news feed algorithm is bound to spread lies , especially those that serve to bolster people \u2019 s preconceived biases . And these falsehoods are bound to influence people \u2019 s thinking .\nAnd yet , in the days following the election , as criticisms of the company mounted , Facebook CEO Mark Zuckerberg downplayed and denied the issue\u2014a defensiveness that says even more about the company than the fake news scandal itself . Zuckerberg \u2019 s response points to a problem deeper than any bogus story , one that won \u2019 t be fixed by cutting some shady websites out of its advertising network . The problem is Facebook \u2019 s refusal to own up to its increasingly dominant role in the news media . It \u2019 s one that is unlikely to go away , even if the fake news does .\nIn a public interview last Thursday , Zuckerberg claimed that fake news on Facebook \u201c surely had no impact \u201d on the election and that to suggest otherwise was \u201c a pretty crazy idea. \u201d He accused Facebook critics of condescension for assuming that voters could be influenced by falsehoods and dismissed the notion that one side could have shared more fake news than the other . ( There is evidence that it did . ) As criticism intensified , he followed up with a personal Facebook post on Saturday , which struck a more conciliatory tone but still rejected the notion that fake news had an impact . He noted that Facebook already allows users to flag hoaxes and fake news and added that \u201c we will continue to work on this to improve further. \u201d At the same time , he cautioned that Facebook had to \u201c proceed very carefully , \u201d because \u201c identifying the \u2018 truth \u2019 is complicated . \u201d\nYes , the truth is complicated , and Facebook should proceed carefully . But there is a growing sense , both inside and outside the company , that it may be proceeding rather too carefully , given its increasingly dominant role in the distribution of news online . And Zuckerberg \u2019 s denials seem to be fanning the flames .\nOver the weekend , some highly placed , anonymous Facebook employees told the New York Times that they \u2019 ve been questioning the company \u2019 s role in the campaign . Five more anonymous employees told BuzzFeed on Monday that they and dozens of others within Facebook have formed a secret \u201c task force \u201d to advocate for stronger action against fake news . Meanwhile , a top Clinton strategist told Politico that Democratic leaders are looking for ways to get Facebook to address the problem . And Gizmodo reported , citing an anonymous source , that Facebook considered a tougher move against fake news this summer but held off out of fear of upsetting conservatives . Facebook disputed that , telling me it did no such thing and providing an alternative explanation for its tweaks to the news feed over the summer . ( This puts Facebook in the ironic position of arguing that Gizmodo \u2019 s post is itself a false news story of sorts . )\nFinally , on Monday night , the company took a concrete step . Following the lead of Google , which made a similar move earlier in the day , Facebook announced that it will ban fake news sites from using its advertising network . It \u2019 s a fine start . It is not nearly enough .\nThe furor over fake news is warranted . Fabricated stories about the pope endorsing Trump or an FBI agent getting murdered for leaking Clinton \u2019 s emails may have composed a small fraction of all the political content shared on Facebook . ( Zuckerberg declared , without sharing any evidence , that more than 99 percent of Facebook content is \u201c authentic. \u201d ) But they and others like them were so widely shared\u2014nearly 1 million times in the case of the bogus pope endorsement\u2014that it \u2019 s easy to imagine they played a role in at least some voters \u2019 thinking . By contrast , a major investigative scoop from the New York Times about Trump \u2019 s tax returns was shared fewer than 200,000 times . The presence of fake news side by side with real news , in identical format , contributes to a sense that anything you read in the news feed could just as well be true as entirely made up .\nYet in the long run , fake news on Facebook may prove to be a relatively short-lived concern compared with the deeper fault line that the tremors have exposed . It reveals a company increasingly torn between its self-conception as a neutral technology platform and its undeniable influence on the creation , distribution , and consumption of news and other media . And it \u2019 s left Zuckerberg , one of the world \u2019 s most powerful executives , struggling to keep control of his company and the story it tells about itself .\nHe \u2019 s right , by the way , to be wary of casting Facebook in the role of arbiter of journalistic credibility . A news feed that \u2019 s a messy free-for-all is probably preferable to one in which only Facebook-approved sources can be heard . So let \u2019 s grant that it would be impossible for Facebook to stamp out all falsehoods in its network and perhaps even dangerous for it to even try , were it to cast too expansive a net . Even so , the existence of Macedonian click-farms dedicated to churning out fake news stories for profit is a clear sign that Facebook could be doing more to address the small fraction of content that is obviously bogus . Even Zuckerberg admits this .\nWhat was odd about Zuckerberg \u2019 s response to the fake news problem was how adamant he seemed that it had no impact . Facebook \u2019 s whole premise as a business is that what people read in their news feeds can influence their decisions\u2014otherwise , there would be little point in advertising there . And Zuckerberg has been more than happy to trumpet the company \u2019 s estimate that it encouraged 2 million people who might have otherwise stayed home to vote . Yet he wants us to believe that fake news stories played no role at all .\nIf Gizmodo \u2019 s report is accurate , it would cast Zuckerberg \u2019 s pooh-poohing of the fake news problem in an ugly new light . It would suggest that the company knew fake news was helping one political party more than the other and that it declined to take action for that very reason . It would imply that Zuckerberg isn \u2019 t just in denial\u2014he \u2019 s flat-out lying .\nBut there \u2019 s another explanation for his defiant stance that doesn \u2019 t rely on speculation ( or single anonymous sources ) . It \u2019 s that Zuckerberg is so loath to take responsibility for the content that appears on Facebook\u2014so reluctant to be weighed down by its baggage , even as he runs the conveyor belt\u2014that he \u2019 d rather deny its effects than grapple with its causes .\nThat \u2019 s consistent with Zuckerberg \u2019 s approach to other deeper questions about Facebook \u2019 s role in the media , including the charge that it insulates users in ideological bubbles by reinforcing what they already believe . \u201c All the research we have suggests that this isn \u2019 t really a problem , \u201d Zuckerberg said on Thursday , citing a Facebook-funded 2015 study that has been criticized as misleading . The data showed that Facebook does in fact expose users primarily to political content that conforms to their partisan identifications . But the study concluded , a little defensively , that this problem was insignificant compared with the problem of users \u2019 own choices as to which sort of content to engage with . As Jefferson Pooley pointed out in \u2588\u2588\u2588 , it \u2019 s impossible to reproduce Facebook \u2019 s findings , because the company won \u2019 t let independent researchers see its data .\nDubious as the study \u2019 s conclusions are , it seems to have convinced Zuckerberg beyond a doubt that Facebook doesn \u2019 t have a filter-bubble problem . That \u2019 s convenient for Facebook , since addressing such an issue would require rethinking the fundamental structure of its algorithm and user experience . Evidently Facebook \u2019 s users are not the only ones subject to confirmation bias and epistemic closure .\nThere is an even more subtle and insidious effect of Facebook \u2019 s algorithm that has gone almost unmentioned in this saga . It \u2019 s the incentive Facebook creates for the media\u2014both the hoax-disseminating media and the truth-telling one\u2014to write and frame stories in ways that are geared to generate likes , clicks , and shares among the social network \u2019 s users . The illusion that Facebook is a neutral platform should have been shattered long ago by the obvious ways it has warped online news coverage , from the manipulative headlines to the feeding frenzies over sensational stories and anecdotes that are too good to check . If you were trying to design a media diet that could help give rise to something like the Trump phenomenon , you could hardly do better than 24-hour cable news and the Facebook news feed . To its credit , Facebook has acknowledged the problems of clickbait and likebait and made real efforts to mitigate its own perverse incentives . But even as Zuckerberg has repeatedly addressed the issue of fake news , he has evinced no awareness of the other ways Facebook might have disrupted political coverage for the worse .\nFinally , there \u2019 s Zuckerberg \u2019 s oft-criticized denial that Facebook is a media company . \u201c It \u2019 s a technology company , \u201d he says , as if that settles it . There are valid arguments on both sides , and no doubt the company has its feet in both sectors . It would be eminently reasonable for Facebook to admit that it is a media company in some key respects but not in others . But Zuckerberg denies even that . To him , there is no argument .\nDrill down into Facebook \u2019 s reasons for insisting that it isn \u2019 t a media company , and you \u2019 ll hit layer upon layer of denial . It denies that it \u2019 s a media company because that allows it to further deny that Facebook shapes not only how the news is distributed , but how it is reported , framed , discussed , and perceived . That in turn allows it to deny that its humans or algorithms might exhibit any bias that could warp the news for better or worse or favor one set of interests over another . If Facebook is a neutral platform , as it insists , then it can deny any responsibility for how people use it , any responsibility for what they post or share , any responsibility to ensure the accuracy or fairness or journalistic virtue of whatever news might circulate on it .\nThe ultimate denial , and the underlying purpose of it all , is to deny the very possibility of any tension between Facebook \u2019 s own interests and the interests of society . Facebook , by Zuckerberg \u2019 s lights , is simply a powerful tool for making the world more open and connected . And if that means Trump is elected U.S. president , there must have been good reasons for his election that had nothing to do with Facebook . Or , in Zuckerberg \u2019 s words , \u201c voters make decisions based on their lived experience \u201d \u2014as if Facebook weren \u2019 t a part of that , as if its $ 335 billion market value weren \u2019 t a function of the incredible degree to which it has managed to ingratiate itself into people \u2019 s daily lives , as if our online and offline lives weren \u2019 t now irrevocably intertwined .\nEither the internal contradiction of Zuckerberg \u2019 s position is lost on him or , more likely , he recognizes it but refuses to acknowledge it . His discretion makes sense , from a business perspective if not a moral one , if he believes that confronting Facebook \u2019 s impact on politics would require changes that would hurt the company \u2019 s bottom line . But coming from a figure who preaches the gospel of openness , it \u2019 s baffling .\nIt now seems , however , that Zuckerberg has lost the faith of some of his own employees on this issue . Facebook has rarely been a leaky company in the past . But the leaks started with its bungling of the trending news controversy , and they \u2019 ve resurfaced around the fake news debate . Facebook \u2019 s move on Monday to cut off advertising to fake news sites feels like an acknowledgement from the top that outright denial is no longer tenable .\nThe question now is how far Facebook will go to placate its critics . The last time it faced an uproar over its influence on U.S. politics\u2014the overblown controversy involving its trending news section\u2014it grossly overreacted and made everything worse . That seems less likely this time , especially since the news feed is a far more precious product to the company .\nWhat \u2019 s more likely is that Facebook will seek to isolate and defuse the fake news issue while preserving its claim to be a neutral technology platform . As John Herrman pointed out in the New York Times last week , Facebook may already be evolving in ways that render the current controversy largely irrelevant . For instance , it has been partnering with prestigious media outlets to produce video content , broadcast live videos , and publish glossy \u201c instant articles \u201d within the news feed itself . It \u2019 s using the power of its algorithm to prioritize those forms over others , including links to news stories from publishers around the web . It \u2019 s conceivable that Facebook will end up drowning out most fake news , along with a lot of legitimate content from second- and third-tier web publishers , without having to police it any more actively than it already does .\nThose clamoring for Facebook to fix its fake news problem should be careful what they wish for . They might find in a few years that the fake news is gone\u2014but the filter bubbles , the perverse incentives , and Facebook \u2019 s pretense to algorithmic neutrality remain .",
    "content_original": "Facebook CEO Mark Zuckerberg during a town hall at Facebook\u2019s headquarters in Menlo Park, California, in 2015. Stephen Lam/Reuters\n\nIn the wake of Donald Trump\u2019s election as president, Facebook has taken justifiable heat for its role in spreading misinformation and propaganda about the candidates. In particular, its news feed algorithm fueled a cottage industry of fake and intentionally misleading \u201cnews\u201d that skewed heavily anti\u2013Hillary Clinton and pro-Trump, according to a BuzzFeed analysis. These falsehoods attracted far more user engagement, on average, than true stories from the same outlets and drowned out earnest attempts by dedicated fact-checking sites such as Snopes to debunk them.\n\nThis should not surprise anyone who understands how Facebook works. People tend to read, like, and share stories that appeal to their emotions and play to their existing beliefs. Without robust countervailing forces favoring credibility and accuracy, Facebook\u2019s news feed algorithm is bound to spread lies, especially those that serve to bolster people\u2019s preconceived biases. And these falsehoods are bound to influence people\u2019s thinking.\n\nAnd yet, in the days following the election, as criticisms of the company mounted, Facebook CEO Mark Zuckerberg downplayed and denied the issue\u2014a defensiveness that says even more about the company than the fake news scandal itself. Zuckerberg\u2019s response points to a problem deeper than any bogus story, one that won\u2019t be fixed by cutting some shady websites out of its advertising network. The problem is Facebook\u2019s refusal to own up to its increasingly dominant role in the news media. It\u2019s one that is unlikely to go away, even if the fake news does.\n\nIn a public interview last Thursday, Zuckerberg claimed that fake news on Facebook \u201csurely had no impact\u201d on the election and that to suggest otherwise was \u201ca pretty crazy idea.\u201d He accused Facebook critics of condescension for assuming that voters could be influenced by falsehoods and dismissed the notion that one side could have shared more fake news than the other. (There is evidence that it did.) As criticism intensified, he followed up with a personal Facebook post on Saturday, which struck a more conciliatory tone but still rejected the notion that fake news had an impact. He noted that Facebook already allows users to flag hoaxes and fake news and added that \u201cwe will continue to work on this to improve further.\u201d At the same time, he cautioned that Facebook had to \u201cproceed very carefully,\u201d because \u201cidentifying the \u2018truth\u2019 is complicated.\u201d\n\nYes, the truth is complicated, and Facebook should proceed carefully. But there is a growing sense, both inside and outside the company, that it may be proceeding rather too carefully, given its increasingly dominant role in the distribution of news online. And Zuckerberg\u2019s denials seem to be fanning the flames.\n\nOver the weekend, some highly placed, anonymous Facebook employees told the New York Times that they\u2019ve been questioning the company\u2019s role in the campaign. Five more anonymous employees told BuzzFeed on Monday that they and dozens of others within Facebook have formed a secret \u201ctask force\u201d to advocate for stronger action against fake news. Meanwhile, a top Clinton strategist told Politico that Democratic leaders are looking for ways to get Facebook to address the problem. And Gizmodo reported, citing an anonymous source, that Facebook considered a tougher move against fake news this summer but held off out of fear of upsetting conservatives. Facebook disputed that, telling me it did no such thing and providing an alternative explanation for its tweaks to the news feed over the summer. (This puts Facebook in the ironic position of arguing that Gizmodo\u2019s post is itself a false news story of sorts.)\n\nFinally, on Monday night, the company took a concrete step. Following the lead of Google, which made a similar move earlier in the day, Facebook announced that it will ban fake news sites from using its advertising network. It\u2019s a fine start. It is not nearly enough.\n\nThe furor over fake news is warranted. Fabricated stories about the pope endorsing Trump or an FBI agent getting murdered for leaking Clinton\u2019s emails may have composed a small fraction of all the political content shared on Facebook. (Zuckerberg declared, without sharing any evidence, that more than 99 percent of Facebook content is \u201cauthentic.\u201d) But they and others like them were so widely shared\u2014nearly 1 million times in the case of the bogus pope endorsement\u2014that it\u2019s easy to imagine they played a role in at least some voters\u2019 thinking. By contrast, a major investigative scoop from the New York Times about Trump\u2019s tax returns was shared fewer than 200,000 times. The presence of fake news side by side with real news, in identical format, contributes to a sense that anything you read in the news feed could just as well be true as entirely made up.\n\nYet in the long run, fake news on Facebook may prove to be a relatively short-lived concern compared with the deeper fault line that the tremors have exposed. It reveals a company increasingly torn between its self-conception as a neutral technology platform and its undeniable influence on the creation, distribution, and consumption of news and other media. And it\u2019s left Zuckerberg, one of the world\u2019s most powerful executives, struggling to keep control of his company and the story it tells about itself.\n\nHe\u2019s right, by the way, to be wary of casting Facebook in the role of arbiter of journalistic credibility. A news feed that\u2019s a messy free-for-all is probably preferable to one in which only Facebook-approved sources can be heard. So let\u2019s grant that it would be impossible for Facebook to stamp out all falsehoods in its network and perhaps even dangerous for it to even try, were it to cast too expansive a net. Even so, the existence of Macedonian click-farms dedicated to churning out fake news stories for profit is a clear sign that Facebook could be doing more to address the small fraction of content that is obviously bogus. Even Zuckerberg admits this.\n\nWhat was odd about Zuckerberg\u2019s response to the fake news problem was how adamant he seemed that it had no impact. Facebook\u2019s whole premise as a business is that what people read in their news feeds can influence their decisions\u2014otherwise, there would be little point in advertising there. And Zuckerberg has been more than happy to trumpet the company\u2019s estimate that it encouraged 2 million people who might have otherwise stayed home to vote. Yet he wants us to believe that fake news stories played no role at all.\n\nIf Gizmodo\u2019s report is accurate, it would cast Zuckerberg\u2019s pooh-poohing of the fake news problem in an ugly new light. It would suggest that the company knew fake news was helping one political party more than the other and that it declined to take action for that very reason. It would imply that Zuckerberg isn\u2019t just in denial\u2014he\u2019s flat-out lying.\n\nBut there\u2019s another explanation for his defiant stance that doesn\u2019t rely on speculation (or single anonymous sources). It\u2019s that Zuckerberg is so loath to take responsibility for the content that appears on Facebook\u2014so reluctant to be weighed down by its baggage, even as he runs the conveyor belt\u2014that he\u2019d rather deny its effects than grapple with its causes.\n\nThat\u2019s consistent with Zuckerberg\u2019s approach to other deeper questions about Facebook\u2019s role in the media, including the charge that it insulates users in ideological bubbles by reinforcing what they already believe. \u201cAll the research we have suggests that this isn\u2019t really a problem,\u201d Zuckerberg said on Thursday, citing a Facebook-funded 2015 study that has been criticized as misleading. The data showed that Facebook does in fact expose users primarily to political content that conforms to their partisan identifications. But the study concluded, a little defensively, that this problem was insignificant compared with the problem of users\u2019 own choices as to which sort of content to engage with. As Jefferson Pooley pointed out in Slate, it\u2019s impossible to reproduce Facebook\u2019s findings, because the company won\u2019t let independent researchers see its data.\n\nDubious as the study\u2019s conclusions are, it seems to have convinced Zuckerberg beyond a doubt that Facebook doesn\u2019t have a filter-bubble problem. That\u2019s convenient for Facebook, since addressing such an issue would require rethinking the fundamental structure of its algorithm and user experience. Evidently Facebook\u2019s users are not the only ones subject to confirmation bias and epistemic closure.\n\nThere is an even more subtle and insidious effect of Facebook\u2019s algorithm that has gone almost unmentioned in this saga. It\u2019s the incentive Facebook creates for the media\u2014both the hoax-disseminating media and the truth-telling one\u2014to write and frame stories in ways that are geared to generate likes, clicks, and shares among the social network\u2019s users. The illusion that Facebook is a neutral platform should have been shattered long ago by the obvious ways it has warped online news coverage, from the manipulative headlines to the feeding frenzies over sensational stories and anecdotes that are too good to check. If you were trying to design a media diet that could help give rise to something like the Trump phenomenon, you could hardly do better than 24-hour cable news and the Facebook news feed. To its credit, Facebook has acknowledged the problems of clickbait and likebait and made real efforts to mitigate its own perverse incentives. But even as Zuckerberg has repeatedly addressed the issue of fake news, he has evinced no awareness of the other ways Facebook might have disrupted political coverage for the worse.\n\nFinally, there\u2019s Zuckerberg\u2019s oft-criticized denial that Facebook is a media company. \u201cIt\u2019s a technology company,\u201d he says, as if that settles it. There are valid arguments on both sides, and no doubt the company has its feet in both sectors. It would be eminently reasonable for Facebook to admit that it is a media company in some key respects but not in others. But Zuckerberg denies even that. To him, there is no argument.\n\nDrill down into Facebook\u2019s reasons for insisting that it isn\u2019t a media company, and you\u2019ll hit layer upon layer of denial. It denies that it\u2019s a media company because that allows it to further deny that Facebook shapes not only how the news is distributed, but how it is reported, framed, discussed, and perceived. That in turn allows it to deny that its humans or algorithms might exhibit any bias that could warp the news for better or worse or favor one set of interests over another. If Facebook is a neutral platform, as it insists, then it can deny any responsibility for how people use it, any responsibility for what they post or share, any responsibility to ensure the accuracy or fairness or journalistic virtue of whatever news might circulate on it.\n\nThe ultimate denial, and the underlying purpose of it all, is to deny the very possibility of any tension between Facebook\u2019s own interests and the interests of society. Facebook, by Zuckerberg\u2019s lights, is simply a powerful tool for making the world more open and connected. And if that means Trump is elected U.S. president, there must have been good reasons for his election that had nothing to do with Facebook. Or, in Zuckerberg\u2019s words, \u201cvoters make decisions based on their lived experience\u201d\u2014as if Facebook weren\u2019t a part of that, as if its $335 billion market value weren\u2019t a function of the incredible degree to which it has managed to ingratiate itself into people\u2019s daily lives, as if our online and offline lives weren\u2019t now irrevocably intertwined.\n\nEither the internal contradiction of Zuckerberg\u2019s position is lost on him or, more likely, he recognizes it but refuses to acknowledge it. His discretion makes sense, from a business perspective if not a moral one, if he believes that confronting Facebook\u2019s impact on politics would require changes that would hurt the company\u2019s bottom line. But coming from a figure who preaches the gospel of openness, it\u2019s baffling.\n\nIt now seems, however, that Zuckerberg has lost the faith of some of his own employees on this issue. Facebook has rarely been a leaky company in the past. But the leaks started with its bungling of the trending news controversy, and they\u2019ve resurfaced around the fake news debate. Facebook\u2019s move on Monday to cut off advertising to fake news sites feels like an acknowledgement from the top that outright denial is no longer tenable.\n\nThe question now is how far Facebook will go to placate its critics. The last time it faced an uproar over its influence on U.S. politics\u2014the overblown controversy involving its trending news section\u2014it grossly overreacted and made everything worse. That seems less likely this time, especially since the news feed is a far more precious product to the company.\n\nWhat\u2019s more likely is that Facebook will seek to isolate and defuse the fake news issue while preserving its claim to be a neutral technology platform. As John Herrman pointed out in the New York Times last week, Facebook may already be evolving in ways that render the current controversy largely irrelevant. For instance, it has been partnering with prestigious media outlets to produce video content, broadcast live videos, and publish glossy \u201cinstant articles\u201d within the news feed itself. It\u2019s using the power of its algorithm to prioritize those forms over others, including links to news stories from publishers around the web. It\u2019s conceivable that Facebook will end up drowning out most fake news, along with a lot of legitimate content from second- and third-tier web publishers, without having to police it any more actively than it already does.\n\nThose clamoring for Facebook to fix its fake news problem should be careful what they wish for. They might find in a few years that the fake news is gone\u2014but the filter bubbles, the perverse incentives, and Facebook\u2019s pretense to algorithmic neutrality remain.",
    "source_url": "www.slate.com",
    "bias_text": "left",
    "ID": "MNhKoq6Ik9e26MMF"
}