{
    "topic": "media_bias",
    "source": "Vox",
    "bias": 0,
    "url": "http://www.vox.com/new-money/2016/11/16/13637310/facebook-fake-news-explained",
    "title": "Facebook's fake news problem, explained",
    "date": "2016-11-16",
    "authors": "Timothy B. Lee, Zack Beauchamp, Hannah Brown, Jen Kirby, Peter Kafka, Matthew Yglesias, Sean Collins",
    "content": "News stories are supposed to help ordinary voters understand the world around them . But in the 2016 election , news stories online too often had the opposite effect . Stories rocketed around the internet that were misleading , sloppily reported , or in some cases totally made up .\nOver the course of 2016 , Facebook users learned that the pope endorsed Donald Trump ( he didn \u2019 t ) , that a Democratic operative was murdered after agreeing to testify against Hillary Clinton ( it never happened ) , that Bill Clinton raped a 13-year-old girl ( a total fabrication ) , and many other totally bogus \u201c news \u201d stories . Stories like this thrive on Facebook because Facebook \u2019 s algorithm prioritizes \u201c engagement \u201d \u2014 and a reliable way to get readers to engage is by making up outrageous nonsense about politicians they don \u2019 t like .\nA big problem here is that the internet has broken down the traditional distinction between professional news-gathering and amateur rumor-mongering . On the internet , the \u201c Denver Guardian \u201d \u2014 a fake news site designed to look like a real Colorado newspaper \u2014 can reach a wide audience as easily as real news organizations like the Denver Post , the New York Times , and Fox News .\nSince last week \u2019 s election , there has been a fierce debate about whether the flood of fake news \u2014 much of it prejudicial to Hillary Clinton \u2014 could have swung the election to Donald Trump . Internet giants are coming under increasing pressure to do something about the problem .\nOn Monday , Google announced that it was going to cut fake news sites off from access to its vast advertising network , depriving them of a key revenue source . Facebook quickly followed suit with its own ad network .\nAt the same time , CEO Mark Zuckerberg has signaled reluctance to have Facebook become more active in weeding out fake news stories . He described it as \u201c a pretty crazy idea \u201d to think fake news on Facebook could have swayed the election . He says Facebook will look for new ways to stop the spread of fake news , but he also argues that \u201c we must proceed very carefully \u201d and that Facebook must be \u201c extremely cautious about becoming arbiters of truth ourselves . \u201d\nThe importance of this issue is only going to grow over time . More and more people are getting their news from the internet , putting more and more power in the hands of companies like Google , Twitter , and especially Facebook . The leaders of those companies are going to be under increasing pressure to use that power wisely .\nIn the 1990s and early 2000s , it was common to think of the internet as a decentralized , even anarchic , place where no one was really in charge . Online-only news organizations were still in their infancy , so that most people either got their news from traditional sources like newspapers or cable news shows , or else they went to the home pages of conventional news organizations like the New York Times , the Atlantic , or Fox News .\nThe rise of social media sites has changed things in two major ways .\nFirst , social media has drastically lowered barriers to entry in the news business . It has always been easy for anyone to publish a website , of course . But as news consumption is increasingly driven by social media sharing , it \u2019 s becoming easier than ever for no-name sites to reach a big audience .\nAt the same time , a handful of big tech companies \u2014 Twitter , Google , and especially Facebook \u2014 have gained a huge and growing influence over what news people see . 44 percent of US adults tell pollsters they got news from Facebook in 2016 . That \u2019 s vastly larger than other news-focused social media sites like Twitter ( 9 percent ) and Reddit ( 2 percent ) . And while many people get their news from television programs or newspapers , those media are divided among many competing news organizations . This means that Facebook has a larger influence over ordinary Americans \u2019 media diets than almost any other news organization .\nNormally we think that organizations with a lot of power have an obligation to use that power responsibly . But the leaders of the largest technology companies have resisted thinking of themselves in those terms . They like to think of their sites as neutral platforms that help users share information with each other \u2014 without the company making value judgments of its own .\nBut this isn \u2019 t how power works . When an authority figure turns a blind eye to a problem that \u2019 s happening under his watch , the problem doesn \u2019 t go away . It festers , often becoming an even bigger problem over time .\nFake news is a problem , but we don \u2019 t know how big it is\nThe problem of fake news is so new that we don \u2019 t have definitive data on how big of a problem it is . But there are some reasons to think it could be very significant .\nWe know that low-quality news stories have proliferated on Facebook . For example , investigations by BuzzFeed and the Guardian found that a group of cynical Macedonian hucksters had created dozens of right-wing news sites that publish low-quality pro-Trump news stories . Some are plagiarized from other conservative news sites . Others appear to be totally made up , with headlines like \u201c Proof surfaces that Obama was born in Kenya , \u201d \u201c Bill Clinton \u2019 s sex tape just leaked , \u201d and \u201c Pope Francis forbids Catholics from voting for Hillary ! \u201d\n\u201c Yes , the info in the blogs is bad , false , and misleading but the rationale is that \u2018 if it gets the people to click on it and engage , then use it , \u2019 \u201d a Macedonian student told BuzzFeed .\nOther fake news is generated by partisan bloggers taking news tidbits out of context and drawing totally wrong conclusions from them . For example , some confused conservative bloggers misread a leaked email from Clinton adviser John Podesta as evidence that Democrats were manipulating public poll results . In fact , Democrats were using a standard polling technique called oversampling on Democrats \u2019 own internal polls \u2014 but that didn \u2019 t stop the story from spreading among online conservatives .\nAnd fake news hasn \u2019 t only circulated on the right-hand side of the political spectrum . A story about Pope Francis endorsing Bernie Sanders was also made up .\nAs the internet \u2019 s most popular news source , Facebook appears to have the biggest fake news problem . But it \u2019 s not a problem that only afflicts Facebook . In the wake of last week \u2019 s election , one of the top search results on Google was a post claiming that Trump won the popular vote \u2014 he didn \u2019 t .\nFacebook is worried about being seen as biased against conservatives\nPublicly , Facebook \u2019 s CEO has downplayed the site \u2019 s role in distributing fake news online . But privately , there \u2019 s a raging debate inside Facebook about how it could do more .\nBuzzFeed reports that some Facebook employees are frustrated by Zuckerberg \u2019 s blas\u00e9 response to concerns about fake news on the social media platform .\n\u201c What \u2019 s crazy is for him to come out and dismiss it like that , \u201d one anonymous engineer wrote , according to BuzzFeed . \u201c He knows , and those of us at the company know , that fake news ran wild on our platform during the entire campaign season . \u201d\nOne reason Facebook \u2019 s management has been so cautious on this issue is that it \u2019 s still smarting from the controversy earlier this year over Facebook \u2019 s trending news feature . Until this summer , Facebook employed a team of professional journalists to curate the trending news box that appeared in the right-hand rail next to the Facebook newsfeed .\nThen in May , one of Facebook \u2019 s trending news editors told Gizmodo that the team was routinely suppressing trending stories that slanted in a conservative direction . That caused a massive backlash , including questions from Republicans in Congress about Facebook \u2019 s editorial policies . This led to Facebook terminating the entire trending news team . Today , Facebook uses software to choose which headlines appear in this box .\nBut with the human editors gone , Facebook had a new problem : It started to see fake stories showing up in the trending box . Facebook \u2019 s trending news algorithm simply wasn \u2019 t sophisticated enough to distinguish an accurate news story from an inaccurate one .\nThe current debate over fake news on Facebook can be seen as a much broader version of the same controversy . Nobody is going to defend fake news per se . But once you start injecting human editorial judgment into content decisions , questions of bias are inevitably going to come up .\nThis is a particularly tricky issue because it \u2019 s not easy to draw a line between articles that are totally fake and articles that are just highly misleading or based on shoddy reporting .\nFor example , after BuzzFeed reported that 43 percent of articles from a hyperpartisan site called Right Wing News were either \u201c mostly false \u201d or a \u201c mix of true and false , \u201d the site \u2019 s editor insisted that many of the articles classified as false were actually accurate . One story claimed that the Clinton Foundation devoted only 10 percent of its revenue to charity , a figure it got from a Federalist article that only counted grants to third-party organizations , not charitable activities carried out by the Clinton Foundation itself , in calculating total charitable spending .\nIt seems pretty clear that the Federalist and Right Wing News are in the wrong here . It \u2019 s not reasonable to count a foundation \u2019 s own charitable programs as overhead . But if Facebook were to classify this story as fake news and ban it from the site , some conservatives are going to see that as evidence of left-wing bias .\nAlso , any effort to weed out fake news at Facebook \u2019 s scale is going to lead to some straight-up mistakes . If these mistakes disproportionately target conservative viewpoints , that \u2019 s going to create a backlash that will hurt Facebook \u2019 s brand with tens of millions of conservative Facebook users .\n\u201c This is an area where I believe we must proceed very carefully , \u201d Zuckerberg wrote in a Sunday Facebook post . He argued that many stories \u201c express an opinion that many will disagree with and flag as incorrect even when factual . I am confident we can find ways for our community to tell us what content is most meaningful , but I believe we must be extremely cautious about becoming arbiters of truth ourselves . \u201d\nMost of the discussion about how Facebook could address fake news has assumed that the goal is to banish fake news from the platforms . But there are a couple of other approaches that might ultimately work better .\nOne is that rather than banning fake news , Facebook could give a boost to high-quality news . It \u2019 s hard to say whether Right Wing News is a fake news site , but it \u2019 s easy to say that the New York Times and the Washington Times are legitimate news sources . And Facebook \u2019 s newsfeed algorithm decides which news stories to show users first . Giving high-quality news sources a bonus in the newsfeed algorithm could improve the average quality of news users read without Facebook having to make tricky judgments about which news is and isn \u2019 t fake .\nA second approach would be to change how Facebook presents dubious news stories instead of banning them outright . Right now , when users post a link , Facebook expands that into a \u201c card \u201d showing an image , headline , and short sentence describing the article . This format is standardized so that a New York Times article is formatted in the same way as an article from a no-name blog .\nBut Facebook could change that . Instead of presenting an identical summary card for every link , it could present different kinds of cards \u2014 or no card at all \u2014 depending on the perceived quality of the source . Credible news sources could show full cards like they do now . Less credible sources could show smaller cards \u2014 or no cards at all .\nAnd Facebook could hire a team of fact-checkers to examine the most widely-shared stories . If a story checks out , Facebook could show an icon verifying that the story is authentic . If it doesn \u2019 t check out , Facebook could include a prominent link to a story explaining that the story is inaccurate . Users would still be free to read the story and disagree with Facebook \u2019 s verdict . But they \u2019 d at least be aware that a particular article \u2019 s claim is disputed .\nUltimately , some level of controversy is inevitable for a topic this political . Any effort to crack down on fake news is going to generate a certain amount of backlash from people whose stories are labeled as bogus . But critics say Zuckerberg has an obligation to try to do something to stem the flood of fake news on his platform .",
    "content_original": "News stories are supposed to help ordinary voters understand the world around them. But in the 2016 election, news stories online too often had the opposite effect. Stories rocketed around the internet that were misleading, sloppily reported, or in some cases totally made up.\n\nOver the course of 2016, Facebook users learned that the pope endorsed Donald Trump (he didn\u2019t), that a Democratic operative was murdered after agreeing to testify against Hillary Clinton (it never happened), that Bill Clinton raped a 13-year-old girl (a total fabrication), and many other totally bogus \u201cnews\u201d stories. Stories like this thrive on Facebook because Facebook\u2019s algorithm prioritizes \u201cengagement\u201d \u2014 and a reliable way to get readers to engage is by making up outrageous nonsense about politicians they don\u2019t like.\n\nA big problem here is that the internet has broken down the traditional distinction between professional news-gathering and amateur rumor-mongering. On the internet, the \u201cDenver Guardian\u201d \u2014 a fake news site designed to look like a real Colorado newspaper \u2014 can reach a wide audience as easily as real news organizations like the Denver Post, the New York Times, and Fox News.\n\nSince last week\u2019s election, there has been a fierce debate about whether the flood of fake news \u2014 much of it prejudicial to Hillary Clinton \u2014 could have swung the election to Donald Trump. Internet giants are coming under increasing pressure to do something about the problem.\n\nOn Monday, Google announced that it was going to cut fake news sites off from access to its vast advertising network, depriving them of a key revenue source. Facebook quickly followed suit with its own ad network.\n\nAt the same time, CEO Mark Zuckerberg has signaled reluctance to have Facebook become more active in weeding out fake news stories. He described it as \u201ca pretty crazy idea\u201d to think fake news on Facebook could have swayed the election. He says Facebook will look for new ways to stop the spread of fake news, but he also argues that \u201cwe must proceed very carefully\u201d and that Facebook must be \u201cextremely cautious about becoming arbiters of truth ourselves.\u201d\n\nThe importance of this issue is only going to grow over time. More and more people are getting their news from the internet, putting more and more power in the hands of companies like Google, Twitter, and especially Facebook. The leaders of those companies are going to be under increasing pressure to use that power wisely.\n\nThe internet is growing up\n\nIn the 1990s and early 2000s, it was common to think of the internet as a decentralized, even anarchic, place where no one was really in charge. Online-only news organizations were still in their infancy, so that most people either got their news from traditional sources like newspapers or cable news shows, or else they went to the home pages of conventional news organizations like the New York Times, the Atlantic, or Fox News.\n\nThe rise of social media sites has changed things in two major ways.\n\nFirst, social media has drastically lowered barriers to entry in the news business. It has always been easy for anyone to publish a website, of course. But as news consumption is increasingly driven by social media sharing, it\u2019s becoming easier than ever for no-name sites to reach a big audience.\n\nAt the same time, a handful of big tech companies \u2014 Twitter, Google, and especially Facebook \u2014 have gained a huge and growing influence over what news people see. 44 percent of US adults tell pollsters they got news from Facebook in 2016. That\u2019s vastly larger than other news-focused social media sites like Twitter (9 percent) and Reddit (2 percent). And while many people get their news from television programs or newspapers, those media are divided among many competing news organizations. This means that Facebook has a larger influence over ordinary Americans\u2019 media diets than almost any other news organization.\n\nNormally we think that organizations with a lot of power have an obligation to use that power responsibly. But the leaders of the largest technology companies have resisted thinking of themselves in those terms. They like to think of their sites as neutral platforms that help users share information with each other \u2014 without the company making value judgments of its own.\n\nBut this isn\u2019t how power works. When an authority figure turns a blind eye to a problem that\u2019s happening under his watch, the problem doesn\u2019t go away. It festers, often becoming an even bigger problem over time.\n\nFake news is a problem, but we don\u2019t know how big it is\n\nThe problem of fake news is so new that we don\u2019t have definitive data on how big of a problem it is. But there are some reasons to think it could be very significant.\n\nWe know that low-quality news stories have proliferated on Facebook. For example, investigations by BuzzFeed and the Guardian found that a group of cynical Macedonian hucksters had created dozens of right-wing news sites that publish low-quality pro-Trump news stories. Some are plagiarized from other conservative news sites. Others appear to be totally made up, with headlines like \u201cProof surfaces that Obama was born in Kenya,\u201d \u201cBill Clinton\u2019s sex tape just leaked,\u201d and \u201cPope Francis forbids Catholics from voting for Hillary!\u201d\n\n\u201cYes, the info in the blogs is bad, false, and misleading but the rationale is that \u2018if it gets the people to click on it and engage, then use it,\u2019\u201d a Macedonian student told BuzzFeed.\n\nOther fake news is generated by partisan bloggers taking news tidbits out of context and drawing totally wrong conclusions from them. For example, some confused conservative bloggers misread a leaked email from Clinton adviser John Podesta as evidence that Democrats were manipulating public poll results. In fact, Democrats were using a standard polling technique called oversampling on Democrats\u2019 own internal polls \u2014 but that didn\u2019t stop the story from spreading among online conservatives.\n\nAnd fake news hasn\u2019t only circulated on the right-hand side of the political spectrum. A story about Pope Francis endorsing Bernie Sanders was also made up.\n\nAs the internet\u2019s most popular news source, Facebook appears to have the biggest fake news problem. But it\u2019s not a problem that only afflicts Facebook. In the wake of last week\u2019s election, one of the top search results on Google was a post claiming that Trump won the popular vote \u2014 he didn\u2019t.\n\nFacebook is worried about being seen as biased against conservatives\n\nPublicly, Facebook\u2019s CEO has downplayed the site\u2019s role in distributing fake news online. But privately, there\u2019s a raging debate inside Facebook about how it could do more.\n\nBuzzFeed reports that some Facebook employees are frustrated by Zuckerberg\u2019s blas\u00e9 response to concerns about fake news on the social media platform.\n\n\u201cWhat\u2019s crazy is for him to come out and dismiss it like that,\u201d one anonymous engineer wrote, according to BuzzFeed. \u201cHe knows, and those of us at the company know, that fake news ran wild on our platform during the entire campaign season.\u201d\n\nOne reason Facebook\u2019s management has been so cautious on this issue is that it\u2019s still smarting from the controversy earlier this year over Facebook\u2019s trending news feature. Until this summer, Facebook employed a team of professional journalists to curate the trending news box that appeared in the right-hand rail next to the Facebook newsfeed.\n\nThen in May, one of Facebook\u2019s trending news editors told Gizmodo that the team was routinely suppressing trending stories that slanted in a conservative direction. That caused a massive backlash, including questions from Republicans in Congress about Facebook\u2019s editorial policies. This led to Facebook terminating the entire trending news team. Today, Facebook uses software to choose which headlines appear in this box.\n\nBut with the human editors gone, Facebook had a new problem: It started to see fake stories showing up in the trending box. Facebook\u2019s trending news algorithm simply wasn\u2019t sophisticated enough to distinguish an accurate news story from an inaccurate one.\n\nThe current debate over fake news on Facebook can be seen as a much broader version of the same controversy. Nobody is going to defend fake news per se. But once you start injecting human editorial judgment into content decisions, questions of bias are inevitably going to come up.\n\nThis is a particularly tricky issue because it\u2019s not easy to draw a line between articles that are totally fake and articles that are just highly misleading or based on shoddy reporting.\n\nFor example, after BuzzFeed reported that 43 percent of articles from a hyperpartisan site called Right Wing News were either \u201cmostly false\u201d or a \u201cmix of true and false,\u201d the site\u2019s editor insisted that many of the articles classified as false were actually accurate. One story claimed that the Clinton Foundation devoted only 10 percent of its revenue to charity, a figure it got from a Federalist article that only counted grants to third-party organizations, not charitable activities carried out by the Clinton Foundation itself, in calculating total charitable spending.\n\nIt seems pretty clear that the Federalist and Right Wing News are in the wrong here. It\u2019s not reasonable to count a foundation\u2019s own charitable programs as overhead. But if Facebook were to classify this story as fake news and ban it from the site, some conservatives are going to see that as evidence of left-wing bias.\n\nAlso, any effort to weed out fake news at Facebook\u2019s scale is going to lead to some straight-up mistakes. If these mistakes disproportionately target conservative viewpoints, that\u2019s going to create a backlash that will hurt Facebook\u2019s brand with tens of millions of conservative Facebook users.\n\n\u201cThis is an area where I believe we must proceed very carefully,\u201d Zuckerberg wrote in a Sunday Facebook post. He argued that many stories \u201cexpress an opinion that many will disagree with and flag as incorrect even when factual. I am confident we can find ways for our community to tell us what content is most meaningful, but I believe we must be extremely cautious about becoming arbiters of truth ourselves.\u201d\n\nBanning fake news might be the wrong approach\n\nMost of the discussion about how Facebook could address fake news has assumed that the goal is to banish fake news from the platforms. But there are a couple of other approaches that might ultimately work better.\n\nOne is that rather than banning fake news, Facebook could give a boost to high-quality news. It\u2019s hard to say whether Right Wing News is a fake news site, but it\u2019s easy to say that the New York Times and the Washington Times are legitimate news sources. And Facebook\u2019s newsfeed algorithm decides which news stories to show users first. Giving high-quality news sources a bonus in the newsfeed algorithm could improve the average quality of news users read without Facebook having to make tricky judgments about which news is and isn\u2019t fake.\n\nA second approach would be to change how Facebook presents dubious news stories instead of banning them outright. Right now, when users post a link, Facebook expands that into a \u201ccard\u201d showing an image, headline, and short sentence describing the article. This format is standardized so that a New York Times article is formatted in the same way as an article from a no-name blog.\n\nBut Facebook could change that. Instead of presenting an identical summary card for every link, it could present different kinds of cards \u2014 or no card at all \u2014 depending on the perceived quality of the source. Credible news sources could show full cards like they do now. Less credible sources could show smaller cards \u2014 or no cards at all.\n\nAnd Facebook could hire a team of fact-checkers to examine the most widely-shared stories. If a story checks out, Facebook could show an icon verifying that the story is authentic. If it doesn\u2019t check out, Facebook could include a prominent link to a story explaining that the story is inaccurate. Users would still be free to read the story and disagree with Facebook\u2019s verdict. But they\u2019d at least be aware that a particular article\u2019s claim is disputed.\n\nUltimately, some level of controversy is inevitable for a topic this political. Any effort to crack down on fake news is going to generate a certain amount of backlash from people whose stories are labeled as bogus. But critics say Zuckerberg has an obligation to try to do something to stem the flood of fake news on his platform.",
    "source_url": "www.vox.com",
    "bias_text": "left",
    "ID": "NqE1NexjCFqFSz7T"
}