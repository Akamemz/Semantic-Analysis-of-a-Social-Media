{
    "topic": "nsa",
    "source": "Christian Science Monitor",
    "bias": 1,
    "url": "http://www.csmonitor.com/Commentary/the-monitors-view/2013/0606/Spying-on-DNA-Verizon-and-free-will?nav=90-csm_category-topStories",
    "title": "Spying on DNA, Verizon, and free will",
    "date": "2013-06-06",
    "authors": "",
    "content": "Humans read each other \u2019 s faces to detect emotions . If that is difficult , they may even offer a bribe : \u201c A penny for your thoughts. \u201d We \u2019 re so used to inferring each other \u2019 s inner life that it \u2019 s easy to not think twice about new technologies that are slowly taking over the task \u2013 whether for good or ill .\nTake , for example , Google Glass , the wearable computer in a head-mounted display that could easily come with a facial-recognition application that can discern whether someone is lying , in love , contemptuous , or bored . Fortunately , Google has decided not to release the app \u2013 for now . The technology \u2013 much like the street-level views on Google Maps \u2013 still raises difficult questions about privacy .\nYet the pressure persists , especially in government , for better tools for surveillance of people \u2019 s bodies , behavior , and \u2013 increasingly \u2013 their mental and emotional states . Two examples this month show just how eager the government is .\nThe Supreme Court ruled June 3 that police can swab a person \u2019 s mouth for DNA upon arrest . The justices likened this to fingerprinting , saying it can help solve or prevent crime . And on June 6 , the Obama administration admitted it was secretly collecting the phone records ( although not the conversations ) of all Verizon customers \u2013 yes , all \u2013 in its antiterrorist surveillance .\nLike airport body scanners , such high-tech anticrime tools in themselves may be acceptable if a court or Congress approves their use . Such approval implies societal consent or constitutionality . And Internet companies like Google and Facebook are improving their privacy practices as more consumers seek control of their personal data in return for handing it over .\nBut science is also on the cusp of releasing many tools to detect or track emotional states and brain activity . This raises questions about whether government and business will treat people as being controlled by neurons and hormones rather than as moral agents with independent thought .\nSome experts claim notions like consciousness , even conscience , must change as neuroscience makes advances . \u201c The idea that our conscious , individual thinking is the key determining factor of our behavior may come to be seen as foolish a vanity as our earlier idea that we were the center of the universe , \u201d argues Alex Pentland , a computer scientist at the Massachusetts Institute of Technology , in his book \u201c Honest Signals . \u201d\nYet others say society will not function unless it recognizes humans can make choices regardless of any theory of brain science . That is why concerns about privacy \u2013 such as the right not to self-incriminate \u2013 are so strong . \u201c If there is a quintessential zone of human privacy it is the mind , \u201d wrote the late Justice Allen Broussard of California \u2019 s Supreme Court .\nGet the Monitor Stories you care about delivered to your inbox . By signing up , you agree to our Privacy Policy\nAs brain imaging and emotion detectors improve , people \u2019 s needs to rely on free will and the dignity of thought must not be eroded . The users of iPhone \u2019 s Siri or similar \u201c intelligent \u201d software are not about to outsource all of their cognitive abilities .\n\u201c A sphere of private rumination is essential to our fundamental concepts of freedom of thought , freedom of expression , freedom of will and individual autonomy , \u201d writes law professor Francis Shen . \u201c Whether or not we preserve that sphere may come to define us as a society as emerging neuroscience begins to take hold . \u201d",
    "content_original": "Humans read each other\u2019s faces to detect emotions. If that is difficult, they may even offer a bribe: \u201cA penny for your thoughts.\u201d We\u2019re so used to inferring each other\u2019s inner life that it\u2019s easy to not think twice about new technologies that are slowly taking over the task \u2013 whether for good or ill.\n\nTake, for example, Google Glass, the wearable computer in a head-mounted display that could easily come with a facial-recognition application that can discern whether someone is lying, in love, contemptuous, or bored. Fortunately, Google has decided not to release the app \u2013 for now. The technology \u2013 much like the street-level views on Google Maps \u2013 still raises difficult questions about privacy.\n\nYet the pressure persists, especially in government, for better tools for surveillance of people\u2019s bodies, behavior, and \u2013 increasingly \u2013 their mental and emotional states. Two examples this month show just how eager the government is.\n\nThe Supreme Court ruled June 3 that police can swab a person\u2019s mouth for DNA upon arrest. The justices likened this to fingerprinting, saying it can help solve or prevent crime. And on June 6, the Obama administration admitted it was secretly collecting the phone records (although not the conversations) of all Verizon customers \u2013 yes, all \u2013 in its antiterrorist surveillance.\n\nLike airport body scanners, such high-tech anticrime tools in themselves may be acceptable if a court or Congress approves their use. Such approval implies societal consent or constitutionality. And Internet companies like Google and Facebook are improving their privacy practices as more consumers seek control of their personal data in return for handing it over.\n\nBut science is also on the cusp of releasing many tools to detect or track emotional states and brain activity. This raises questions about whether government and business will treat people as being controlled by neurons and hormones rather than as moral agents with independent thought.\n\nSome experts claim notions like consciousness, even conscience, must change as neuroscience makes advances. \u201cThe idea that our conscious, individual thinking is the key determining factor of our behavior may come to be seen as foolish a vanity as our earlier idea that we were the center of the universe,\u201d argues Alex Pentland, a computer scientist at the Massachusetts Institute of Technology, in his book \u201cHonest Signals.\u201d\n\nYet others say society will not function unless it recognizes humans can make choices regardless of any theory of brain science. That is why concerns about privacy \u2013 such as the right not to self-incriminate \u2013 are so strong. \u201cIf there is a quintessential zone of human privacy it is the mind,\u201d wrote the late Justice Allen Broussard of California\u2019s Supreme Court.\n\nGet the Monitor Stories you care about delivered to your inbox. By signing up, you agree to our Privacy Policy\n\nAs brain imaging and emotion detectors improve, people\u2019s needs to rely on free will and the dignity of thought must not be eroded. The users of iPhone\u2019s Siri or similar \u201cintelligent\u201d software are not about to outsource all of their cognitive abilities.\n\n\u201cA sphere of private rumination is essential to our fundamental concepts of freedom of thought, freedom of expression, freedom of will and individual autonomy,\u201d writes law professor Francis Shen. \u201cWhether or not we preserve that sphere may come to define us as a society as emerging neuroscience begins to take hold.\u201d",
    "source_url": "www.csmonitor.com",
    "bias_text": "center",
    "ID": "JmosvwlDGaV7JxhS"
}